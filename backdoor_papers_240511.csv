title,venue,year,author,volume,url
A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives.,AAAI,2024,"Yudong Gao, Honglong Chen, Peng Sun 0003, Junjian Li, Anqing Zhang, Zhibo Wang 0001, Weifeng Liu 0001",,https://doi.org/10.1609/aaai.v38i3.27954
Backdoor Adjustment via Group Adaptation for Debiased Coupon Recommendations.,AAAI,2024,"Junpeng Fang, Gongduo Zhang, Qing Cui, Caizhi Tang, Lihong Gu, Longfei Li, Jinjie Gu, Jun Zhou 0011",,https://doi.org/10.1609/aaai.v38i11.29081
Backdoor Attacks via Machine Unlearning.,AAAI,2024,"Zihao Liu, Tianhao Wang 0001, Mengdi Huai, Chenglin Miao",,https://doi.org/10.1609/aaai.v38i13.29321
BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning.,AAAI,2024,"Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang",,https://doi.org/10.1609/aaai.v38i10.29052
BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks (Student Abstract).,AAAI,2024,"Zihan Guan 0001, Mengxuan Hu, Zhongliang Zhou, Jielu Zhang, Sheng Li 0001, Ninghao Liu",,https://doi.org/10.1609/aaai.v38i21.30448
Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning.,AAAI,2024,"Tao Liu, Yuhang Zhang, Zhu Feng, Zhiqin Yang, Chen Xu 0008, Dapeng Man, Wu Yang 0001",,https://doi.org/10.1609/aaai.v38i19.30131
COMBAT: Alternated Training for Effective Clean-Label Backdoor Attacks.,AAAI,2024,"Tran Huynh, Dang Nguyen, Tung Pham 0001, Anh Tran",,https://doi.org/10.1609/aaai.v38i3.28019
Chronic Poisoning: Backdoor Attack against Split Learning.,AAAI,2024,"Fangchao Yu, Bo Zeng, Kai Zhao, Zhi Pang, Lina Wang",,https://doi.org/10.1609/aaai.v38i15.29591
Conditional Backdoor Attack via JPEG Compression.,AAAI,2024,"Qiuyu Duan, Zhongyun Hua, Qing Liao 0001, Yushu Zhang, Leo Yu Zhang",,https://doi.org/10.1609/aaai.v38i18.29957
DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models.,AAAI,2024,"Jiachen Zhou, Peizhuo Lv, Yibing Lan, Guozhu Meng, Kai Chen 0012, Hualong Ma",,https://doi.org/10.1609/aaai.v38i19.30186
Does Few-Shot Learning Suffer from Backdoor Attacks?,AAAI,2024,"Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao",,https://doi.org/10.1609/aaai.v38i18.29965
Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift.,AAAI,2024,"Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang 0002, Qiuling Xu, Guanhong Tao 0001, Guangyu Shen, Siyuan Cheng 0005, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, Xiangyu Zhang",,https://doi.org/10.1609/aaai.v38i10.28958
Inspecting Prediction Confidence for Detecting Black-Box Backdoor Attacks.,AAAI,2024,"Tong Wang, Yuan Yao 0001, Feng Xu 0007, Miao Xu, Shengwei An, Ting Wang",,https://doi.org/10.1609/aaai.v38i1.27780
Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain.,AAAI,2024,"Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li",,https://doi.org/10.1609/aaai.v38i19.30099
Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models.,AAAI,2024,"Yihao Huang 0001, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu 0009, Ming Hu 0003, Tianlin Li, Geguang Pu, Yang Liu",,https://doi.org/10.1609/aaai.v38i19.30110
Progressive Poisoned Data Isolation for Training-Time Backdoor Defense.,AAAI,2024,"Yiming Chen, Haiwei Wu, Jiantao Zhou 0001",,https://doi.org/10.1609/aaai.v38i10.29023
Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective.,AAAI,2024,"Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng",,https://doi.org/10.1609/aaai.v38i13.29385
SEER: Backdoor Detection for Vision-Language Models through Searching Target Text and Image Trigger Jointly.,AAAI,2024,"Liuwan Zhu, Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu",,https://doi.org/10.1609/aaai.v38i7.28611
Temporal-Distributed Backdoor Attack against Video Based Action Recognition.,AAAI,2024,"Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis",,https://doi.org/10.1609/aaai.v38i4.28104
UMA: Facilitating Backdoor Scanning via Unlearning-Based Model Ablation.,AAAI,2024,"Yue Zhao, Congyi Li, Kai Chen 0012",,https://doi.org/10.1609/aaai.v38i19.30183
Watermarking in Secure Federated Learning: A Verification Framework Based on Client-Side Backdooring.,ACM Trans. Intell. Syst. Technol.,2024,"Wenyuan Yang, Shuo Shao, Yue Yang, Xiyao Liu 0001, Ximeng Liu, Zhihua Xia, Gerald Schaefer, Hui Fang 0003",15,https://doi.org/10.1145/3630636
Invariant Aggregator for Defending against Federated Backdoor Attacks.,AISTATS,2024,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",,https://proceedings.mlr.press/v238/wang24e.html
On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem.,AISTATS,2024,"Georg Pichler, Marco Romanelli 0002, Divya Prakash Manivannan, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg",,https://proceedings.mlr.press/v238/pichler24a.html
Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems.,ANZCC,2024,"Yue Wang 0055, Wenqing Li, Michail Maniatakos, Saif Eddin Jabari",,https://doi.org/10.1109/ANZCC59813.2024.10432866
Imperceptible and multi-channel backdoor attack.,Appl. Intell.,2024,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Weiqiang Liu 0010",54,https://doi.org/10.1007/s10489-023-05228-6
Backdoor Attacks and Generative Model Fairness: Current Trends and Future Research Directions.,COMSNETS,2024,"Ryan Holland, Shantanu Pal, Lei Pan 0002, Leo Yu Zhang",,https://doi.org/10.1109/COMSNETS59351.2024.10427172
A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks.,CoRR,2024,,abs/2404.00076,https://doi.org/10.48550/arXiv.2404.00076
A backdoor attack against link prediction tasks with graph neural networks.,CoRR,2024,"Jiazhu Dai, Haoyu Sun",abs/2401.02663,https://doi.org/10.48550/arXiv.2401.02663
A clean-label graph backdoor attack method in node classification task.,CoRR,2024,"Xiaogang Xing, Ming Xu, Yujing Bai, Dongdong Yang",abs/2401.00163,https://doi.org/10.48550/arXiv.2401.00163
A general approach to enhance the survivability of backdoor attacks by decision path coupling.,CoRR,2024,"Yufei Zhao, Dingji Wang, Bihuan Chen 0001, Ziqian Chen, Xin Peng 0001",abs/2403.02950,https://doi.org/10.48550/arXiv.2403.02950
AS-FIBA: Adaptive Selective Frequency-Injection for Backdoor Attack on Deep Face Restoration.,CoRR,2024,"Zhenbo Song, Wenhao Gao, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",abs/2403.06430,https://doi.org/10.48550/arXiv.2403.06430
Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space.,CoRR,2024,"Zongru Wu, Zhuosheng Zhang 0001, Pengzhou Cheng, Gongshen Liu",abs/2402.12026,https://doi.org/10.48550/arXiv.2402.12026
Advancing Security in AI Systems: A Novel Approach to Detecting Backdoors in Deep Neural Networks.,CoRR,2024,"Khondoker Murad Hossain, Tim Oates 0001",abs/2403.08208,https://doi.org/10.48550/arXiv.2403.08208
An Embarrassingly Simple Defense Against Backdoor Attacks On SSL.,CoRR,2024,"Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade",abs/2403.15918,https://doi.org/10.48550/arXiv.2403.15918
Architectural Neural Backdoors from First Principles.,CoRR,2024,"Harry Langford, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot",abs/2402.06957,https://doi.org/10.48550/arXiv.2402.06957
Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP.,CoRR,2024,"Ruinan Jin, Chun-Yin Huang, Chenyu You, Xiaoxiao Li",abs/2401.01911,https://doi.org/10.48550/arXiv.2401.01911
Backdoor Attack with Mode Mixture Latent Modification.,CoRR,2024,"Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang",abs/2403.07463,https://doi.org/10.48550/arXiv.2403.07463
Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation.,CoRR,2024,"Quanyu Long, Yue Deng 0010, Leilei Gan, Wenya Wang, Sinno Jialin Pan",abs/2402.13532,https://doi.org/10.48550/arXiv.2402.13532
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency.,CoRR,2024,"Soumyadeep Pal, Yuguang Yao, Ren Wang 0008, Bingquan Shen, Sijia Liu 0001",abs/2403.10717,https://doi.org/10.48550/arXiv.2403.10717
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning.,CoRR,2024,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang 0008, Li Liu, Chao Shen",abs/2401.15002,https://doi.org/10.48550/arXiv.2401.15002
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models.,CoRR,2024,"Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li",abs/2401.12242,https://doi.org/10.48550/arXiv.2401.12242
BadEdit: Backdooring large language models by model editing.,CoRR,2024,"Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang 0004, Yang Liu",abs/2403.13355,https://doi.org/10.48550/arXiv.2403.13355
Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and Defense on Model Adaptation.,CoRR,2024,"Lijun Sheng, Jian Liang, Ran He 0001, Zilei Wang, Tieniu Tan",abs/2401.06030,https://doi.org/10.48550/arXiv.2401.06030
Clean-image Backdoor Attacks.,CoRR,2024,"Dazhong Rong, Guoyao Yu, Shuheng Shen, Xinyi Fu, Peng Qian, Jianhai Chen, Qinming He, Xing Fu, Weiqiang Wang",abs/2403.15010,https://doi.org/10.48550/arXiv.2403.15010
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning.,CoRR,2024,"Shuai Zhao, Leilei Gan, Luu Anh Tuan, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen",abs/2402.12168,https://doi.org/10.48550/arXiv.2402.12168
DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models.,CoRR,2024,"Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi 0004, Yan Wang 0003, Yingying Chen 0001, Bo Yuan",abs/2402.02739,https://doi.org/10.48550/arXiv.2402.02739
End-to-End Anti-Backdoor Learning on Images and Time Series.,CoRR,2024,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, Yige Li, James Bailey 0001",abs/2401.03215,https://doi.org/10.48550/arXiv.2401.03215
Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion.,CoRR,2024,"Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum",abs/2403.16365,https://doi.org/10.48550/arXiv.2403.16365
Here&apos;s a Free Lunch: Sanitizing Backdoored Models with Model Merge.,CoRR,2024,"Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu",abs/2402.19334,https://doi.org/10.48550/arXiv.2402.19334
Impart: An Imperceptible and Effective Label-Specific Backdoor Attack.,CoRR,2024,"Jingke Zhao, Zan Wang, Yongwei Wang, Lanjun Wang",abs/2403.13017,https://doi.org/10.48550/arXiv.2403.13017
Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control.,CoRR,2024,"Ka Ho Chow, Wenqi Wei, Lei Yu 0002",abs/2401.01085,https://doi.org/10.48550/arXiv.2401.01085
Invisible Backdoor Attack Through Singular Value Decomposition.,CoRR,2024,"Wenmin Chen, Xiaowei Xu",abs/2403.13018,https://doi.org/10.48550/arXiv.2403.13018
Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?,CoRR,2024,"Xiaoxuan Han, Songlin Yang, Wei Wang 0025, Ziwen He, Jing Dong 0003",abs/2401.00414,https://doi.org/10.48550/arXiv.2401.00414
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning.,CoRR,2024,"Siyuan Cheng 0005, Guanhong Tao 0001, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng 0002, Xiangzhe Xu, Kaiyuan Zhang 0002, Shiqing Ma, Xiangyu Zhang",abs/2403.17188,https://doi.org/10.48550/arXiv.2403.17188
Learning Backdoors for Mixed Integer Programs with Contrastive Learning.,CoRR,2024,"Junyang Cai, Taoan Huang, Bistra Dilkina",abs/2401.10467,https://doi.org/10.48550/arXiv.2401.10467
Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm.,CoRR,2024,"Yanqi Qiao, Dazhuang Liu, Rui Wang 0070, Kaitai Liang",abs/2402.15653,https://doi.org/10.48550/arXiv.2402.15653
MalModel: Hiding Malicious Payload in Mobile Deep Learning Models with Black-box Backdoor Attack.,CoRR,2024,"Jiayi Hua, Kailong Wang, Meizhen Wang, Guangdong Bai, Xiapu Luo, Haoyu Wang 0001",abs/2401.02659,https://doi.org/10.48550/arXiv.2401.02659
MirrorAttack: Backdoor Attack on 3D Point Cloud with a Distorting Mirror.,CoRR,2024,"Yuhao Bian, Shengjing Tian, Xiuping Liu",abs/2403.05847,https://doi.org/10.48550/arXiv.2403.05847
Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment.,CoRR,2024,"Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao",abs/2402.14968,https://doi.org/10.48550/arXiv.2402.14968
Model Pairing Using Embedding Translation for Backdoor Attack Detection on Open-Set Classification Tasks.,CoRR,2024,"Alexander Unnervik, Hatef Otroshi-Shahreza, Anjith George, Sébastien Marcel",abs/2402.18718,https://doi.org/10.48550/arXiv.2402.18718
Model X-ray: Detect Backdoored Models via Decision Boundary.,CoRR,2024,"Yanghao Su, Jie Zhang, Ting Xu, Tianwei Zhang, Weiming Zhang 0001, Nenghai Yu",abs/2402.17465,https://doi.org/10.48550/arXiv.2402.17465
Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models.,CoRR,2024,"Hongbin Liu, Michael K. Reiter, Neil Zhenqiang Gong",abs/2402.14977,https://doi.org/10.48550/arXiv.2402.14977
"Multi-Trigger Backdoor Attacks: More Triggers, More Threats.",CoRR,2024,"Yige Li, Xingjun Ma, Jiabo He, Hanxun Huang, Yu-Gang Jiang",abs/2401.15295,https://doi.org/10.48550/arXiv.2401.15295
Object-oriented backdoor attack against image captioning.,CoRR,2024,"Meiling Li, Nan Zhong, Xinpeng Zhang 0001, Zhenxing Qian, Sheng Li 0006",abs/2401.02600,https://doi.org/10.48550/arXiv.2401.02600
On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder.,CoRR,2024,"Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen",abs/2403.03846,https://doi.org/10.48550/arXiv.2403.03846
OrderBkd: Textual backdoor attack through repositioning.,CoRR,2024,"Irina Alekseevskaia, Konstantin Arkhipenko",abs/2402.07689,https://doi.org/10.48550/arXiv.2402.07689
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection.,CoRR,2024,"Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",abs/2402.11473,https://doi.org/10.48550/arXiv.2402.11473
Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models.,CoRR,2024,"Yuxin Wen, Leo Marchyok, Sanghyun Hong 0001, Jonas Geiping, Tom Goldstein, Nicholas Carlini",abs/2404.01231,https://doi.org/10.48550/arXiv.2404.01231
Privacy Backdoors: Stealing Data with Corrupted Pretrained Models.,CoRR,2024,"Shanglun Feng, Florian Tramèr",abs/2404.00473,https://doi.org/10.48550/arXiv.2404.00473
REPQC: Reverse Engineering and Backdooring Hardware Accelerators for Post-quantum Cryptography.,CoRR,2024,"Samuel Pagliarini, Aikata, Malik Imran, Sujoy Sinha Roy",abs/2403.09352,https://doi.org/10.48550/arXiv.2403.09352
Real is not True: Backdoor Attacks Against Deepfake Detection.,CoRR,2024,"Hong Sun, Ziqiang Li, Lei Liu, Bin Li",abs/2403.06610,https://doi.org/10.48550/arXiv.2403.06610
Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors.,CoRR,2024,"Md Abdul Kadir, Gowtham Krishna Addluri, Daniel Sonntag",abs/2403.16569,https://doi.org/10.48550/arXiv.2403.16569
SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection.,CoRR,2024,"Qiannan Wang, Changchun Yin, Liming Fang 0001, Lu Zhou 0002, Zhe Liu 0001, Run Wang, Chenhao Lin",abs/2401.00137,https://doi.org/10.48550/arXiv.2401.00137
Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs.,CoRR,2024,"Jane Downer, Ren Wang, Binghui Wang",abs/2403.18136,https://doi.org/10.48550/arXiv.2403.18136
Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices.,CoRR,2024,"Hanqing Fu, Gaolei Li, Jun Wu 0001, Jianhua Li 0001, Xi Lin 0003, Kai Zhou 0001, Yuchen Liu",abs/2403.18607,https://doi.org/10.48550/arXiv.2403.18607
Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack.,CoRR,2024,"Ruofei Wang, Renjie Wan, Zongyu Guo, Qing Guo, Rui Huang",abs/2401.02031,https://doi.org/10.48550/arXiv.2401.02031
Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models.,CoRR,2024,"Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu",abs/2402.18945,https://doi.org/10.48550/arXiv.2402.18945
TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks.,CoRR,2024,"Khondoker Murad Hossain, Tim Oates 0001",abs/2401.05432,https://doi.org/10.48550/arXiv.2401.05432
Task-Agnostic Detector for Insertion-Based Backdoor Attacks.,CoRR,2024,"Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang 0006, Haibin Ling, Susmit Jha, Chao Chen",abs/2403.17155,https://doi.org/10.48550/arXiv.2403.17155
Test-Time Backdoor Attacks on Multimodal Large Language Models.,CoRR,2024,"Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin",abs/2402.08577,https://doi.org/10.48550/arXiv.2402.08577
The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers.,CoRR,2024,,abs/2401.01537,https://doi.org/10.48550/arXiv.2401.01537
"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline.",CoRR,2024,"Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, Kenji Kawaguchi",abs/2401.04136,https://doi.org/10.48550/arXiv.2401.04136
The last Dance : Robust backdoor attack via diffusion models and bayesian approach.,CoRR,2024,,abs/2402.05967,https://doi.org/10.48550/arXiv.2402.05967
Time-Distributed Backdoor Attacks on Federated Spiking Learning.,CoRR,2024,"Gorka Abad, Stjepan Picek, Aitor Urbieta",abs/2402.02886,https://doi.org/10.48550/arXiv.2402.02886
TransTroj: Transferable Backdoor Attacks to Pre-trained Models via Embedding Indistinguishability.,CoRR,2024,"Hao Wang, Tao Xiang 0001, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang 0004",abs/2401.15883,https://doi.org/10.48550/arXiv.2401.15883
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models.,CoRR,2024,"Zihan Guan 0001, Mengxuan Hu, Sheng Li 0001, Anil Vullikanti",abs/2404.01101,https://doi.org/10.48550/arXiv.2404.01101
Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks.,CoRR,2024,"Xi Li, Hang Wang, David J. Miller 0001, George Kesidis",abs/2402.02034,https://doi.org/10.48550/arXiv.2402.02034
Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks.,CoRR,2024,"Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Jinming Wen",abs/2401.05949,https://doi.org/10.48550/arXiv.2401.05949
Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal Contrastive Learning via Local Token Unlearning.,CoRR,2024,"Siyuan Liang, Kuanrong Liu, Jiajun Gong, Jiawei Liang, Yuan Xun, Ee-Chien Chang, Xiaochun Cao",abs/2403.16257,https://doi.org/10.48550/arXiv.2403.16257
VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models.,CoRR,2024,"Jiawei Liang, Siyuan Liang, Man Luo, Aishan Liu, Dongchen Han, Ee-Chien Chang, Xiaochun Cao",abs/2402.13851,https://doi.org/10.48550/arXiv.2402.13851
WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection.,CoRR,2024,"Anudeex Shetty, Yue Teng, Ke He, Qiongkai Xu",abs/2403.01472,https://doi.org/10.48550/arXiv.2403.01472
WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition.,CoRR,2024,"Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu",abs/2401.13578,https://doi.org/10.48550/arXiv.2401.13578
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents.,CoRR,2024,"Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun",abs/2402.11208,https://doi.org/10.48550/arXiv.2402.11208
Federated learning backdoor attack detection with persistence diagram.,Comput. Secur.,2024,"Zihan Ma, Tianchong Gao",136,https://doi.org/10.1016/j.cose.2023.103557
SGBA: A stealthy scapegoat backdoor attack against deep neural networks.,Comput. Secur.,2024,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong 0002",136,https://doi.org/10.1016/j.cose.2023.103523
Universal adversarial backdoor attacks to fool vertical federated learning.,Comput. Secur.,2024,"Peng Chen, Xin Du, Zhihui Lu 0002, Hongfeng Chai",137,https://doi.org/10.1016/j.cose.2023.103601
"Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions.",Eng. Appl. Artif. Intell.,2024,"Thuy Dung Nguyen, Tuan Nguyen, Phi Le Nguyen, Hieu H. Pham 0001, Khoa D. Doan, Kok-Seng Wong",127,https://doi.org/10.1016/j.engappai.2023.107166
Highly-Effective Backdoors for Hash Functions and Beyond.,IACR Cryptol. ePrint Arch.,2024,"Mihir Bellare, Doreen Riepel, Laura Shea",2024,https://eprint.iacr.org/2024/536
Defense Method Challenges Against Backdoor Attacks in Neural Networks.,ICAIIC,2024,"Samaneh Shamshiri, Insoo Sohn",,https://doi.org/10.1109/ICAIIC60209.2024.10463411
Detecting Backdoors Embedded in Ensembles.,ICEIC,2024,"SeokHee Kim, Changhee Hahn",,https://doi.org/10.1109/ICEIC61013.2024.10457185
Gradient-Based Clean Label Backdoor Attack to Graph Neural Networks.,ICISSP,2024,"Ryo Meguro, Hiroya Kato, Shintaro Narisada, Seira Hidano, Kazuhide Fukushima, Takuo Suganuma, Masahiro Hiji",,https://doi.org/10.5220/0012369500003648
A Comprehensive Survey on Backdoor Attacks and Their Defenses in Face Recognition Systems.,IEEE Access,2024,"Quentin Le Roux, Eric Bourbao, Yannick Teglia, Kassem Kallas",12,https://doi.org/10.1109/ACCESS.2024.3382584
"Backdoor Attacks to Deep Neural Networks: A Survey of the Literature, Challenges, and Future Research Directions.",IEEE Access,2024,"Orson Mengara, Anderson R. Avila, Tiago H. Falk",12,https://doi.org/10.1109/ACCESS.2024.3355816
Defending Against Backdoor Attacks by Quarantine Training.,IEEE Access,2024,"Chengxu Yu, Yulai Zhang",12,https://doi.org/10.1109/ACCESS.2024.3354385
Effective Backdoor Attack on Graph Neural Networks in Spectral Domain.,IEEE Internet Things J.,2024,"Xiangyu Zhao, Hanzhou Wu, Xinpeng Zhang 0001",11,https://doi.org/10.1109/JIOT.2023.3332848
Enrollment-Stage Backdoor Attacks on Speaker Recognition Systems via Adversarial Ultrasound.,IEEE Internet Things J.,2024,"Xinfeng Li, Junning Ze, Chen Yan 0001, Yushi Cheng, Xiaoyu Ji 0001, Wenyuan Xu 0001",11,https://doi.org/10.1109/JIOT.2023.3328253
MITDBA: Mitigating Dynamic Backdoor Attacks in Federated Learning for IoT Applications.,IEEE Internet Things J.,2024,"Yongkang Wang, Di-Hua Zhai, Dongyu Han, Yuyin Guan, Yuanqing Xia",11,https://doi.org/10.1109/JIOT.2023.3325634
A Spatiotemporal Backdoor Attack Against Behavior-Oriented Decision Makers in Metaverse: From Perspective of Autonomous Driving.,IEEE J. Sel. Areas Commun.,2024,"Yinbo Yu, Jiajia Liu 0001, Hongzhi Guo, Bomin Mao, Nei Kato",42,https://doi.org/10.1109/JSAC.2023.3345379
Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection.,IEEE Trans. Comput. Soc. Syst.,2024,"Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen",11,https://doi.org/10.1109/TCSS.2023.3260833
Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs.,IEEE Trans. Comput. Soc. Syst.,2024,"Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang",11,https://doi.org/10.1109/TCSS.2023.3267094
"Incremental Learning, Incremental Backdoor Threats.",IEEE Trans. Dependable Secur. Comput.,2024,"Wenbo Jiang, Tianwei Zhang 0004, Han Qiu 0001, Hongwei Li 0001, Guowen Xu",21,https://doi.org/10.1109/TDSC.2022.3201234
BadCM: Invisible Backdoor Attack Against Cross-Modal Learning.,IEEE Trans. Image Process.,2024,"Zheng Zhang 0006, Xu Yuan 0007, Lei Zhu 0002, Jingkuan Song, Liqiang Nie",33,https://doi.org/10.1109/TIP.2024.3378918
PerVK: A Robust Personalized Federated Framework to Defend Against Backdoor Attacks for IoT Applications.,IEEE Trans. Ind. Informatics,2024,"Yongkang Wang, Di-Hua Zhai, Yuanqing Xia, Danyang Liu",20,https://doi.org/10.1109/TII.2023.3329688
Untargeted Backdoor Attack Against Deep Neural Networks With Imperceptible Trigger.,IEEE Trans. Ind. Informatics,2024,"Mingfu Xue, Yinghao Wu, Shifeng Ni, Leo Yu Zhang, Yushu Zhang, Weiqiang Liu 0001",20,https://doi.org/10.1109/TII.2023.3329641
Backdoor Attack Against Split Neural Network-Based Vertical Federated Learning.,IEEE Trans. Inf. Forensics Secur.,2024,"Ying He, Zhili Shen, Jingyu Hua, Qixuan Dong, Jiacheng Niu, Wei Tong, Xu Huang, Chen Li, Sheng Zhong 0002",19,https://doi.org/10.1109/TIFS.2023.3327853
Backdoor Attack on Deep Learning-Based Medical Image Encryption and Decryption Network.,IEEE Trans. Inf. Forensics Secur.,2024,"Yi Ding 0003, Zi Wang, Zhen Qin 0002, Erqiang Zhou, Guobin Zhu, Zhiguang Qin, Kim-Kwang Raymond Choo",19,https://doi.org/10.1109/TIFS.2023.3322315
Imperceptible and Robust Backdoor Attack in 3D Point Cloud.,IEEE Trans. Inf. Forensics Secur.,2024,"Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia",19,https://doi.org/10.1109/TIFS.2023.3333687
Invisible Backdoor Attack With Dynamic Triggers Against Person Re-Identification.,IEEE Trans. Inf. Forensics Secur.,2024,"Wenli Sun, Xinyang Jiang, Shuguang Dou, Dongsheng Li 0002, Duoqian Miao, Cheng Deng, Cairong Zhao",19,https://doi.org/10.1109/TIFS.2023.3322659
MBA: Backdoor Attacks Against 3D Mesh Classifier.,IEEE Trans. Inf. Forensics Secur.,2024,"Linkun Fan, Fazhi He, Tongzhen Si, Rubin Fan, Chuanlong Ye, Bing Li 0010",19,https://doi.org/10.1109/TIFS.2023.3346644
NTD: Non-Transferability Enabled Deep Learning Backdoor Detection.,IEEE Trans. Inf. Forensics Secur.,2024,"Yinshan Li, Hua Ma, Zhi Zhang 0001, Yansong Gao, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",19,https://doi.org/10.1109/TIFS.2023.3312973
On Model Outsourcing Adaptive Attacks to Deep Learning Backdoor Defenses.,IEEE Trans. Inf. Forensics Secur.,2024,"Huaibing Peng, Huming Qiu, Hua Ma, Shuo Wang, Anmin Fu, Said F. Al-Sarawi, Derek Abbott, Yansong Gao",19,https://doi.org/10.1109/TIFS.2024.3349869
Privacy-Enhancing and Robust Backdoor Defense for Federated Learning on Heterogeneous Data.,IEEE Trans. Inf. Forensics Secur.,2024,"Zekai Chen, Shengxing Yu, Mingyuan Fan, Ximeng Liu, Robert H. Deng",19,https://doi.org/10.1109/TIFS.2023.3326983
Toward a Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures.,IEEE Trans. Inf. Forensics Secur.,2024,"Huming Qiu, Hua Ma, Zhi Zhang 0001, Alsharif Abuadbba, Wei Kang 0004, Anmin Fu, Yansong Gao",19,https://doi.org/10.1109/TIFS.2023.3324318
Universal Detection of Backdoor Attacks via Density-Based Clustering and Centroids Analysis.,IEEE Trans. Inf. Forensics Secur.,2024,"Wei Guo 0012, Benedetta Tondi, Mauro Barni",19,https://doi.org/10.1109/TIFS.2023.3329426
Verifying in the Dark: Verifiable Machine Unlearning by Using Invisible Backdoor Triggers.,IEEE Trans. Inf. Forensics Secur.,2024,"Yu Guo 0003, Yu Zhao, Saihui Hou, Cong Wang 0001, Xiaohua Jia",19,https://doi.org/10.1109/TIFS.2023.3328269
Dyn-Backdoor: Backdoor Attack on Dynamic Link Prediction.,IEEE Trans. Netw. Sci. Eng.,2024,"Jinyin Chen, Haiyang Xiong, Haibin Zheng, Jian Zhang 0023, Yi Liu 0024",11,https://doi.org/10.1109/TNSE.2023.3301673
Backdoor Learning: A Survey.,IEEE Trans. Neural Networks Learn. Syst.,2024,"Yiming Li 0004, Yong Jiang 0001, Zhifeng Li 0001, Shu-Tao Xia",35,https://doi.org/10.1109/TNNLS.2022.3182979
Critical Path-Based Backdoor Detection for Deep Neural Networks.,IEEE Trans. Neural Networks Learn. Syst.,2024,"Wei Jiang 0016, Xiangyu Wen, Jinyu Zhan, Xupeng Wang, Ziwei Song, Chen Bian",35,https://doi.org/10.1109/TNNLS.2022.3201586
Stealthy Backdoor Attack for Code Models.,IEEE Trans. Software Eng.,2024,"Zhou Yang 0003, Bowen Xu, Jie M. Zhang, Hong Jin Kang, Jieke Shi, Junda He, David Lo 0001",50,https://doi.org/10.1109/TSE.2024.3361661
Backdoor Attacks on Graph Neural Networks Trained with Data Augmentation.,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2024,"Shingo Yashiki, Chako Takahashi, Koutarou Suzuki",107,https://doi.org/10.1587/transfun.2023cil0007
NLPSweep: A comprehensive defense scheme for mitigating NLP backdoor attacks.,Inf. Sci.,2024,"Tao Xiang 0001, Fei Ouyang, Di Zhang, Chunlong Xie, Hao Wang 0003",661,https://doi.org/10.1016/j.ins.2024.120176
The reality of backdoored S-Boxes - An eye opener.,J. Inf. Secur. Appl.,2024,"Shah Fahd, Mehreen Afzal, Waseem Iqbal 0001, Dawood Shah, Ijaz Khalid",80,https://doi.org/10.1016/j.jisa.2023.103674
TridentShell: An enhanced covert and scalable backdoor injection attack on web applications.,J. Netw. Comput. Appl.,2024,"Xiaobo Yu, Weizhi Meng 0001, Yi-Ning Liu 0002, Fei Zhou",223,https://doi.org/10.1016/j.jnca.2023.103823
Detection of backdoor attacks using targeted universal adversarial perturbations for deep neural networks.,J. Syst. Softw.,2024,"Yubin Qu, Song Huang, Xiang Chen 0005, Xingya Wang, Yongming Yao",207,https://doi.org/10.1016/j.jss.2023.111859
Invisible backdoor learning in regional transform domain.,Neural Comput. Appl.,2024,"Yuyuan Sun, Yuliang Lu, Xuehu Yan, Xuan Wang",36,https://doi.org/10.1007/s00521-024-09506-3
Enhanced Coalescence Backdoor Attack Against DNN Based on Pixel Gradient.,Neural Process. Lett.,2024,"Jianyao Yin, Honglong Chen, Junjian Li, Yudong Gao",56,https://doi.org/10.1007/s11063-024-11469-4
"Backdoor advertising scandals, Yingyeo culture, and cancel culture among YouTube Influencers in South Korea.",New Media Soc.,2024,"Jin Lee, Crystal Abidin",26,https://doi.org/10.1177/14614448211061829
Backdoor Attack Against One-Class Sequential Anomaly Detection Models.,PAKDD,2024,"He Cheng, Shuhan Yuan",,https://doi.org/10.1007/978-981-97-2259-4_20
Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning.,PAKDD,2024,"Xi Li, Chen Wu, Jiaqi Wang",,https://doi.org/10.1007/978-981-97-2259-4_13
SilentTrig: An imperceptible backdoor attack against speaker identification with hidden triggers.,Pattern Recognit. Lett.,2024,"Yu Tang, Lijuan Sun, Xiaolong Xu 0002",177,https://doi.org/10.1016/j.patrec.2023.12.002
On the Possibility of a Backdoor in the Micali-Schnorr Generator.,Public Key Cryptography,2024,"Hannah Davis, Matthew D. Green, Nadia Heninger, Keegan Ryan, Adam Suhl",,https://doi.org/10.1007/978-3-031-57718-5_12
A Closer Look at Robustness of Vision Transformers to Backdoor Attacks.,WACV,2024,"Akshayvarun Subramanya, Soroush Abbasi Koohpayegani, Aniruddha Saha, Ajinkya Tejankar, Hamed Pirsiavash",,https://doi.org/10.1109/WACV57701.2024.00383
Towards a Robust Defense: A Multifaceted Approach to the Detection and Mitigation of Neural Backdoor Attacks through Feature Space Exploration and Analysis.,,2023,,,https://digitalcommons.odu.edu/ece_etds/254
Defending Backdoor Attacks on Vision Transformer via Patch Processing.,AAAI,2023,"Khoa D. Doan, Yingjie Lao, Peng Yang 0013, Ping Li 0001",,https://doi.org/10.1609/aaai.v37i1.25125
Defending against Backdoor Attacks in Natural Language Generation.,AAAI,2023,"Xiaofei Sun, Xiaoya Li, Yuxian Meng, Xiang Ao 0001, Lingjuan Lyu, Jiwei Li 0001, Tianwei Zhang 0004",,https://doi.org/10.1609/aaai.v37i4.25656
On the Vulnerability of Backdoor Defenses for Federated Learning.,AAAI,2023,"Pei Fang, Jinghui Chen",,https://doi.org/10.1609/aaai.v37i10.26393
Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning.,AAAI,2023,"Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Bin Wang, Jiqiang Liu, Xiangliang Zhang 0001",,https://doi.org/10.1609/aaai.v37i7.26083
Poisoning-Based Backdoor Attacks in Computer Vision.,AAAI,2023,,,https://doi.org/10.1609/aaai.v37i13.26921
Probabilistic Generalization of Backdoor Trees with Application to SAT.,AAAI,2023,"Alexander A. Semenov, Daniil Chivilikhin, Stepan Kochemazov, Ibragim Dzhiblavi",,https://doi.org/10.1609/aaai.v37i4.25525
A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning.,ACL,2023,"Naibin Gu, Peng Fu 0008, Xiyu Liu 0003, Zhengxiao Liu, Zheng Lin 0001, Weiping Wang 0005",,https://doi.org/10.18653/v1/2023.acl-long.194
Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark.,ACL,2023,"Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu 0001, Guangzhong Sun, Xing Xie 0001",,https://doi.org/10.18653/v1/2023.acl-long.423
BITE: Textual Backdoor Attacks with Iterative Trigger Injection.,ACL,2023,"Jun Yan 0012, Vansh Gupta, Xiang Ren 0001",,https://doi.org/10.18653/v1/2023.acl-long.725
Backdooring Neural Code Search.,ACL,2023,"Weisong Sun, Yuchen Chen, Guanhong Tao 0001, Chunrong Fang, Xiangyu Zhang 0001, Quanjun Zhang, Bin Luo 0003",,https://doi.org/10.18653/v1/2023.acl-long.540
Defending against Insertion-based Textual Backdoor Attacks via Attribution.,ACL,2023,"Jiazhao Li, Zhuofeng Wu 0001, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran",,https://doi.org/10.18653/v1/2023.findings-acl.561
Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias.,ACL,2023,"Zhiyuan Zhang 0001, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou 0016, Xu Sun 0001",,https://doi.org/10.18653/v1/2023.findings-acl.157
"Maximum Entropy Loss, the Silver Bullet Targeting Backdoor Attacks in Pre-trained Language Models.",ACL,2023,"Zhengxiao Liu, Bowen Shen, Zheng Lin, Fali Wang, Weiping Wang",,https://doi.org/10.18653/v1/2023.findings-acl.237
Multi-target Backdoor Attacks for Code Pre-trained Models.,ACL,2023,"Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang 0004, Yang Liu 0003",,https://doi.org/10.18653/v1/2023.acl-long.399
NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models.,ACL,2023,"Kai Mei, Zheng Li 0023, Zhenting Wang, Yang Zhang 0016, Shiqing Ma",,https://doi.org/10.18653/v1/2023.acl-long.867
ACQ: Few-shot Backdoor Defense via Activation Clipping and Quantizing.,ACM Multimedia,2023,"Yulin Jin, Xiaoyu Zhang, Jian Lou 0001, Xiaofeng Chen 0001",,https://doi.org/10.1145/3581783.3612410
Model-Contrastive Learning for Backdoor Elimination.,ACM Multimedia,2023,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu 0003, Ting Wang 0001, Xian Wei, Mingsong Chen",,https://doi.org/10.1145/3581783.3612415
Moiré Backdoor Attack (MBA): A Novel Trigger for Pedestrian Detectors in the Physical World.,ACM Multimedia,2023,"Hui Wei 0004, Hanxun Yu, Kewei Zhang, Zhixiang Wang, Jianke Zhu, Zheng Wang 0007",,https://doi.org/10.1145/3581783.3611910
PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification.,ACM Multimedia,2023,"Yizhen Yuan, Rui Kong, Shenghao Xie, Yuanchun Li, Yunxin Liu",,https://doi.org/10.1145/3581783.3612032
Physical Invisible Backdoor Based on Camera Imaging.,ACM Multimedia,2023,"Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang 0001",,https://doi.org/10.1145/3581783.3612476
PointCRT: Detecting Backdoor in 3D Point Cloud via Corruption Robustness.,ACM Multimedia,2023,"Shengshan Hu, Wei Liu, Minghui Li, Yechao Zhang, Xiaogeng Liu, Xianlong Wang, Leo Yu Zhang, Junhui Hou",,https://doi.org/10.1145/3581783.3612456
Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning.,ACM Multimedia,2023,"Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su 0006",,https://doi.org/10.1145/3581783.3612108
The Silent Manipulator: A Practical and Inaudible Backdoor Attack against Speech Recognition Systems.,ACM Multimedia,2023,"Zhicong Zheng, Xinfeng Li, Chen Yan 0001, Xiaoyu Ji 0001, Wenyuan Xu 0001",,https://doi.org/10.1145/3581783.3613843
Exploiting a Benign Loudspeaker as Magnetic Backdoor for Practical Injection Attacks.,ACM TUR-C,2023,"Tiantian Liu 0002, Feng Lin 0004",,https://doi.org/10.1145/3603165.3607443
B3: Backdoor Attacks against Black-box Machine Learning Models.,ACM Trans. Priv. Secur.,2023,"Xueluan Gong, Yanjiao Chen, Wenbin Yang, Huayang Huang, Qian Wang 0002",26,https://doi.org/10.1145/3605212
Pied-Piper: Revealing the Backdoor Threats in Ethereum ERC Token Contracts.,ACM Trans. Softw. Eng. Methodol.,2023,"Fuchen Ma, Meng Ren, Lerong Ouyang, Yuanliang Chen, Juan Zhu, Ting Chen 0002, Yingli Zheng, Xiao Dai, Yu Jiang 0001, Jiaguang Sun 0001",32,https://doi.org/10.1145/3560264
FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks.,ACSAC,2023,"Jorge Castillo, Phillip Rieger, Hossein Fereidooni, Qian Chen 0019, Ahmad-Reza Sadeghi",,https://doi.org/10.1145/3627106.3627194
DFaP: Data Filtering and Purification Against Backdoor Attacks.,AIS&amp;P,2023,"Haochen Wang, Tianshi Mu, Guocong Feng, ShangBo Wu, Yuanzhang Li",,https://doi.org/10.1007/978-981-99-9785-5_7
SSL-ABD : An Adversarial Defense Method Against Backdoor Attacks in Self-supervised Learning.,AIS&amp;P,2023,"Hui Yang, Ruilin Yang, Heqiu Cai, Xiao Zhang, Qingqi Pei, Shaowei Wang, Hongyang Yan",,https://doi.org/10.1007/978-981-99-9785-5_32
PerCBA: Persistent Clean-label Backdoor Attacks on Semi-Supervised Graph Node Classification.,AISafety/SafeRL@IJCAI,2023,"Xiao Yang, Gaolei Li, Chaofeng Zhang, Meng Han, Wu Yang",,https://ceur-ws.org/Vol-3505/paper_4.pdf
Lookin&apos; Out My Backdoor! Investigating Backdooring Attacks Against DL-driven Malware Detectors.,AISec@CCS,2023,"Mario D&apos;Onghia, Federico Di Cesare, Luigi Gallo, Michele Carminati, Mario Polino, Stefano Zanero",,https://doi.org/10.1145/3605764.3623919
Identifying Backdoor Attacks in Federated Learning via Anomaly Detection.,APWeb/WAIM,2023,"Yuxi Mi, Yiheng Sun, Jihong Guan, Shuigeng Zhou",,https://doi.org/10.1007/978-981-97-2387-4_8
Joint Energy-Based Model for Robust Speech Classification System Against Dirty-Label Backdoor Poisoning Attacks.,ASRU,2023,"Martin Sustek, Sonal Joshi, Henry Li, Thomas Thebaud, Jesús Villalba 0001, Sanjeev Khudanpur, Najim Dehak",,https://doi.org/10.1109/ASRU57964.2023.10389697
Compression-resistant backdoor attack against deep neural networks.,Appl. Intell.,2023,"Mingfu Xue, Xin Wang, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu 0001",53,https://doi.org/10.1007/s10489-023-04575-8
Universal backdoor attack on deep neural networks for malware detection.,Appl. Soft Comput.,2023,"Yunchun Zhang, Fan Feng, Zikun Liao, Zixuan Li, Shaowen Yao 0001",143,https://doi.org/10.1016/j.asoc.2023.110389
CASSOCK: Viable Backdoor Attacks against DNN in the Wall of Source-Specific Backdoor Defenses.,AsiaCCS,2023,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang 0001, Yuqing Zhang 0001, Willy Susilo, Dongxi Liu",,https://doi.org/10.1145/3579856.3582829
DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation.,AsiaCCS,2023,"Zhicong Yan, Shenghong Li 0001, Ruijie Zhao 0001, Yuan Tian 0017, Yuanyuan Zhao",,https://doi.org/10.1145/3579856.3582822
SolScope: Effectively Hunting Potential Permission Backdoor Threats in Smart Contracts.,BIGCOM,2023,"Renjie Ji, Wansen Wang, Yan Xiong, Wenchao Huang",,https://doi.org/10.1109/BIGCOM61073.2023.00020
Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning.,BMVC,2023,"Kuofeng Gao, Jiawang Bai, Bin Chen 0011, Dongxian Wu, Shu-Tao Xia",,http://proceedings.bmvc2023.org/172/
Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information.,CCS,2023,"Yi Zeng 0005, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia 0001",,https://doi.org/10.1145/3576915.3616617
Poster: Backdoor Attack on Extreme Learning Machines.,CCS,2023,"Behrad Tajalli, Gorka Abad, Stjepan Picek",,https://doi.org/10.1145/3576915.3624369
Poster: Fooling XAI with Explanation-Aware Backdoors.,CCS,2023,"Maximilian Noppel, Christian Wressnegger",,https://doi.org/10.1145/3576915.3624379
Poster: Multi-target &amp; Multi-trigger Backdoor Attacks on Graph Neural Networks.,CCS,2023,"Jing Xu, Stjepan Picek",,https://doi.org/10.1145/3576915.3624387
Physical Backdoor Trigger Activation of Autonomous Vehicle Using Reachability Analysis.,CDC,2023,"Wenqing Li, Yue Wang 0055, Muhammad Shafique 0001, Saif Eddin Jabari",,https://doi.org/10.1109/CDC49753.2023.10383622
Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks.,CIKM,2023,"Zihan Guan 0001, Lichao Sun 0001, Mengnan Du, Ninghao Liu",,https://doi.org/10.1145/3583780.3614784
Vulnerabilities of Deep Learning-Driven Semantic Communications to Backdoor (Trojan) Attacks.,CISS,2023,"Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus, Aylin Yener",,https://doi.org/10.1109/CISS56502.2023.10089692
Detecting Backdoors in Collaboration Graphs of Software Repositories.,CODASPY,2023,"Tom Ganz, Inaam Ashraf, Martin Härterich, Konrad Rieck",,https://doi.org/10.1145/3577923.3583657
PerDoor: Persistent Backdoors in Federated Learning using Adversarial Perturbations.,COINS,2023,"Manaar Alam, Esha Sarkar, Michail Maniatakos",,https://doi.org/10.1109/COINS57856.2023.10189281
Blind Concealment from Reconstruction-based Attack Detectors for Industrial Control Systems via Backdoor Attacks.,CPSS@AsiaCCS,2023,"Tim Walita, Alessandro Erba 0001, John Henry Castellanos, Nils Ole Tippenhauer",,https://doi.org/10.1145/3592538.3594271
Architectural Backdoors in Neural Networks.,CVPR,2023,"Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot",,https://doi.org/10.1109/CVPR52729.2023.02356
Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger.,CVPR,2023,"Yi Yu, Yufei Wang, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot",,https://doi.org/10.1109/CVPR52729.2023.01179
Backdoor Cleansing with Unlabeled Data.,CVPR,2023,"Lu Pang 0006, Tao Sun 0009, Haibin Ling, Chao Chen 0012",,https://doi.org/10.1109/CVPR52729.2023.01176
Backdoor Defense via Adaptively Splitting Poisoned Dataset.,CVPR,2023,"Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia",,https://doi.org/10.1109/CVPR52729.2023.00390
Backdoor Defense via Deconfounded Representation Learning.,CVPR,2023,"Zaixi Zhang, Qi Liu 0003, Zhicai Wang, Zepu Lu, Qingyong Hu",,https://doi.org/10.1109/CVPR52729.2023.01177
Color Backdoor: A Robust Poisoning Attack in Color Space.,CVPR,2023,"Wenbo Jiang, Hongwei Li 0001, Guowen Xu, Tianwei Zhang 0004",,https://doi.org/10.1109/CVPR52729.2023.00786
Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning.,CVPR,2023,"Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan",,https://doi.org/10.1109/CVPR52729.2023.01178
Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency.,CVPR,2023,"Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin 0001, Libing Wu, Chaowei Xiao",,https://doi.org/10.1109/CVPR52729.2023.01570
Detecting Backdoors in Pre-trained Encoders.,CVPR,2023,"Shiwei Feng 0002, Guanhong Tao 0001, Siyuan Cheng 0005, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang 0002, Shiqing Ma, Xiangyu Zhang 0001",,https://doi.org/10.1109/CVPR52729.2023.01569
How to Backdoor Diffusion Models?,CVPR,2023,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",,https://doi.org/10.1109/CVPR52729.2023.00391
MEDIC: Remove Model Backdoors via Importance Driven Cloning.,CVPR,2023,"Qiuling Xu, Guanhong Tao 0001, Jean Honorio, Yingqi Liu, Shengwei An, Guangyu Shen, Siyuan Cheng 0005, Xiangyu Zhang 0001",,https://doi.org/10.1109/CVPR52729.2023.01962
Progressive Backdoor Erasing via connecting Backdoor and Adversarial Attacks.,CVPR,2023,"Bingxu Mu, Zhenxing Niu, Le Wang 0003, Xue Wang, Qiguang Mia, Rong Jin, Gang Hua 0001",,https://doi.org/10.1109/CVPR52729.2023.01963
Single Image Backdoor Inversion via Robust Smoothed Classifiers.,CVPR,2023,"Mingjie Sun, Zico Kolter",,https://doi.org/10.1109/CVPR52729.2023.00784
The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection.,CVPR,2023,"Simin Chen, Hanlin Chen, Mirazul Haque, Cong Liu 0005, Wei Yang 0013",,https://doi.org/10.1109/CVPR52729.2023.02355
You Are Catching My Attention: Are Vision Transformers Bad Learners under Backdoor Attacks?,CVPR,2023,"Zenghui Yuan, Pan Zhou, Kai Zou, Yu Cheng 0001",,https://doi.org/10.1109/CVPR52729.2023.02357
Don&apos;t FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs.,CVPR Workshops,2023,"Hasan Abed Al Kader Hammoud, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",,https://doi.org/10.1109/CVPRW59228.2023.00230
A Comprehensive Overview of Backdoor Attacks in Large Language Models within Communication Networks.,CoRR,2023,"Haomiao Yang, Kunlan Xiang, Hongwei Li 0001, Rongxing Lu",abs/2308.14367,https://doi.org/10.48550/arXiv.2308.14367
A Proxy-Free Strategy for Practically Improving the Poisoning Efficiency in Backdoor Attacks.,CoRR,2023,"Ziqiang Li 0001, Hong Sun, Pengfei Xia, Beihao Xia, Xue Rui, Wei Zhang, Bin Li 0025",abs/2306.08313,https://doi.org/10.48550/arXiv.2306.08313
A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification.,CoRR,2023,"Gorka Abad, Jing Xu, Stefanos Koffas, Behrad Tajalli, Stjepan Picek",abs/2302.01740,https://doi.org/10.48550/arXiv.2302.01740
A Universal Identity Backdoor Attack against Speaker Verification based on Siamese Network.,CoRR,2023,"Haodong Zhao, Wei Du, Junjie Guo, Gongshen Liu",abs/2303.16031,https://doi.org/10.48550/arXiv.2303.16031
A semantic backdoor attack against Graph Convolutional Networks.,CoRR,2023,"Jiazhu Dai, Zhipeng Xiong",abs/2302.14353,https://doi.org/10.48550/arXiv.2302.14353
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks.,CoRR,2023,"Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu",abs/2312.06230,https://doi.org/10.48550/arXiv.2312.06230
"Adversarial Machine Learning: A Systematic Survey of Backdoor Attack, Weight Attack and Adversarial Example.",CoRR,2023,"Baoyuan Wu, Li Liu, Zihao Zhu, Qingshan Liu, Zhaofeng He, Siwei Lyu",abs/2302.09457,https://doi.org/10.48550/arXiv.2302.09457
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning.,CoRR,2023,"Taejin Kim, Jiarui Li, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",abs/2310.11594,https://doi.org/10.48550/arXiv.2310.11594
Analyzing And Editing Inner Mechanisms Of Backdoored Language Models.,CoRR,2023,"Max Lamparth, Anka Reuel",abs/2302.12461,https://doi.org/10.48550/arXiv.2302.12461
BAGEL: Backdoor Attacks against Federated Contrastive Learning.,CoRR,2023,"Yao Huang, Kongyang Chen, Jiannong Cao 0001, Jiaxing Shen, Shaowei Wang 0003, Yun Peng, Weilong Peng, Kechao Cai",abs/2311.16113,https://doi.org/10.48550/arXiv.2311.16113
BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models.,CoRR,2023,"Jordan Vice, Naveed Akhtar, Richard Hartley 0001, Ajmal Mian",abs/2307.16489,https://doi.org/10.48550/arXiv.2307.16489
BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing.,CoRR,2023,"Jiali Wei, Ming Fan 0002, Wenjing Jiao, Wuxia Jin, Ting Liu 0002",abs/2301.10412,https://doi.org/10.48550/arXiv.2301.10412
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.,CoRR,2023,"Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang",abs/2312.04902,https://doi.org/10.48550/arXiv.2312.04902
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection.,CoRR,2023,"Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal",abs/2308.12439,https://doi.org/10.48550/arXiv.2308.12439
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment.,CoRR,2023,"Haoran Wang, Kai Shu",abs/2311.09433,https://doi.org/10.48550/arXiv.2311.09433
Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes.,CoRR,2023,"Xiruo Ding, Zhecheng Sheng, Meliha Yetisgen, Serguei Pakhomov, Trevor Cohen",abs/2310.02451,https://doi.org/10.48550/arXiv.2310.02451
Backdoor Attack against Object Detection with Clean Annotation.,CoRR,2023,"Yize Cheng, Wenbin Hu, Minhao Cheng",abs/2307.10487,https://doi.org/10.48550/arXiv.2307.10487
Backdoor Attack through Machine Unlearning.,CoRR,2023,"Peixin Zhang, Jun Sun 0001, Mingtian Tan, Xinyu Wang",abs/2310.10659,https://doi.org/10.48550/arXiv.2310.10659
Backdoor Attack with Sparse and Invisible Trigger.,CoRR,2023,"Yinghua Gao, Yiming Li 0004, Xueluan Gong, Shu-Tao Xia, Qian Wang",abs/2306.06209,https://doi.org/10.48550/arXiv.2306.06209
Backdoor Attacks Against Incremental Learners: An Empirical Evaluation Study.,CoRR,2023,"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji",abs/2305.18384,https://doi.org/10.48550/arXiv.2305.18384
Backdoor Attacks against Voice Recognition Systems: A Survey.,CoRR,2023,"Baochen Yan, Jiahe Lan, Zheng Yan 0002",abs/2307.13643,https://doi.org/10.48550/arXiv.2307.13643
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review.,CoRR,2023,"Pengzhou Cheng, Zongru Wu, Wei Du, Haodong Zhao, Gongshen Liu",abs/2309.06055,https://doi.org/10.48550/arXiv.2309.06055
Backdoor Attacks for In-Context Learning with Language Models.,CoRR,2023,"Nikhil Kandpal, Matthew Jagielski, Florian Tramèr, Nicholas Carlini",abs/2307.14692,https://doi.org/10.48550/arXiv.2307.14692
Backdoor Attacks in Peer-to-Peer Federated Learning.,CoRR,2023,"Gökberk Yar, Cristina Nita-Rotaru, Alina Oprea",abs/2301.09732,https://doi.org/10.48550/arXiv.2301.09732
Backdoor Attacks to Pre-trained Unified Foundation Models.,CoRR,2023,"Zenghui Yuan, Yixin Liu, Kai Zhang 0039, Pan Zhou, Lichao Sun 0001",abs/2302.09360,https://doi.org/10.48550/arXiv.2302.09360
Backdoor Attacks with Input-unique Triggers in NLP.,CoRR,2023,"Xukun Zhou, Jiwei Li 0001, Tianwei Zhang 0004, Lingjuan Lyu, Muqiao Yang, Jun He",abs/2303.14325,https://doi.org/10.48550/arXiv.2303.14325
Backdoor Defense with Non-Adversarial Backdoor.,CoRR,2023,"Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue",abs/2307.15539,https://doi.org/10.48550/arXiv.2307.15539
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers.,CoRR,2023,"Haomin Zhuang, Mingxian Yu, Hao Wang 0022, Yang Hua, Jian Li 0008, Xu Yuan 0001",abs/2308.04466,https://doi.org/10.48550/arXiv.2308.04466
"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions.",CoRR,2023,,abs/2302.06801,https://doi.org/10.48550/arXiv.2302.06801
Backdoor Learning on Sequence to Sequence Models.,CoRR,2023,"Lichang Chen, Minhao Cheng, Heng Huang",abs/2305.02424,https://doi.org/10.48550/arXiv.2305.02424
Backdoor Mitigation by Correcting the Distribution of Neural Activations.,CoRR,2023,"Xi Li 0015, Zhen Xiang, David J. Miller 0001, George Kesidis",abs/2308.09850,https://doi.org/10.48550/arXiv.2308.09850
Backdoor Threats from Compromised Foundation Models to Federated Learning.,CoRR,2023,"Xi Li, Songhe Wang, Chen Wu, Hao Zhou, Jiaqi Wang 0002",abs/2311.00144,https://doi.org/10.48550/arXiv.2311.00144
Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based Artificial Bias.,CoRR,2023,"Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu",abs/2303.01504,https://doi.org/10.48550/arXiv.2303.01504
Backdoor to the Hidden Ground State: Planted Vertex Cover Example.,CoRR,2023,"Xin-Yi Fan, Hai-Jun Zhou",abs/2305.06610,https://doi.org/10.48550/arXiv.2305.06610
BackdoorBox: A Python Toolbox for Backdoor Learning.,CoRR,2023,"Yiming Li 0004, Mengxi Ya, Yang Bai, Yong Jiang 0001, Shu-Tao Xia",abs/2302.01762,https://doi.org/10.48550/arXiv.2302.01762
Backdooring Textual Inversion for Concept Censorship.,CoRR,2023,"Yutong Wu 0009, Jie Zhang, Florian Kerschbaum, Tianwei Zhang 0004",abs/2308.10718,https://doi.org/10.48550/arXiv.2308.10718
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning.,CoRR,2023,,abs/2311.12075,https://doi.org/10.48550/arXiv.2311.12075
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP.,CoRR,2023,"Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li 0001, Wei Liu",abs/2311.16194,https://doi.org/10.48550/arXiv.2311.16194
BadCS: A Backdoor Attack Framework for Code search.,CoRR,2023,"Shiyi Qi, Yuanhang Yang, Shuzheng Gao, Cuiyun Gao, Zenglin Xu",abs/2305.05503,https://doi.org/10.48550/arXiv.2305.05503
BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT.,CoRR,2023,"Jiawen Shi, Yixin Liu, Pan Zhou, Lichao Sun 0001",abs/2304.12298,https://doi.org/10.48550/arXiv.2304.12298
BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks.,CoRR,2023,"Zihan Guan 0001, Mengxuan Hu, Zhongliang Zhou, Jielu Zhang, Sheng Li 0001, Ninghao Liu",abs/2305.03289,https://doi.org/10.48550/arXiv.2305.03289
BadSQA: Stealthy Backdoor Attacks Using Presence Events as Triggers in Non-Intrusive Speech Quality Assessment.,CoRR,2023,"Ying Ren, Kailai Shen, Zhe Ye, Diqun Yan",abs/2309.01480,https://doi.org/10.48550/arXiv.2309.01480
BadVFL: Backdoor Attacks in Vertical Federated Learning.,CoRR,2023,"Mohammad Naseri, Yufei Han, Emiliano De Cristofaro",abs/2304.08847,https://doi.org/10.48550/arXiv.2304.08847
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks.,CoRR,2023,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",abs/2310.05862,https://doi.org/10.48550/arXiv.2310.05862
Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network.,CoRR,2023,"Fan Liu, Siqi Lai, Yansong Ning, Hao Liu 0026",abs/2306.10351,https://doi.org/10.48550/arXiv.2306.10351
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy.,CoRR,2023,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Li Shen 0008, Yanbo Fan, Baoyuan Wu",abs/2307.07328,https://doi.org/10.48550/arXiv.2307.07328
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger.,CoRR,2023,"Jiazhao Li, Yijin Yang, Zhuofeng Wu 0001, V. G. Vinod Vydiswaran, Chaowei Xiao",abs/2304.14475,https://doi.org/10.48550/arXiv.2304.14475
Composite Backdoor Attacks Against Large Language Models.,CoRR,2023,"Hai Huang, Zhengyu Zhao 0001, Michael Backes 0001, Yun Shen, Yang Zhang 0016",abs/2310.07676,https://doi.org/10.48550/arXiv.2310.07676
Confidence-driven Sampling for Backdoor Attacks.,CoRR,2023,"Pengfei He, Han Xu 0002, Yue Xing, Jie Ren, Yingqian Cui, Shenglai Zeng, Jiliang Tang, Makoto Yamada, Mohammad Sabokrou",abs/2310.05263,https://doi.org/10.48550/arXiv.2310.05263
DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning.,CoRR,2023,"Wenqiang Sun, Sen Li, Yuchang Sun 0001, Jun Zhang",abs/2305.01267,https://doi.org/10.48550/arXiv.2305.01267
"Data and Model Poisoning Backdoor Attacks on Wireless Federated Learning, and the Defense Mechanisms: A Comprehensive Survey.",CoRR,2023,"Yichen Wan, Youyang Qu, Wei Ni 0001, Yong Xiang 0001, Longxiang Gao, Ekram Hossain 0001",abs/2312.08667,https://doi.org/10.48550/arXiv.2312.08667
Defending Our Privacy With Backdoors.,CoRR,2023,"Dominik Hintersdorf, Lukas Struppek, Daniel Neider, Kristian Kersting",abs/2310.08320,https://doi.org/10.48550/arXiv.2310.08320
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective.,CoRR,2023,"Ganghua Wang, Xun Xian, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding 0002",abs/2310.10780,https://doi.org/10.48550/arXiv.2310.10780
Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking.,CoRR,2023,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang 0023, Xia Hu 0001",abs/2303.11470,https://doi.org/10.48550/arXiv.2303.11470
Do Backdoors Assist Membership Inference Attacks?,CoRR,2023,"Yumeki Goto, Nami Ashizawa, Toshiki Shibahara, Naoto Yanai",abs/2303.12589,https://doi.org/10.48550/arXiv.2303.12589
Does Differential Privacy Prevent Backdoor Attacks in Practice?,CoRR,2023,"Fereshteh Razmi, Jian Lou 0001, Li Xiong 0001",abs/2311.06227,https://doi.org/10.48550/arXiv.2311.06227
Effective Backdoor Mitigation Depends on the Pre-training Objective.,CoRR,2023,"Sahil Verma, Gantavya Bhatt, Avi Schwarzschild, Soumye Singhal, Arnav Mohanty Das, Chirag Shah, John P. Dickerson, Jeff A. Bilmes",abs/2311.14948,https://doi.org/10.48550/arXiv.2311.14948
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios.,CoRR,2023,"Hong Sun, Ziqiang Li 0001, Pengfei Xia, Heng Li 0008, Beihao Xia, Yi Wu 0018, Bin Li 0025",abs/2306.08386,https://doi.org/10.48550/arXiv.2306.08386
Efficient Backdoor Removal Through Natural Gradient Fine-tuning.,CoRR,2023,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Nazanin Rahnavard",abs/2306.17441,https://doi.org/10.48550/arXiv.2306.17441
Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking.,CoRR,2023,"Shengsheng Qian, Yifei Wang, Dizhan Xue, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu",abs/2312.07955,https://doi.org/10.48550/arXiv.2312.07955
Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack.,CoRR,2023,"Sze Jue Yang, Quang H. Nguyen, Chee Seng Chan, Khoa Doan",abs/2308.16684,https://doi.org/10.48550/arXiv.2308.16684
Evil from Within: Machine Learning Backdoors through Hardware Trojans.,CoRR,2023,"Alexander Warnecke, Julian Speith, Jan-Niklas Möller, Konrad Rieck, Christof Paar",abs/2304.08411,https://doi.org/10.48550/arXiv.2304.08411
Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks.,CoRR,2023,"Ziqiang Li 0001, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li",abs/2310.09744,https://doi.org/10.48550/arXiv.2310.09744
FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks.,CoRR,2023,"Dong Huang 0005, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui",abs/2307.11565,https://doi.org/10.48550/arXiv.2307.11565
FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning.,CoRR,2023,"Yanqi Qiao, Dazhuang Liu, Congwen Chen, Rui Wang 0070, Kaitai Liang",abs/2309.00127,https://doi.org/10.48550/arXiv.2309.00127
Fake the Real: Backdoor Attack on Deep Speech Classification via Voice Conversion.,CoRR,2023,"Zhe Ye, Terui Mao, Li Dong 0006, Diqun Yan",abs/2306.15875,https://doi.org/10.48550/arXiv.2306.15875
FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning Framework.,CoRR,2023,"Sheldon C. Ebron Jr., Kan Yang 0001",abs/2311.10248,https://doi.org/10.48550/arXiv.2311.10248
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge.,CoRR,2023,"Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan 0002, Elisa Bertino",abs/2312.09665,https://doi.org/10.48550/arXiv.2312.09665
From Shortcuts to Triggers: Backdoor Defense with Denoised PoE.,CoRR,2023,"Qin Liu, Fei Wang 0060, Chaowei Xiao, Muhao Chen",abs/2305.14910,https://doi.org/10.48550/arXiv.2305.14910
From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models.,CoRR,2023,"Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu 0001",abs/2311.02373,https://doi.org/10.48550/arXiv.2311.02373
G2uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering.,CoRR,2023,"Hao Yu, Chuan Ma, Meng Liu 0014, Xinwang Liu, Zhe Liu 0001, Ming Ding 0001",abs/2306.04984,https://doi.org/10.48550/arXiv.2306.04984
Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning.,CoRR,2023,"Manaar Alam, Hithem Lamri, Michail Maniatakos",abs/2304.10638,https://doi.org/10.48550/arXiv.2304.10638
GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning.,CoRR,2023,"Qiannan Wang, Changchun Yin, Zhe Liu 0001, Liming Fang 0001, Run Wang, Chenhao Lin",abs/2310.00626,https://doi.org/10.48550/arXiv.2310.00626
Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering.,CoRR,2023,"Rui Zhu, Di Tang, Siyuan Tang, Guanhong Tao 0001, Shiqing Ma, XiaoFeng Wang 0001, Haixu Tang",abs/2301.12318,https://doi.org/10.48550/arXiv.2301.12318
Hiding Backdoors within Event Sequence Data via Poisoning Attacks.,CoRR,2023,"Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev 0002",abs/2308.10201,https://doi.org/10.48550/arXiv.2308.10201
High Dimensional Causal Inference with Variational Backdoor Adjustment.,CoRR,2023,"Daniel Israel, Aditya Grover, Guy Van den Broeck",abs/2310.06100,https://doi.org/10.48550/arXiv.2310.06100
Horizontal Class Backdoor to Deep Learning.,CoRR,2023,"Hua Ma, Shang Wang, Yansong Gao",abs/2310.00542,https://doi.org/10.48550/arXiv.2310.00542
Hyperparameter Search Is All You Need For Training-Agnostic Backdoor Robustness.,CoRR,2023,"Eugene Bagdasaryan, Vitaly Shmatikov",abs/2302.04977,https://doi.org/10.48550/arXiv.2302.04977
IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks.,CoRR,2023,"Xuanli He, Jun Wang 0126, Benjamin I. P. Rubinstein, Trevor Cohn",abs/2305.16503,https://doi.org/10.48550/arXiv.2305.16503
IMPOSITION: Implicit Backdoor Attack through Scenario Injection.,CoRR,2023,"Mozhgan PourKeshavarz, Mohammad Sabokrou, Amir Rasouli",abs/2306.15755,https://doi.org/10.48550/arXiv.2306.15755
Imperceptible Sample-Specific Backdoor to DNN with Denoising Autoencoder.,CoRR,2023,"Jiliang Zhang 0002, Jing Xu, Zhi Zhang 0001, Yansong Gao",abs/2302.04457,https://doi.org/10.48550/arXiv.2302.04457
Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection.,CoRR,2023,"Hang Wang, Zhen Xiang, David J. Miller 0001, George Kesidis",abs/2308.04617,https://doi.org/10.48550/arXiv.2308.04617
Influencer Backdoor Attack on Semantic Segmentation.,CoRR,2023,"Haoheng Lan, Jindong Gu, Philip H. S. Torr, Hengshuang Zhao",abs/2303.12054,https://doi.org/10.48550/arXiv.2303.12054
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models.,CoRR,2023,"Jiashu Xu, Mingyu Derek Ma, Fei Wang 0060, Chaowei Xiao, Muhao Chen",abs/2305.14710,https://doi.org/10.48550/arXiv.2305.14710
Invisible Threats: Backdoor Attack in OCR Systems.,CoRR,2023,"Mauro Conti, Nicola Farronato, Stefanos Koffas, Luca Pajola, Stjepan Picek",abs/2310.08259,https://doi.org/10.48550/arXiv.2310.08259
LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors.,CoRR,2023,"Chengkun Wei, Wenlong Meng, Zhikun Zhang, Min Chen, Minghu Zhao, Wenjing Fang, Lei Wang, Zihui Zhang, Wenzhi Chen",abs/2308.13904,https://doi.org/10.48550/arXiv.2308.13904
Launching a Robust Backdoor Attack under Capability Constrained Scenarios.,CoRR,2023,"Ming Yi, Yixiao Xu, Kangyi Ding, Mingyong Yin, Xiaolei Liu 0001",abs/2304.10985,https://doi.org/10.48550/arXiv.2304.10985
Learning to Backdoor Federated Learning.,CoRR,2023,"Henger Li, Chen Wu, Sencun Zhu, Zizhan Zheng",abs/2303.03320,https://doi.org/10.48550/arXiv.2303.03320
"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition.",CoRR,2023,"Hasan Abed Al Kader Hammoud, Shuming Liu, Mohammad Alkhrashi, Fahad Albalawi, Bernard Ghanem",abs/2301.00986,https://doi.org/10.48550/arXiv.2301.00986
Manipulating Trajectory Prediction with Backdoors.,CoRR,2023,"Kaouther Messaoud, Kathrin Grosse, Mickaël Chen, Matthieu Cord, Patrick Pérez, Alexandre Alahi",abs/2312.13863,https://doi.org/10.48550/arXiv.2312.13863
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder.,CoRR,2023,"Tao Sun 0009, Lu Pang 0006, Chao Chen 0012, Haibin Ling",abs/2303.15564,https://doi.org/10.48550/arXiv.2303.15564
Mitigating Backdoor Attack Via Prerequisite Transformation.,CoRR,2023,,abs/2306.01983,https://doi.org/10.48550/arXiv.2306.01983
Mitigating Backdoors in Federated Learning with FLD.,CoRR,2023,"Yihang Lin, Pengyuan Zhou, Zhiqian Wu, Yong Liao",abs/2303.00302,https://doi.org/10.48550/arXiv.2303.00302
Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration.,CoRR,2023,"Soroush Hashemifar, Saeed Parsa, Morteza Zakeri Nasrabadi",abs/2311.07417,https://doi.org/10.48550/arXiv.2311.07417
OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection.,CoRR,2023,"Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi",abs/2312.01585,https://doi.org/10.48550/arXiv.2312.01585
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.,CoRR,2023,"Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang 0006",abs/2312.09057,https://doi.org/10.48550/arXiv.2312.09057
One-to-Multiple Clean-Label Image Camouflage (OmClic) based Backdoor Attack on Deep Learning.,CoRR,2023,"Guohong Wang, Hua Ma, Yansong Gao, Alsharif Abuadbba, Zhi Zhang 0001, Wei Kang, Said F. Al-Sarawi, Gongxuan Zhang, Derek Abbott",abs/2309.04036,https://doi.org/10.48550/arXiv.2309.04036
PECAN: A Deterministic Certified Defense Against Backdoor Attacks.,CoRR,2023,"Yuhao Zhang, Aws Albarghouthi, Loris D&apos;Antoni",abs/2301.11824,https://doi.org/10.48550/arXiv.2301.11824
PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models.,CoRR,2023,"Hongwei Yao, Jian Lou 0001, Zhan Qin",abs/2310.12439,https://doi.org/10.48550/arXiv.2310.12439
PoisonedGNN: Backdoor Attack on Graph Neural Networks-based Hardware Security Systems.,CoRR,2023,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique 0001, Ozgur Sinanoglu",abs/2303.14009,https://doi.org/10.48550/arXiv.2303.14009
Prompt Backdoors in Visual Prompt Learning.,CoRR,2023,"Hai Huang, Zhengyu Zhao 0001, Michael Backes 0001, Yun Shen, Yang Zhang 0016",abs/2310.07632,https://doi.org/10.48550/arXiv.2310.07632
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation.,CoRR,2023,"Yanxin Yang, Ming Hu 0003, Yue Cao, Jun Xia, Yihao Huang 0001, Yang Liu 0003, Mingsong Chen",abs/2308.11333,https://doi.org/10.48550/arXiv.2308.11333
Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning.,CoRR,2023,"Hao Chen, Chen Gong 0005, Yizhe Wang, Xinwen Hou",abs/2304.00252,https://doi.org/10.48550/arXiv.2304.00252
Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective.,CoRR,2023,"Ming-Yu Chung, Sheng-Yen Chou, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo, Tsung-Yi Ho",abs/2311.16646,https://doi.org/10.48550/arXiv.2311.16646
"Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers.",CoRR,2023,"Ruotong Wang 0008, Hongrui Chen, Zihao Zhu, Li Liu, Yong Zhang 0034, Yanbo Fan, Baoyuan Wu",abs/2306.00816,https://doi.org/10.48550/arXiv.2306.00816
Robust Backdoor Attacks on Object Detection in Real World.,CoRR,2023,"Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang",abs/2309.08953,https://doi.org/10.48550/arXiv.2309.08953
Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics.,CoRR,2023,"Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo 0001, Nan Sun 0002, Shengshan Hu, Shang Gao 0003, Yang Xiang 0001",abs/2312.02673,https://doi.org/10.48550/arXiv.2312.02673
RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks.,CoRR,2023,,abs/2302.09420,https://doi.org/10.48550/arXiv.2302.09420
SATBA: An Invisible Backdoor Attack Based On Spatial Attention.,CoRR,2023,"Huasong Zhou, Zhenyu Wang, Xiaowei Xu",abs/2302.13056,https://doi.org/10.48550/arXiv.2302.13056
Salient Conditional Diffusion for Defending Against Backdoor Attacks.,CoRR,2023,"Brandon B. May, N. Joseph Tatro, Piyush Kumar, Nathan Shnidman",abs/2301.13862,https://doi.org/10.48550/arXiv.2301.13862
Silent Killer: Optimizing Backdoor Trigger Yields a Stealthy and Powerful Data Poisoning Attack.,CoRR,2023,"Tzvi Lederer, Gallil Maimon, Lior Rokach",abs/2301.02615,https://doi.org/10.48550/arXiv.2301.02615
Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data.,CoRR,2023,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Aitor Urbieta",abs/2302.06279,https://doi.org/10.48550/arXiv.2302.06279
Stealthy Low-frequency Backdoor Attack against Deep Neural Networks.,CoRR,2023,"Xinrui Liu, Yu-an Tan 0001, Yajie Wang, Kefan Qiu, Yuanzhang Li",abs/2305.09677,https://doi.org/10.48550/arXiv.2305.09677
Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections.,CoRR,2023,"Yuanpu Cao, Bochuan Cao, Jinghui Chen",abs/2312.00027,https://doi.org/10.48550/arXiv.2312.00027
Steganography for Neural Radiance Fields by Backdooring.,CoRR,2023,"Weina Dong, Jia Liu, Yan Ke, Lifeng Chen, Wenquan Sun, Xiaozhong Pan",abs/2309.10503,https://doi.org/10.48550/arXiv.2309.10503
Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models.,CoRR,2023,"Sze Jue Yang, Chinh D. La, Quang H. Nguyen, Eugene Bagdasaryan, Kok-Seng Wong, Anh Tuan Tran, Chee Seng Chan, Khoa D. Doan",abs/2312.03419,https://doi.org/10.48550/arXiv.2312.03419
TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4.,CoRR,2023,"Zihao Tan, Qingliang Chen, Yongjian Huang, Chen Liang",abs/2311.17429,https://doi.org/10.48550/arXiv.2311.17429
Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data.,CoRR,2023,"Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha A. Larson, Stjepan Picek",abs/2311.07550,https://doi.org/10.48550/arXiv.2311.07550
Test-Time Adaptation for Backdoor Defense.,CoRR,2023,"Jiyang Guan, Jian Liang, Ran He 0001",abs/2308.06107,https://doi.org/10.48550/arXiv.2308.06107
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations.,CoRR,2023,"Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Chaowei Xiao, Muhao Chen",abs/2311.09763,https://doi.org/10.48550/arXiv.2311.09763
TextGuard: Provable Defense against Backdoor Attacks on Text Classification.,CoRR,2023,"Hengzhi Pei, Jinyuan Jia, Wenbo Guo 0002, Bo Li 0026, Dawn Song",abs/2311.11225,https://doi.org/10.48550/arXiv.2311.11225
Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks.,CoRR,2023,"Xinrui Liu, Yajie Wang, Yu-An Tan 0001, Kefan Qiu, Yuanzhang Li",abs/2305.10596,https://doi.org/10.48550/arXiv.2305.10596
Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger.,CoRR,2023,"Yiming Li 0004, Mingyan Zhu, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin",abs/2312.04584,https://doi.org/10.48550/arXiv.2312.04584
Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound.,CoRR,2023,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao 0002, Stefanos Koffas, Yiming Li",abs/2307.08208,https://doi.org/10.48550/arXiv.2307.08208
UOR: Universal Backdoor Attacks on Pre-trained Language Models.,CoRR,2023,"Wei Du, Peixuan Li, Boqun Li, Haodong Zhao, Gongshen Liu",abs/2305.09574,https://doi.org/10.48550/arXiv.2305.09574
UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks.,CoRR,2023,"Bingyin Zhao, Yingjie Lao",abs/2312.10657,https://doi.org/10.48550/arXiv.2312.10657
Universal Adversarial Backdoor Attacks to Fool Vertical Federated Learning in Cloud-Edge Collaboration.,CoRR,2023,"Peng Chen, Xin Du, Zhihui Lu 0002, Hongfeng Chai",abs/2304.11432,https://doi.org/10.48550/arXiv.2304.11432
Universal Backdoor Attacks.,CoRR,2023,"Benjamin Schneider, Nils Lukas, Florian Kerschbaum",abs/2312.00157,https://doi.org/10.48550/arXiv.2312.00157
Universal Jailbreak Backdoors from Poisoned Human Feedback.,CoRR,2023,"Javier Rando, Florian Tramèr",abs/2311.14455,https://doi.org/10.48550/arXiv.2311.14455
Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks.,CoRR,2023,"Xiaoyun Xu, Oguzhan Ersoy, Stjepan Picek",abs/2302.00747,https://doi.org/10.48550/arXiv.2302.00747
WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks.,CoRR,2023,"Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Xian Wei, Mingsong Chen",abs/2310.11595,https://doi.org/10.48550/arXiv.2310.11595
You Can Backdoor Personalized Federated Learning.,CoRR,2023,"Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li 0067, Ming Gao 0001",abs/2307.15971,https://doi.org/10.48550/arXiv.2307.15971
Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization.,CoRR,2023,"Yihao Huang 0001, Qing Guo 0005, Felix Juefei-Xu",abs/2305.10701,https://doi.org/10.48550/arXiv.2305.10701
ADFL: Defending backdoor attacks in federated learning via adversarial distillation.,Comput. Secur.,2023,"Chengcheng Zhu, Jiale Zhang, Xiaobing Sun 0001, Bing Chen 0002, Weizhi Meng 0001",132,https://doi.org/10.1016/j.cose.2023.103366
"DIHBA: Dynamic, invisible and high attack success rate boundary backdoor attack with low poison ratio.",Comput. Secur.,2023,"Binhao Ma, Can Zhao, Dejun Wang, Bo Meng",129,https://doi.org/10.1016/j.cose.2023.103212
LR-BA: Backdoor attack against vertical federated learning using local latent representations.,Comput. Secur.,2023,"Yuhao Gu, Yuebin Bai",129,https://doi.org/10.1016/j.cose.2023.103193
Object-free backdoor attack and defense on semantic segmentation.,Comput. Secur.,2023,"Jiaoze Mao, Yaguan Qian, Jianchang Huang, Zejie Lian, Renhui Tao, Bin Wang 0062, Wei Wang 0012, Tengteng Yao",132,https://doi.org/10.1016/j.cose.2023.103365
SCFL: Mitigating backdoor attacks in federated learning based on SVD and clustering.,Comput. Secur.,2023,"Yongkang Wang, Di-Hua Zhai, Yuanqing Xia",133,https://doi.org/10.1016/j.cose.2023.103414
Towards Backdoor Attacks and Defense in Robust Machine Learning Models.,Comput. Secur.,2023,"Ezekiel O. Soremekun, Sakshi Udeshi, Sudipta Chattopadhyay 0001",127,https://doi.org/10.1016/j.cose.2023.103101
A New Idea for RSA Backdoors.,Cryptogr.,2023,,7,https://doi.org/10.3390/cryptography7030045
DLP: towards active defense against backdoor attacks with decoupled learning process.,Cybersecur.,2023,"Zonghao Ying, Bin Wu 0011",6,https://doi.org/10.1186/s42400-023-00141-4
NBA: defensive distillation for backdoor removal via neural behavior alignment.,Cybersecur.,2023,"Zonghao Ying, Bin Wu 0011",6,https://doi.org/10.1186/s42400-023-00154-z
Don&apos;t Knock! Rowhammer at the Backdoor of DNN Models.,DSN,2023,"M. Caner Tol, Saad Islam, Andrew J. Adiletta, Berk Sunar, Ziming Zhang",,https://doi.org/10.1109/DSN58367.2023.00023
Invisible Backdoor Attacks Using Data Poisoning in Frequency Domain.,ECAI,2023,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen 0012",,https://doi.org/10.3233/FAIA230610
XGBD: Explanation-Guided Graph Backdoor Detection.,ECAI,2023,"Zihan Guan 0001, Mengnan Du, Ninghao Liu",,https://doi.org/10.3233/FAIA230363
Practical and General Backdoor Attacks Against Vertical Federated Learning.,ECML/PKDD,2023,"Yuexin Xuan, Xiaojun Chen 0004, Zhendong Zhao, Bisheng Tang, Ye Dong",,https://doi.org/10.1007/978-3-031-43415-0_24
Attention-Enhancing Backdoor Attacks Against BERT-based Models.,EMNLP,2023,"Weimin Lyu, Songzhu Zheng, Lu Pang 0006, Haibin Ling, Chao Chen 0012",,https://doi.org/10.18653/v1/2023.findings-emnlp.716
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers.,EMNLP,2023,"Wencong You, Zayd Hammoudeh, Daniel Lowd",,https://doi.org/10.18653/v1/2023.findings-emnlp.833
Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation.,EMNLP,2023,"Xuanli He, Qiongkai Xu, Jun Wang 0126, Benjamin I. P. Rubinstein, Trevor Cohn",,https://doi.org/10.18653/v1/2023.emnlp-main.60
Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models.,EMNLP,2023,"Shuai Zhao, Jinming Wen, Anh Tuan Luu, Junbo Zhao, Jie Fu",,https://doi.org/10.18653/v1/2023.emnlp-main.757
Backdoor Attacks Leveraging Latent Representation in Competitive Learning.,ESORICS Workshops,2023,"Kazuki Iwahana, Naoto Yanai, Toru Fujiwara",,https://doi.org/10.1007/978-3-031-54129-2_41
A Textual Backdoor Defense Method Based on Deep Feature Classification.,Entropy,2023,"Kun Shao, Jun-an Yang, Pengjiang Hu, Xiaoshuai Li",25,https://doi.org/10.3390/e25020220
Backdoor Attack against Face Sketch Synthesis.,Entropy,2023,"Shengchuan Zhang, Suhang Ye",25,https://doi.org/10.3390/e25070974
Watermarking Graph Neural Networks based on Backdoor Attacks.,EuroS&amp;P,2023,"Jing Xu, Stefanos Koffas, Oguzhan Ersoy, Stjepan Picek",,https://doi.org/10.1109/EuroSP57164.2023.00072
A defense method against backdoor attacks on neural networks.,Expert Syst. Appl.,2023,"Sara Kaviani, Samaneh Shamshiri, Insoo Sohn",213,https://doi.org/10.1016/j.eswa.2022.118990
Backdoor Mitigation in Deep Neural Networks via Strategic Retraining.,FM,2023,"Akshay Dhonthi, Ernst Moritz Hahn, Vahid Hashemi",,https://doi.org/10.1007/978-3-031-27481-7_37
An Investigation of Recent Backdoor Attacks and Defenses in Federated Learning.,FMEC,2023,"Qiuxian Chen, Yizheng Tao",,https://doi.org/10.1109/FMEC59375.2023.10306127
Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification.,FMEC,2023,"Mahmoud Nazzal, Nura Aljaafari, Ahmad H. Sawalmeh, Abdallah Khreishah, Muhammad Anan, Abdulelah Abdallah Algosaibi, Mohammed Alnaeem, Adel Aldalbahi, Abdulaziz Alhumam, Conrado P. Vizcarra, Shadan Alhamed",,https://doi.org/10.1109/FMEC59375.2023.10306137
An adaptive robust defending algorithm against backdoor attacks in federated learning.,Future Gener. Comput. Syst.,2023,"Yongkang Wang, Di-Hua Zhai, Yongping He, Yuanqing Xia",143,https://doi.org/10.1016/j.future.2023.01.026
Backdoor Attacks Against Deep Learning-Based Massive MIMO Localization.,GLOBECOM,2023,"Tianya Zhao, Xuyu Wang, Shiwen Mao",,https://doi.org/10.1109/GLOBECOM54140.2023.10437534
Backdoor Attacks on Multi-Agent Reinforcement Learning-based Spectrum Management.,GLOBECOM,2023,"Hongyi Zhang, Mingqian Liu, Yunfei Chen 0001",,https://doi.org/10.1109/GLOBECOM54140.2023.10437779
Knowledge Distillation Based Defense for Audio Trigger Backdoor in Federated Learning.,GLOBECOM,2023,"Yu-Wen Chen, Bo-Hsu Ke, Bozhong Chen, Si-Rong Chiu, Chun-Wei Tu, Jian-Jhih Kuo",,https://doi.org/10.1109/GLOBECOM54140.2023.10437601
PBE-Plan: Periodic Backdoor Erasing Plan for Trustworthy Federated Learning.,HPCC/DSS/SmartCity/DependSys,2023,"Bei Chen, Gaolei Li, Mingzhe Chen, Yuchen Liu, Xiaoyu Yi 0003, Jianhua Li 0001",,https://doi.org/10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00016
Black-Box Graph Backdoor Defense.,ICA3PP,2023,"Xiao Yang, Gaolei Li, Xiaoyi Tao, Chaofeng Zhang, Jianhua Li",,https://doi.org/10.1007/978-981-97-0808-6_10
Fully Hidden Dynamic Trigger Backdoor Attacks.,ICAART,2023,"Shintaro Narisada, Seira Hidano, Kazuhide Fukushima",,https://doi.org/10.5220/0011617800003393
An Empirical Study of Backdoor Attacks on Masked Auto Encoders.,ICASSP,2023,"Shuli Zhuang, Pengfei Xia, Bin Li",,https://doi.org/10.1109/ICASSP49357.2023.10095201
BATT: Backdoor Attack with Transformation-Based Triggers.,ICASSP,2023,"Tong Xu, Yiming Li 0004, Yong Jiang 0001, Shu-Tao Xia",,https://doi.org/10.1109/ICASSP49357.2023.10096034
Backdoor Attack Against Automatic Speaker Verification Models in Federated Learning.,ICASSP,2023,"Dan Meng, Xue Wang, Jun Wang",,https://doi.org/10.1109/ICASSP49357.2023.10094675
Backdoor Defense via Suppressing Model Shortcuts.,ICASSP,2023,"Sheng Yang, Yiming Li 0004, Yong Jiang 0001, Shu-Tao Xia",,https://doi.org/10.1109/ICASSP49357.2023.10097220
BadRes: Reveal the Backdoors Through Residual Connection.,ICASSP,2023,"Mingrui He, Tianyu Chen, Haoyi Zhou, Shanghang Zhang, Jianxin Li 0002",,https://doi.org/10.1109/ICASSP49357.2023.10094691
Going in Style: Audio Backdoors Through Stylistic Transformations.,ICASSP,2023,"Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti",,https://doi.org/10.1109/ICASSP49357.2023.10096332
Measure and Countermeasure of the Capsulation Attack Against Backdoor-Based Deep Neural Network Watermarks.,ICASSP,2023,"Fang-Qi Li, Shi-Lin Wang, Yun Zhu",,https://doi.org/10.1109/ICASSP49357.2023.10096448
NCL: Textual Backdoor Defense Using Noise-Augmented Contrastive Learning.,ICASSP,2023,"Shengfang Zhai, Qingni Shen, Xiaoyi Chen, Weilong Wang, Cong Li, Yuejian Fang, Zhonghai Wu",,https://doi.org/10.1109/ICASSP49357.2023.10095007
QTROJAN: A Circuit Backdoor Against Quantum Neural Networks.,ICASSP,2023,"Cheng Chu, Lei Jiang 0001, Martin Swany, Fan Chen 0001",,https://doi.org/10.1109/ICASSP49357.2023.10096293
Training Set Cleansing of Backdoor Poisoning by Self-Supervised Representation Learning.,ICASSP,2023,"Hang Wang, Sahar Karami, Ousmane Dia, Hippolyt Ritter, Ehsan Emamjomeh-Zadeh, Jiahui Chen, Zhen Xiang, David J. Miller 0001, George Kesidis",,https://doi.org/10.1109/ICASSP49357.2023.10097244
Untargeted Backdoor Attack Against Object Detection.,ICASSP,2023,"Chengxiao Luo, Yiming Li 0004, Yong Jiang 0001, Shu-Tao Xia",,https://doi.org/10.1109/ICASSP49357.2023.10095980
FedMC: Federated Learning with Mode Connectivity Against Distributed Backdoor Attacks.,ICC,2023,"Weiqi Wang, Chenhan Zhang, Shushu Liu, Mingjian Tang 0002, An Liu 0002, Shui Yu 0001",,https://doi.org/10.1109/ICC45041.2023.10278903
Successive Interference Cancellation Based Defense for Trigger Backdoor in Federated Learning.,ICC,2023,"Yu-Wen Chen, Bo-Hsu Ke, Bozhong Chen, Si-Rong Chiu, Chun-Wei Tu, Jian-Jhih Kuo",,https://doi.org/10.1109/ICC45041.2023.10278979
Towards Defending Adaptive Backdoor Attacks in Federated Learning.,ICC,2023,"Han Yang, Dongbing Gu, Jianhua He",,https://doi.org/10.1109/ICC45041.2023.10279267
Random Location Poisoning Backdoor Attack Against Automatic Modulation Classification in Wireless Networks.,ICCC,2023,"Zixin Li, Hang Jiang, Sicheng Zhang, Wei Xiang, Yun Lin",,https://doi.org/10.1109/ICCC57788.2023.10233544
Stealthy Backdoor Attack on RF Signal Classification.,ICCCN,2023,"Tianming Zhao 0001, Zijie Tang, Tianfang Zhang, Huy Phan, Yan Wang 0003, Cong Shi 0004, Bo Yuan 0001, Yingying Chen 0001",,https://doi.org/10.1109/ICCCN58024.2023.10230152
Invisible Encoded Backdoor attack on DNNs using Conditional GAN.,ICCE,2023,"Iram Arshad, Yuansong Qiao, Brian Lee 0001, Yuhang Ye",,https://doi.org/10.1109/ICCE56470.2023.10043484
Countermeasure against Backdoor Attack for Deep Learning-Based Phishing Detection.,ICCE-Taiwan,2023,"Koko Nishiura, Tomotaka Kimura, Jun Cheng 0001",,https://doi.org/10.1109/ICCE-Taiwan58799.2023.10226938
An Embarrassingly Simple Backdoor Attack on Self-supervised Learning.,ICCV,2023,"Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao 0001, Ting Wang",,https://doi.org/10.1109/ICCV51070.2023.00403
Beating Backdoor Attack at Its Own Game.,ICCV,2023,"Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue",,https://doi.org/10.1109/ICCV51070.2023.00426
Computation and Data Efficient Backdoor Attacks.,ICCV,2023,"Yutong Wu 0009, Xingshuo Han, Han Qiu 0001, Tianwei Zhang 0004",,https://doi.org/10.1109/ICCV51070.2023.00443
Enhancing Fine-Tuning based Backdoor Defense with Sharpness-Aware Minimization.,ICCV,2023,"Mingli Zhu, Shaokui Wei, Li Shen 0008, Yanbo Fan, Baoyuan Wu",,https://doi.org/10.1109/ICCV51070.2023.00412
Multi-metrics adaptively identifies backdoors in Federated learning.,ICCV,2023,"Siquan Huang, Yijiang Li, Chong Chen, Leyu Shi, Ying Gao 0004",,https://doi.org/10.1109/ICCV51070.2023.00429
PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning.,ICCV,2023,"Junfeng Guo, Ang Li, Lixu Wang, Cong Liu 0005",,https://doi.org/10.1109/ICCV51070.2023.00433
Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis.,ICCV,2023,"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",,https://doi.org/10.1109/ICCV51070.2023.00423
TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models.,ICCV,2023,"Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha",,https://doi.org/10.1109/ICCV51070.2023.00022
The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning.,ICCV,2023,"Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr",,https://doi.org/10.1109/ICCV51070.2023.00436
ScanFed: Scalable Behavior-Based Backdoor Detection in Federated Learning.,ICDCS,2023,"Rui Ning, Jiang Li, Chunsheng Xin, Chonggang Wang, Xu Li, Robert Gazda, Jin-Hee Cho, Hongyi Wu",,https://doi.org/10.1109/ICDCS57875.2023.00011
Backdoor Learning on Siamese Networks Using Physical Triggers: FaceNet as a Case Study.,ICDF2C,2023,"Zeshan Pang, Yuyuan Sun, Shasha Guo, Yuliang Lu",,https://doi.org/10.1007/978-3-031-56580-9_17
CCBA: Code Poisoning-Based Clean-Label Covert Backdoor Attack Against DNNs.,ICDF2C,2023,"Xubo Yang, Linsen Li, Cunqing Hua, Changhao Yao",,https://doi.org/10.1007/978-3-031-56580-9_11
Persistent Clean-Label Backdoor on Graph-Based Semi-supervised Cybercrime Detection.,ICDF2C,2023,"Xiao Yang, Gaolei Li, Meng Han",,https://doi.org/10.1007/978-3-031-56580-9_16
A Practical Clean-Label Backdoor Attack with Limited Information in Vertical Federated Learning.,ICDM,2023,"Peng Chen, Jirui Yang, Junxiong Lin, Zhihui Lu 0002, Qiang Duan, Hongfeng Chai",,https://doi.org/10.1109/ICDM58522.2023.00013
Backdoor Attack on 3D Grey Image Segmentation.,ICDM,2023,"Honghui Xu, Zhipeng Cai 0001, Zuobin Xiong, Wei Li 0059",,https://doi.org/10.1109/ICDM58522.2023.00080
BHAC-MRI: Backdoor and Hybrid Attacks on MRI Brain Tumor Classification Using CNN.,ICIAP,2023,"Muhammad Imran, Hassaan Khaliq Qureshi, Irene Amerini",,https://doi.org/10.1007/978-3-031-43153-1_28
Neural Network Backdoor Attacks Fully Controlled by Composite Natural Utterance Fragments.,ICICS,2023,"Xubo Yang, Linsen Li, Yenan Chen",,https://doi.org/10.1007/978-981-99-7356-9_27
CSSBA: A Clean Label Sample-Specific Backdoor Attack.,ICIP,2023,"Zihan Shen, Wei Hou, Yun Li",,https://doi.org/10.1109/ICIP49359.2023.10222085
Efficient any-Target Backdoor Attack with Pseudo Poisoned Samples.,ICIP,2023,"Bin Huang, Zhi Wang",,https://doi.org/10.1109/ICIP49359.2023.10222807
Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only.,ICLR,2023,"Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li 0001, Tianwei Zhang 0004",,https://openreview.net/pdf?id=rFQfjDC9Mt
Distilling Cognitive Backdoor Patterns within an Image.,ICLR,2023,"Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey 0001",,https://openreview.net/pdf?id=S3D9NLzjnQ5
FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning.,ICLR,2023,"Kaiyuan Zhang 0002, Guanhong Tao 0001, Qiuling Xu, Siyuan Cheng 0005, Shengwei An, Yingqi Liu, Shiwei Feng 0002, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang 0001",,https://openreview.net/pdf?id=Xo2E217_M4n
Few-shot Backdoor Attacks via Neural Tangent Kernels.,ICLR,2023,"Jonathan Hayase, Sewoong Oh",,https://openreview.net/pdf?id=a70lGJ-rwy
Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks.,ICLR,2023,"Charles Jin, Melinda Sun, Martin C. Rinard",,https://openreview.net/pdf?id=mkJm5Uy4HrQ
Revisiting the Assumption of Latent Separability for Backdoor Defenses.,ICLR,2023,"Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal",,https://openreview.net/pdf?id=_wSHsgrVali
SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency.,ICLR,2023,"Junfeng Guo, Yiming Li 0004, Xun Chen, Hanqing Guo, Lichao Sun 0001, Cong Liu 0005",,https://openreview.net/pdf?id=o0LFPcoFKnr
The Dark Side of AutoML: Towards Architectural Backdoor Search.,ICLR,2023,"Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang 0006",,https://openreview.net/pdf?id=bsZULlDGXe
UNICORN: A Unified Backdoor Trigger Inversion Framework.,ICLR,2023,"Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma",,https://openreview.net/pdf?id=Mj7K4lglGyj
DBIA: Data-Free Backdoor Attack Against Transformer Networks.,ICME,2023,"Peizhuo Lv, Hualong Ma, Jiachen Zhou, Ruigang Liang, Kai Chen 0012, Shengzhi Zhang, Yunfei Yang",,https://doi.org/10.1109/ICME55011.2023.00479
Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data.,ICME,2023,"Zekai Chen, Fuyi Wang, Zhiwei Zheng, Ximeng Liu, Yujie Lin",,https://doi.org/10.1109/ICME55011.2023.00067
Watermarks for Generative Adversarial Network Based on Steganographic Invisible Backdoor.,ICME,2023,"Yuwei Zeng, Jingxuan Tan, Zhengxin You, Zhenxing Qian, Xinpeng Zhang 0001",,https://doi.org/10.1109/ICME55011.2023.00211
Chameleon: Adapting to Peer Images for Planting Durable Backdoors in Federated Learning.,ICML,2023,"Yanbo Dai, Songze Li",,https://proceedings.mlr.press/v202/dai23a.html
Graph Contrastive Backdoor Attacks.,ICML,2023,"Hangfan Zhang, Jinghui Chen, Lu Lin 0001, Jinyuan Jia, Dinghao Wu",,https://proceedings.mlr.press/v202/zhang23e.html
Reconstructive Neuron Pruning for Backdoor Defense.,ICML,2023,"Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang",,https://proceedings.mlr.press/v202/li23v.html
Rethinking Backdoor Attacks.,ICML,2023,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry",,https://proceedings.mlr.press/v202/khaddaj23a.html
UMD: Unsupervised Model Detection for X2X Backdoor Attacks.,ICML,2023,"Zhen Xiang, Zidi Xiong, Bo Li",,https://proceedings.mlr.press/v202/xiang23a.html
Understanding Backdoor Attacks through the Adaptability Hypothesis.,ICML,2023,"Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding 0002",,https://proceedings.mlr.press/v202/xian23a.html
MIC: An Effective Defense Against Word-Level Textual Backdoor Attacks.,ICONIP,2023,"Shufan Yang, Qianmu Li, Zhichao Lian, Pengchuan Wang, Jun Hou 0002",,https://doi.org/10.1007/978-981-99-8076-5_1
SDBC: A Novel and Effective Self-Distillation Backdoor Cleansing Approach.,ICONIP,2023,"Sheng Ran, Baolin Zheng, Mingwei Sun",,https://doi.org/10.1007/978-981-99-8148-9_23
RPFL: Robust and Privacy Federated Learning against Backdoor and Sample Inference Attacks.,ICPADS,2023,"Di Xiao, Zhuyang Yu, Lvjun Chen",,https://doi.org/10.1109/ICPADS60453.2023.00213
SemSBA: Semantic-perturbed Stealthy Backdoor Attack on Federated Semi-supervised Learning.,ICPADS,2023,"Yingrui Tong, Jun Feng, Gaolei Li, Xi Lin 0003, Chengcheng Zhao, Xiaoyu Yi, Jianhua Li 0001",,https://doi.org/10.1109/ICPADS60453.2023.00221
X-HDNN: Explainable Hybrid DNN for Industrial Internet of Things Backdoor Attack Detection.,ICTC,2023,"Love Allen Chijioke Ahakonye, Cosmas Ifeanyi Nwakanma, Jae Min Lee, Dong-Seong Kim",,https://doi.org/10.1109/ICTC58733.2023.10393379
Instance-Agnostic and Practical Clean Label Backdoor Attack Method for Deep Learning Based Face Recognition Models.,IEEE Access,2023,"Tae-Hoon Kim, SeokHwan Choi, Yoon-Ho Choi",11,https://doi.org/10.1109/ACCESS.2023.3342922
A Max-Min Security Game for Coordinated Backdoor Attacks on Federated Learning.,IEEE Big Data,2023,"Omar Abdel Wahab 0001, Anderson Avila",,https://doi.org/10.1109/BigData59044.2023.10386756
Data Poisoning and Backdoor Attacks on Audio Intelligence Systems.,IEEE Commun. Mag.,2023,"Yunjie Ge, Qian Wang, Jiayuan Yu, Chao Shen 0001, Qi Li 0002",61,https://doi.org/10.1109/MCOM.012.2200596
A Triggerless Backdoor Attack and Defense Mechanism for Intelligent Task Offloading in Multi-UAV Systems.,IEEE Internet Things J.,2023,"Shafkat Islam, Shahriar Badsha, Ibrahim Khalil, Mohammed Atiquzzaman, Charalambos Konstantinou",10,https://doi.org/10.1109/JIOT.2022.3172936
Backdoor-Resistant Public Data Integrity Verification Scheme Based on Smart Contracts.,IEEE Internet Things J.,2023,"Shanshan Li 0004, Chunxiang Xu, Yuan Zhang 0006, Yicong Du, Anjia Yang, Xinsheng Wen, Kefei Chen",10,https://doi.org/10.1109/JIOT.2023.3285939
Facilitating Early-Stage Backdoor Attacks in Federated Learning With Whole Population Distribution Inference.,IEEE Internet Things J.,2023,"Tian Liu, Xueyang Hu, Tao Shu",10,https://doi.org/10.1109/JIOT.2023.3237806
Backdoor Attacks to Deep Learning Models and Countermeasures: A Survey.,IEEE Open J. Comput. Soc.,2023,"Yudong Li, Shigeng Zhang, Weiping Wang 0003, Hong Song",4,https://doi.org/10.1109/OJCS.2023.3267221
Stealthy Backdoor Attack Against Speaker Recognition Using Phase-Injection Hidden Trigger.,IEEE Signal Process. Lett.,2023,"Zhe Ye, Diqun Yan, Li Dong 0006, Jiacheng Deng 0001, Shui Yu 0001",30,https://doi.org/10.1109/LSP.2023.3293429
Stealthy Frequency-Domain Backdoor Attacks: Fourier Decomposition and Fundamental Frequency Injection.,IEEE Signal Process. Lett.,2023,"Qianli Ma, Junping Qin, Kai Yan, Lei Wang, Hao Sun",30,https://doi.org/10.1109/LSP.2023.3330126
An Imperceptible Data Augmentation Based Blackbox Clean-Label Backdoor Attack on Deep Neural Networks.,IEEE Trans. Circuits Syst. I Regul. Pap.,2023,"Chaohui Xu, Wenye Liu, Yue Zheng, Si Wang, Chip-Hong Chang",70,https://doi.org/10.1109/TCSI.2023.3298802
$\tt{PoisonedGNN}$: Backdoor Attack on Graph Neural Networks-Based Hardware Security Systems.,IEEE Trans. Computers,2023,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique 0001, Ozgur Sinanoglu",72,https://doi.org/10.1109/TC.2023.3271126
A Temporal Chrominance Trigger for Clean-Label Backdoor Attack Against Anti-Spoof Rebroadcast Detection.,IEEE Trans. Dependable Secur. Comput.,2023,"Wei Guo 0012, Benedetta Tondi, Mauro Barni",20,https://doi.org/10.1109/TDSC.2022.3233519
Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?,IEEE Trans. Dependable Secur. Comput.,2023,"Kaidi Jin, Tianwei Zhang 0004, Chao Shen 0001, Yufei Chen 0001, Ming Fan 0002, Chenhao Lin, Ting Liu 0002",20,https://doi.org/10.1109/TDSC.2022.3194642
Enhancing Backdoor Attacks With Multi-Level MMD Regularization.,IEEE Trans. Dependable Secur. Comput.,2023,"Pengfei Xia, Hongjing Niu, Ziqiang Li 0001, Bin Li 0025",20,https://doi.org/10.1109/TDSC.2022.3161477
FooBaR: Fault Fooling Backdoor Attack on Neural Network Training.,IEEE Trans. Dependable Secur. Comput.,2023,"Jakub Breier, Xiaolu Hou, Martín Ochoa, Jesus Solano",20,https://doi.org/10.1109/TDSC.2022.3166671
Kaleidoscope: Physical Backdoor Attacks Against Deep Neural Networks With RGB Filters.,IEEE Trans. Dependable Secur. Comput.,2023,"Xueluan Gong, Ziyao Wang, Yanjiao Chen, Meng Xue, Qian Wang 0002, Chao Shen 0001",20,https://doi.org/10.1109/TDSC.2023.3239225
MARNet: Backdoor Attacks Against Cooperative Multi-Agent Reinforcement Learning.,IEEE Trans. Dependable Secur. Comput.,2023,"Yanjiao Chen, Zhicong Zheng, Xueluan Gong",20,https://doi.org/10.1109/TDSC.2022.3207429
Backdoor Attacks for Remote Sensing Data With Wavelet Transform.,IEEE Trans. Geosci. Remote. Sens.,2023,"Nikolaus Dräger, Yonghao Xu, Pedram Ghamisi",61,https://doi.org/10.1109/TGRS.2023.3289307
Black-Box Dataset Ownership Verification via Backdoor Watermarking.,IEEE Trans. Inf. Forensics Secur.,2023,"Yiming Li 0004, Mingyan Zhu, Xue Yang 0003, Yong Jiang 0001, Tao Wei, Shu-Tao Xia",18,https://doi.org/10.1109/TIFS.2023.3265535
Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection.,IEEE Trans. Inf. Forensics Secur.,2023,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",18,https://doi.org/10.1109/TIFS.2023.3297056
SAFELearning: Secure Aggregation in Federated Learning With Backdoor Detectability.,IEEE Trans. Inf. Forensics Secur.,2023,"Zhuosheng Zhang 0003, Jiarui Li, Shucheng Yu, Christian Makaya",18,https://doi.org/10.1109/TIFS.2023.3280032
"Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses.",IEEE Trans. Pattern Anal. Mach. Intell.,2023,"Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li 0026, Tom Goldstein",45,https://doi.org/10.1109/TPAMI.2022.3162397
Hidden Backdoor Attack Against Deep Learning-Based Wireless Signal Modulation Classifiers.,IEEE Trans. Veh. Technol.,2023,"Yunsong Huang, Weicheng Liu, Hui-Ming Wang 0001",72,https://doi.org/10.1109/TVT.2023.3267455
"Backdoor Attacks and Defenses in Federated Learning: State-of-the-Art, Taxonomy, and Future Directions.",IEEE Wirel. Commun.,2023,"Xueluan Gong, Yanjiao Chen, Qian Wang 0002, Weihan Kong",30,https://doi.org/10.1109/MWC.017.2100714
Orion: Online Backdoor Sample Detection via Evolution Deviance.,IJCAI,2023,"Huayang Huang, Qian Wang, Xueluan Gong, Tao Wang",,https://doi.org/10.24963/ijcai.2023/96
Backdoor Attack on Deep Neural Networks in Perception Domain.,IJCNN,2023,"Xiaoxing Mo, Leo Yu Zhang, Nan Sun 0002, Wei Luo 0001, Shang Gao 0003",,https://doi.org/10.1109/IJCNN54540.2023.10191661
FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection.,IJCNN,2023,"Thuy Dung Nguyen, Anh Duy Nguyen, Thanh-Hung Nguyen, Kok-Seng Wong, Huy Hieu Pham 0001, Truong Thao Nguyen, Phi Le Nguyen",,https://doi.org/10.1109/IJCNN54540.2023.10191655
Privacy Inference-Empowered Stealthy Backdoor Attack on Federated Learning under Non-IID Scenarios.,IJCNN,2023,"Haochen Mei, Gaolei Li, Jun Wu 0001, Longfei Zheng",,https://doi.org/10.1109/IJCNN54540.2023.10191260
Rethinking the Trigger-injecting Position in Graph Backdoor Attack.,IJCNN,2023,"Jing Xu, Gorka Abad, Stjepan Picek",,https://doi.org/10.1109/IJCNN54540.2023.10191949
Mind Your Heart: Stealthy Backdoor Attack on Dynamic Deep Neural Network in Edge Computing.,INFOCOM,2023,"Tian Dong, Ziyuan Zhang, Han Qiu 0001, Tianwei Zhang 0004, Hewu Li, Terry Wang",,https://doi.org/10.1109/INFOCOM53939.2023.10229092
SDN Application Backdoor: Disrupting the Service via Poisoning the Topology.,INFOCOM,2023,"Shuhua Deng, Xian Qing, Xiaofan Li, Xing Gao 0001, Xieping Gao",,https://doi.org/10.1109/INFOCOM53939.2023.10229058
Robust Federated Learning against Backdoor Attackers.,INFOCOM Workshops,2023,"Priyesh Ranjan, Ashish Gupta 0012, Federico Coro, Sajal K. Das 0001",,https://doi.org/10.1109/INFOCOMWKSHPS57453.2023.10225922
Computational Color Constancy-Based Backdoor Attacks.,ISPA,2023,"Donik Vrsnak, Ivan Sabolic, Marko Subasic, Sven Loncaric",,https://doi.org/10.1109/ISPA58351.2023.10278694
Content Style-triggered Backdoor Attack in Non-IID Federated Learning via Generative AI.,ISPA/BDCloud/SocialCom/SustainCom,2023,"Jinke Cheng, Gaolei Li, Xi Lin 0003, Hao Peng 0001, Jianhua Li 0001",,https://doi.org/10.1109/ISPA-BDCloud-SocialCom-SustainCom59178.2023.00116
Turning backdoors for efficient privacy protection against image retrieval violations.,Inf. Process. Manag.,2023,"Qiang Liu, Tongqing Zhou, Zhiping Cai, Yuan Yuan, Ming Xu 0002, Jiaohua Qin, Wentao Ma",60,https://doi.org/10.1016/j.ipm.2023.103471
Debiasing backdoor attack: A benign application of backdoor attack in eliminating data bias.,Inf. Sci.,2023,"Shangxi Wu, Qiuyang He, Yi Zhang 0101, Dongyuan Lu, Jitao Sang",643,https://doi.org/10.1016/j.ins.2023.119171
Detecting backdoor in deep neural networks via intentional adversarial perturbations.,Inf. Sci.,2023,"Mingfu Xue, Yinghao Wu, Zhiyu Wu, Yushu Zhang, Jian Wang 0038, Weiqiang Liu 0001",634,https://doi.org/10.1016/j.ins.2023.03.112
Efficient and persistent backdoor attack by boundary trigger set constructing against federated learning.,Inf. Sci.,2023,"Deshan Yang, Senlin Luo, Jinjie Zhou, Limin Pan, Xiaonan Yang, Jiyuan Xing",651,https://doi.org/10.1016/j.ins.2023.119743
Unlabeled backdoor poisoning on trained-from-scratch semi-supervised learning.,Inf. Sci.,2023,"Le Feng, Zhenxing Qian, Xinpeng Zhang 0001, Sheng Li 0006",647,https://doi.org/10.1016/j.ins.2023.119453
TRGE: A Backdoor Detection After Quantization.,Inscrypt,2023,"Renhua Xie, Xuxin Fang, Bo Ma, Chuanhuang Li, Xiaoyong Yuan",,https://doi.org/10.1007/978-981-97-0945-8_24
Feature-Based Graph Backdoor Attack in the Node Classification Task.,Int. J. Intell. Syst.,2023,"Yang Chen, Zhonglin Ye, Haixing Zhao, Ying Wang",2023,https://doi.org/10.1155/2023/5418398
IPCADP-Equalizer: An Improved Multibalance Privacy Preservation Scheme against Backdoor Attacks in Federated Learning.,Int. J. Intell. Syst.,2023,"Wenjuan Lian, Yichi Zhang, Xin Chen, Bin Jia, Xiaosong Zhang 0001",2023,https://doi.org/10.1155/2023/6357750
SEBD: Sensor Emulation Based Backdoor for Autopilot.,IoT,2023,"Yue Wang 0063, Chao Yang 0016, Ning Xi, Yulong Shen, Jianfeng Ma 0001",,https://doi.org/10.1145/3627050.3631577
Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks.,KDD,2023,"Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng",,https://doi.org/10.1145/3580305.3599898
DUBIOUS: Detecting Unknown Backdoored Input by Observing Unusual Signatures.,MILCOM,2023,"Matthew Yudin, Rauf Izmailov",,https://doi.org/10.1109/MILCOM58377.2023.10356229
Robust Sentiment Classification Based on the Backdoor Adjustment.,MLNLP,2023,"Lulu Dai, Mingyue Han",,https://doi.org/10.1145/3639479.3639488
Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-level Backdoor Attacks.,Mach. Intell. Res.,2023,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu 0001, Yasheng Wang, Xin Jiang 0002, Maosong Sun 0001",20,https://doi.org/10.1007/s11633-022-1377-5
Backdoor attack and defense in federated generative adversarial network-based medical image synthesis.,Medical Image Anal.,2023,"Ruinan Jin, Xiaoxiao Li",90,https://doi.org/10.1016/j.media.2023.102965
MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems.,MobiCom,2023,"Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao 0001, Qiben Yan",,https://doi.org/10.1145/3570361.3613261
Evil vs evil: using adversarial examples to against backdoor attack in federated learning.,Multim. Syst.,2023,"Tao Liu, Mingjun Li, Haibin Zheng, Zhaoyan Ming, Jinyin Chen",29,https://doi.org/10.1007/s00530-022-00965-z
BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense.,NDSS,2023,"Siyuan Cheng 0005, Guanhong Tao 0001, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng 0002, Guangyu Shen, Kaiyuan Zhang 0002, Qiuling Xu, Shiqing Ma, Xiangyu Zhang 0001",,https://www.ndss-symposium.org/ndss-paper/beagle-forensics-of-deep-learning-backdoor-attack-for-better-defense/
Backdoor Attacks Against Dataset Distillation.,NDSS,2023,"Yugeng Liu, Zheng Li 0023, Michael Backes 0001, Yun Shen, Yang Zhang 0016",,https://www.ndss-symposium.org/ndss-paper/backdoor-attacks-against-dataset-distillation/
The &quot;Beatrix&quot; Resurrections: Robust Backdoor Detection via Gram Matrices.,NDSS,2023,"Wanlun Ma, Derui Wang, Ruoxi Sun 0001, Minhui Xue, Sheng Wen, Yang Xiang 0001",,https://www.ndss-symposium.org/ndss-paper/the-beatrix-resurrections-robust-backdoor-detection-via-gram-matrices/
IMTM: Invisible Multi-trigger Multimodal Backdoor Attack.,NLPCC,2023,"Zhicheng Li, Piji Li, Xuan Sheng, Changchun Yin, Lu Zhou 0002",,https://doi.org/10.1007/978-3-031-44696-2_42
Punctuation Matters! Stealthy Backdoor Attack for Language Models.,NLPCC,2023,"Xuan Sheng, Zhicheng Li, Zhaoyang Han, Xiangmao Chang, Piji Li",,https://doi.org/10.1007/978-3-031-44693-1_41
A Unified Detection Framework for Inference-Stage Backdoor Defenses.,NeurIPS,2023,"Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding 0002",,http://papers.nips.cc/paper_files/paper/2023/hash/1868a3c73d0d2a44c42458575fa8514c-Abstract-Conference.html
A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning.,NeurIPS,2023,"Hangfan Zhang, Jinyuan Jia, Jinghui Chen, Lu Lin 0001, Dinghao Wu",,http://papers.nips.cc/paper_files/paper/2023/hash/c07d71ff0bc042e4b9acd626a79597fa-Abstract-Conference.html
BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning.,NeurIPS,2023,"Xuan Chen, Wenbo Guo 0002, Guanhong Tao 0001, Xiangyu Zhang 0001, Dawn Song",,http://papers.nips.cc/paper_files/paper/2023/hash/802e90325f4c8546e13e5763b2ecab88-Abstract-Conference.html
BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking.,NeurIPS,2023,"Bin Huang, Jiaqian Yu, Yiwei Chen, Siyang Pan, Qiang Wang, Zhi Wang",,http://papers.nips.cc/paper_files/paper/2023/hash/828bb8f42d4ab15322b9315151959c61-Abstract-Conference.html
Black-box Backdoor Defense via Zero-shot Image Purification.,NeurIPS,2023,"Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan 0001, Jin Sun, Ninghao Liu",,http://papers.nips.cc/paper_files/paper/2023/hash/b36554b97da741b1c48c9de05c73993e-Abstract-Conference.html
CBD: A Certified Backdoor Detector Based on Local Dominant Probability.,NeurIPS,2023,"Zhen Xiang, Zidi Xiong, Bo Li",,http://papers.nips.cc/paper_files/paper/2023/hash/0fbf046448d7eea18b982001320b9a10-Abstract-Conference.html
Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks.,NeurIPS,2023,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang",,http://papers.nips.cc/paper_files/paper/2023/hash/677c8dc72c99482507323f313faf4738-Abstract-Conference.html
Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense.,NeurIPS,2023,"Zhiyuan Zhang 0001, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun 0001",,http://papers.nips.cc/paper_files/paper/2023/hash/c39578c86423df5f9e8834ce1cd456e4-Abstract-Conference.html
FedGame: A Game-Theoretic Defense against Backdoor Attacks in Federated Learning.,NeurIPS,2023,"Jinyuan Jia, Zhuowen Yuan, Dinuka Sahabandu, Luyao Niu, Arezoo Rajabi, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran",,http://papers.nips.cc/paper_files/paper/2023/hash/a6678e2be4ce7aef9d2192e03cd586b7-Abstract-Conference.html
IBA: Towards Irreversible Backdoor Attacks in Federated Learning.,NeurIPS,2023,"Thuy Dung Nguyen, Tuan Nguyen, Anh Tran, Khoa D. Doan, Kok-Seng Wong",,http://papers.nips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html
Lockdown: Backdoor Defense for Federated Learning with Isolated Subspace Training.,NeurIPS,2023,"Tiansheng Huang, Sihao Hu, Ka Ho Chow, Fatih Ilhan, Selim F. Tekin, Ling Liu 0001",,http://papers.nips.cc/paper_files/paper/2023/hash/2376f25ef1725a9e3516ee3c86a59f46-Abstract-Conference.html
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features.,NeurIPS,2023,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",,http://papers.nips.cc/paper_files/paper/2023/hash/03df5246cc78af497940338dd3eacbaa-Abstract-Conference.html
Robust Contrastive Language-Image Pretraining against Data Poisoning and Backdoor Attacks.,NeurIPS,2023,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",,http://papers.nips.cc/paper_files/paper/2023/hash/2232e8fee69b150005ac420bfa83d705-Abstract-Conference.html
Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots.,NeurIPS,2023,"Ruixiang (Ryan) Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu 0001",,http://papers.nips.cc/paper_files/paper/2023/hash/e7938ede51225b490bb69f7b361a9259-Abstract-Conference.html
Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples.,NeurIPS,2023,"Shaokui Wei, Mingda Zhang, Hongyuan Zha, Baoyuan Wu",,http://papers.nips.cc/paper_files/paper/2023/hash/520425a5a4c2fb7f7fc345078b188201-Abstract-Conference.html
Towards Stable Backdoor Purification through Feature Shift Tuning.,NeurIPS,2023,"Rui Min, Zeyu Qin, Li Shen 0008, Minhao Cheng",,http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models.,NeurIPS,2023,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",,http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html
How to backdoor split learning.,Neural Networks,2023,"Fangchao Yu, Lina Wang, Bo Zeng, Kai Zhao, Zhi Pang, Tian Wu",168,https://doi.org/10.1016/j.neunet.2023.09.037
Multidomain active defense: Detecting multidomain backdoor poisoned samples via ALL-to-ALL decoupling training without clean datasets.,Neural Networks,2023,"Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng",168,https://doi.org/10.1016/j.neunet.2023.09.036
A lightweight backdoor defense framework based on image inpainting.,Neurocomputing,2023,"Yier Wei, Haichang Gao, Yufei Wang, Yipeng Gao, Huan Liu",537,https://doi.org/10.1016/j.neucom.2023.03.052
Defending Against Backdoor Attacks by Layer-wise Feature Analysis.,PAKDD,2023,"Najeeb Moharram Jebreel, Josep Domingo-Ferrer, Yiming Li",,https://doi.org/10.1007/978-3-031-33377-4_33
Defending Federated Learning from Backdoor Attacks: Anomaly-Aware FedAVG with Layer-Based Aggregation.,PIMRC,2023,"Habib Ullah Manzoor, Ahsan Raza Khan, Tahir Sher, Wasim Ahmad, Ahmed Zoha",,https://doi.org/10.1109/PIMRC56721.2023.10293950
Deep fidelity in DNN watermarking: A study of backdoor watermarking for classification models.,Pattern Recognit.,2023,"Guang Hua 0001, Andrew Beng Jin Teoh",144,https://doi.org/10.1016/j.patcog.2023.109844
Not All Samples Are Born Equal: Towards Effective Clean-Label Backdoor Attacks.,Pattern Recognit.,2023,"Yinghua Gao, Yiming Li 0004, Linghui Zhu, Dongxian Wu, Yong Jiang 0001, Shu-Tao Xia",139,https://doi.org/10.1016/j.patcog.2023.109512
TAT: Targeted backdoor attacks against visual object tracking.,Pattern Recognit.,2023,"Ziyi Cheng, Baoyuan Wu, Zhenya Zhang, Jianjun Zhao",142,https://doi.org/10.1016/j.patcog.2023.109629
Backdoor attacks against deep reinforcement learning based traffic signal control systems.,Peer Peer Netw. Appl.,2023,"Heng Zhang 0001, Jun Gu, Zhikun Zhang 0001, Linkang Du, Yongmin Zhang, Yan Ren, Jian Zhang 0002, Hongran Li",16,https://doi.org/10.1007/s12083-022-01434-0
QDoor: Exploiting Approximate Synthesis for Backdoor Attacks in Quantum Neural Networks.,QCE,2023,"Cheng Chu, Fan Chen 0001, Philip Richerme, Lei Jiang 0001",,https://doi.org/10.1109/QCE57702.2023.00124
Robust Feature-Guided Generative Adversarial Network for Aerial Image Semantic Segmentation against Backdoor Attacks.,Remote. Sens.,2023,"Zhen Wang 0020, Buhong Wang, Chuanlei Zhang, Yaohui Liu 0001, Jianxin Guo",15,https://doi.org/10.3390/rs15102580
Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems.,RepL4NLP@ACL,2023,"Ashim Gupta, Amrith Krishna",,https://doi.org/10.18653/v1/2023.repl4nlp-1.1
FedDefender: Backdoor Attack Defense in Federated Learning.,SE4SafeML@SIGSOFT FSE,2023,"Waris Gill, Ali Anwar 0001, Muhammad Ali Gulzar",,https://doi.org/10.1145/3617574.3617858
Did You Train on My Dataset? Towards Public Dataset Protection with CleanLabel Backdoor Watermarking.,SIGKDD Explor.,2023,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang 0023, Xia Hu 0001",25,https://doi.org/10.1145/3606274.3606279
BATFL: Battling Backdoor Attacks in Federated Learning.,SIN,2023,"Mayank Kumar, Radha Agrawal, Priyanka Singh",,https://doi.org/10.1109/SIN60469.2023.10474981
3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning.,SP,2023,"Haoyang Li, Qingqing Ye 0001, Haibo Hu 0001, Jin Li 0002, Leixia Wang, Chengfang Fang, Jie Shi",,https://doi.org/10.1109/SP46215.2023.10179401
AI-Guardian: Defeating Adversarial Attacks using Backdoors.,SP,2023,"Hong Zhu, Shengzhi Zhang, Kai Chen 0012",,https://doi.org/10.1109/SP46215.2023.10179473
BayBFed: Bayesian Backdoor Defense for Federated Learning.,SP,2023,"Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala, Ahmad-Reza Sadeghi",,https://doi.org/10.1109/SP46215.2023.10179362
Disguising Attacks with Explanation-Aware Backdoors.,SP,2023,"Maximilian Noppel, Lukas Peter, Christian Wressnegger",,https://doi.org/10.1109/SP46215.2023.10179308
Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers.,SP,2023,"Limin Yang, Zhi Chen 0028, Jacopo Cortellazzi, Feargus Pendlebury, Kevin Tu, Fabio Pierazzi, Lorenzo Cavallaro, Gang Wang 0011",,https://doi.org/10.1109/SP46215.2023.10179347
MagBackdoor: Beware of Your Loudspeaker as A Backdoor For Magnetic Injection Attacks.,SP,2023,"Tiantian Liu 0002, Feng Lin 0004, Zhangsen Wang, Chao Wang 0097, Zhongjie Ba, Li Lu 0008, Wenyao Xu, Kui Ren 0001",,https://doi.org/10.1109/SP46215.2023.10179364
On Feasibility of Server-side Backdoor Attacks on Split Learning.,SP,2023,"Behrad Tajalli, Oguzhan Ersoy, Stjepan Picek",,https://doi.org/10.1109/SPW59333.2023.00014
RAB: Provable Robustness Against Backdoor Attacks.,SP,2023,"Maurice Weber, Xiaojun Xu, Bojan Karlas, Ce Zhang 0001, Bo Li 0026",,https://doi.org/10.1109/SP46215.2023.10179451
Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation.,SP,2023,"Xueluan Gong, Yanjiao Chen, Wang Yang, Qian Wang 0002, Yuzhe Gu, Huayang Huang, Chao Shen 0001",,https://doi.org/10.1109/SP46215.2023.10179375
&quot;We Must Protect the Transformers&quot;: Understanding Efficacy of Backdoor Attack Mitigation on Transformer Models.,SPACE,2023,"Rohit Raj, Biplab Roy, Abir Das, Mainack Mondal",,https://doi.org/10.1007/978-3-031-51583-5_14
TransCAB: Transferable Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World.,SRDS,2023,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",,https://doi.org/10.1109/SRDS60354.2023.00018
Training Data Leakage via Imperceptible Backdoor Attack.,SSCI,2023,"Xiangkai Yang, Wenjian Luo, Qi Zhou, Zhijian Chen",,https://doi.org/10.1109/SSCI52147.2023.10372011
Backdoor Attack Detection in Computer Vision by Applying Matrix Factorization on the Weights of Deep Networks.,SafeAI@AAAI,2023,"Khondoker Murad Hossain, Tim Oates 0001",,https://ceur-ws.org/Vol-3381/40.pdf
Towards Understanding How Self-training Tolerates Data Backdoor Poisoning.,SafeAI@AAAI,2023,"Soumyadeep Pal, Ren Wang 0008, Yuguang Yao, Sijia Liu 0001",,https://ceur-ws.org/Vol-3381/31.pdf
Active poisoning: efficient backdoor attacks on transfer learning-based brain-computer interfaces.,Sci. China Inf. Sci.,2023,"Xue Jiang, Lubin Meng, Siyang Li, Dongrui Wu",66,https://doi.org/10.1007/s11432-022-3548-2
Backdoor Attack on Deep Neural Networks Triggered by Fault Injection Attack on Image Sensor Interface.,Sensors,2023,"Tatsuya Oyama, Shunsuke Okura, Kota Yoshida, Takeshi Fujino",23,https://doi.org/10.3390/s23104742
Edge-Cloud Collaborative Defense against Backdoor Attacks in Federated Learning.,Sensors,2023,"Jie Yang, Jun Zheng 0007, Haochen Wang, Jiaxing Li, Haipeng Sun, Weifeng Han, Nan Jiang, Yu-An Tan 0001",23,https://doi.org/10.3390/s23031052
Backdoor Pony: Evaluating backdoor attacks and defenses in different domains.,SoftwareX,2023,"Arthur Mercier, Nikita Smolin, Oliver Sihlovec, Stefanos Koffas, Stjepan Picek",22,https://doi.org/10.1016/j.softx.2023.101387
Immunizing Backdoored PRGs.,TCC,2023,"Marshall Ball, Yevgeniy Dodis, Eli Goldin",,https://doi.org/10.1007/978-3-031-48621-0_6
FUBA: Federated Uncovering of Backdoor Attacks for Heterogeneous Data.,TPS-ISA,2023,"Fabiola Espinoza Castellon, Deepika Singh, Aurelien Mayoue, Cedric Gouy-Pailler",,https://doi.org/10.1109/TPS-ISA58951.2023.00017
Bayesian Causal Bandits with Backdoor Adjustment Prior.,Trans. Mach. Learn. Res.,2023,"Jireh Huang, Qing Zhou",2023,https://openreview.net/forum?id=sMsGv5Kfm3
A Data-free Backdoor Injection Approach in Neural Networks.,USENIX Security Symposium,2023,"Peizhuo Lv, Chang Yue, Ruigang Liang, Yunfei Yang, Shengzhi Zhang, Hualong Ma, Kai Chen 0012",,https://www.usenix.org/conference/usenixsecurity23/presentation/lv
ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms.,USENIX Security Symposium,2023,"Minzhou Pan, Yi Zeng 0005, Lingjuan Lyu, Xue Lin, Ruoxi Jia 0001",,https://www.usenix.org/conference/usenixsecurity23/presentation/pan
Aliasing Backdoor Attacks on Pre-trained Models.,USENIX Security Symposium,2023,"Cheng&apos;an Wei, Yeonjoon Lee, Kai Chen 0012, Guozhu Meng, Peizhuo Lv",,https://www.usenix.org/conference/usenixsecurity23/presentation/wei-chengan
PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis.,USENIX Security Symposium,2023,"Zhuo Zhang 0002, Guanhong Tao 0001, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu, Yapeng Ye, Yaoxuan Wu, Xiangyu Zhang 0001",,https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-pelican
Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks.,USENIX Security Symposium,2023,"Jianwen Tian, Kefan Qiu, Debin Gao, Zhi Wang 0014, Xiaohui Kuang, Gang Zhao",,https://www.usenix.org/conference/usenixsecurity23/presentation/tian
Towards A Proactive ML Approach for Detecting Backdoor Poison Samples.,USENIX Security Symposium,2023,"Xiangyu Qi, Tinghao Xie, Jiachen T. Wang, Tong Wu, Saeed Mahloujifar, Prateek Mittal",,https://www.usenix.org/conference/usenixsecurity23/presentation/qi
VILLAIN: Backdoor Attacks Against Vertical Split Learning.,USENIX Security Symposium,2023,"Yijie Bai, Yanjiao Chen, Hanlei Zhang, Wenyuan Xu 0001, Haiqin Weng, Dou Goodman",,https://www.usenix.org/conference/usenixsecurity23/presentation/bai
Poison Egg: Scrambling Federated Learning with Delayed Backdoor Attack.,UbiSec,2023,"Masayoshi Tsutsui, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki",,https://doi.org/10.1007/978-981-97-1274-8_13
TRAPDOOR: Repurposing neural network backdoors to detect dataset bias in machine learning-based genomic analysis.,VLSI-SoC,2023,"Esha Sarkar, Constantine Doumanidis, Michail Maniatakos",,https://doi.org/10.1109/VLSI-SoC57769.2023.10321928
Training-free Lexical Backdoor Attacks on Language Models.,WWW,2023,"Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen",,https://doi.org/10.1145/3543507.3583348
Unnoticeable Backdoor Attacks on Graph Neural Networks.,WWW,2023,"Enyan Dai, Minhua Lin, Xiang Zhang 0001, Suhang Wang",,https://doi.org/10.1145/3543507.3583392
A stealthy and robust backdoor attack via frequency domain transform.,World Wide Web,2023,"Ruitao Hou, Teng Huang, Hongyang Yan, Lishan Ke, Weixuan Tang",26,https://doi.org/10.1007/s11280-023-01153-3
Backdoor Attacks on the DNN Interpretation System.,AAAI,2022,"Shihong Fang, Anna Choromanska",,https://doi.org/10.1609/aaai.v36i1.19935
Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks.,AAAI,2022,"Jinyuan Jia, Yupei Liu, Xiaoyu Cao, Neil Zhenqiang Gong",,https://doi.org/10.1609/aaai.v36i9.21191
Faster Algorithms for Weak Backdoors.,AAAI,2022,"Serge Gaspers, Andrew Kaploun",,https://doi.org/10.1609/aaai.v36i4.20288
Finding Backdoors to Integer Programs: A Monte Carlo Tree Search Framework.,AAAI,2022,"Elias B. Khalil, Pashootan Vaezipoor, Bistra Dilkina",,https://doi.org/10.1609/aaai.v36i4.20293
Hibernated Backdoor: A Mutual Information Empowered Backdoor Attack to Deep Neural Networks.,AAAI,2022,"Rui Ning, Jiang Li 0001, Chunsheng Xin, Hongyi Wu, Chonggang Wang",,https://doi.org/10.1609/aaai.v36i9.21272
On Probabilistic Generalization of Backdoors in Boolean Satisfiability.,AAAI,2022,"Alexander A. Semenov, Artem Pavlenko, Daniil Chivilikhin, Stepan Kochemazov",,https://doi.org/10.1609/aaai.v36i9.21277
Tractable Abstract Argumentation via Backdoor-Treewidth.,AAAI,2022,"Wolfgang Dvorák, Markus Hecher, Matthias König 0002, André Schidler, Stefan Szeider, Stefan Woltran",,https://doi.org/10.1609/aaai.v36i5.20501
COLLIDER: A Robust Training Framework for Backdoor Data.,ACCV,2022,"Hadi M. Dolatabadi, Sarah M. Erfani, Christopher Leckie",,https://doi.org/10.1007/978-3-031-26351-4_41
Backdoor Attacks on Crowd Counting.,ACM Multimedia,2022,"Yuhua Sun, Tailai Zhang, Xingjun Ma, Pan Zhou, Jian Lou 0001, Zichuan Xu, Xing Di, Yu Cheng 0001, Lichao Sun 0001",,https://doi.org/10.1145/3503161.3548296
BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label.,ACM Multimedia,2022,"Shengshan Hu, Ziqi Zhou, Yechao Zhang, Leo Yu Zhang, Yifeng Zheng, Yuanyuan He 0002, Hai Jin 0001",,https://doi.org/10.1145/3503161.3548272
Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems.,ACM Multimedia,2022,"Qiang Liu 0004, Tongqing Zhou, Zhiping Cai, Yonghao Tang",,https://doi.org/10.1145/3503161.3548261
Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving.,ACM Multimedia,2022,"Xingshuo Han, Guowen Xu, Yuan Zhou 0005, Xuehuan Yang, Jiwei Li 0001, Tianwei Zhang 0004",,https://doi.org/10.1145/3503161.3548171
Purifier: Plug-and-play Backdoor Mitigation for Pre-trained Models Via Anomaly Activation Suppression.,ACM Multimedia,2022,"Xiaoyu Zhang, Yulin Jin, Tao Wang 0036, Jian Lou 0001, Xiaofeng Chen 0001",,https://doi.org/10.1145/3503161.3548065
Defending against Poisoning Backdoor Attacks on Federated Meta-learning.,ACM Trans. Intell. Syst. Technol.,2022,"Chien-Lun Chen, Sara Babakniya, Marco Paolieri, Leana Golubchik",13,https://doi.org/10.1145/3523062
On the Neural Backdoor of Federated Generative Models in Edge Computing.,ACM Trans. Internet Techn.,2022,"Derui Wang, Sheng Wen, Alireza Jolfaei, Mohammad Sayad Haghighi, Surya Nepal, Yang Xiang 0001",22,https://doi.org/10.1145/3425662
Make Data Reliable: An Explanation-powered Cleaning on Malware Dataset Against Backdoor Poisoning Attacks.,ACSAC,2022,"Xutong Wang, Chaoge Liu, Xiaohui Hu, Zhi Wang, Jie Yin, Xiang Cui",,https://doi.org/10.1145/3564625.3564661
More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks.,ACSAC,2022,"Jing Xu, Rui Wang 0070, Stefanos Koffas, Kaitai Liang, Stjepan Picek",,https://doi.org/10.1145/3564625.3567999
An Approach to Generation Triggers for Parrying Backdoor in Neural Networks.,AGI,2022,,,https://doi.org/10.1007/978-3-031-19907-3_29
Dynamic Backdoors with Global Average Pooling.,AICAS,2022,"Stefanos Koffas, Stjepan Picek, Mauro Conti",,https://doi.org/10.1109/AICAS54282.2022.9869920
Sample-Specific Backdoor based Active Intellectual Property Protection for Deep Neural Networks.,AICAS,2022,"Yinghao Wu, Mingfu Xue, Dujuan Gu, Yushu Zhang, Weiqiang Liu 0001",,https://doi.org/10.1109/AICAS54282.2022.9869927
Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation.,AISec@CCS,2022,"Tong Wu, Tianhao Wang 0021, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal",,https://doi.org/10.1145/3560830.3563730
A collaborative deep learning microservice for backdoor defenses in Industrial IoT networks.,Ad Hoc Networks,2022,"Qin Liu 0001, Liqiong Chen, Hongbo Jiang 0001, Jie Wu 0001, Tian Wang 0001, Tao Peng 0011, Guojun Wang 0001",124,https://doi.org/10.1016/j.adhoc.2021.102727
Boosting the Performance of CDCL-Based SAT Solvers by Exploiting Backbones and Backdoors.,Algorithms,2022,"Tasniem Nasser Al-Yahya, Mohamed El Bachir Menai, Hassan Mathkour",15,https://doi.org/10.3390/a15090302
Active intellectual property protection for deep neural networks through stealthy backdoor and users&apos; identities authentication.,Appl. Intell.,2022,"Mingfu Xue, Shichang Sun, Yushu Zhang, Jian Wang 0038, Weiqiang Liu 0001",52,https://doi.org/10.1007/s10489-022-03339-0
Triggerability of Backdoor Attacks in Multi-Source Transfer Learning-based Intrusion Detection.,BDCAT,2022,"Nour Alhussien, Ahmed Aleroud, Reza Rahaeimehr, Alexander Schwarzmann",,https://doi.org/10.1109/BDCAT56447.2022.00013
An anomaly detection approach for backdoored neural networks: face recognition as a case study.,BIOSIG,2022,"Alexander Unnervik, Sébastien Marcel",,https://dl.gi.de/handle/20.500.12116/39718
Check Your Other Door! Creating Backdoor Attacks in the Frequency Domain.,BMVC,2022,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",,https://bmvc2022.mpi-inf.mpg.de/259/
SentMod: Hidden Backdoor Attack on Unstructured Textual Data.,BigDataSecurity/HPSC/IDS,2022,"Saquib Irtiza, Latifur Khan, Kevin W. Hamlen",,https://doi.org/10.1109/BigDataSecurityHPSCIDS54978.2022.00050
A Federated Learning Backdoor Attack Defense.,BigDataService,2022,"Jin Yan, Yingchi Mao, Hua Nie, Zijian Tu, Jianxin Huang",,https://doi.org/10.1109/BigDataService55688.2022.00030
Verifying Neural Networks Against Backdoor Attacks.,CAV,2022,"Long H. Pham, Jun Sun 0001",,https://doi.org/10.1007/978-3-031-13185-1_9
Poster: Backdoor Attacks on Spiking NNs and Neuromorphic Datasets.,CCS,2022,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",,https://doi.org/10.1145/3548606.3563532
Poster: Clean-label Backdoor Attack on Graph Neural Networks.,CCS,2022,"Jing Xu, Stjepan Picek",,https://doi.org/10.1145/3548606.3563531
Asynchronous Evolutionary Algorithm for Finding Backdoors in Boolean Satisfiability.,CEC,2022,"Artem Pavlenko, Daniil Chivilikhin, Alexander A. Semenov",,https://doi.org/10.1109/CEC55065.2022.9870262
Where to Attack: A Dynamic Locator Model for Backdoor Attack in Text Classifications.,COLING,2022,"Heng-Yang Lu, Chenyou Fan, Jun Yang 0038, Cong Hu, Wei Fang 0001, Xiao-Jun Wu 0001",,https://aclanthology.org/2022.coling-1.82
Learning Pseudo-Backdoors for Mixed Integer Programs.,CPAIOR,2022,"Aaron M. Ferber, Jialin Song, Bistra Dilkina, Yisong Yue",,https://doi.org/10.1007/978-3-031-08011-1_8
Backdoor Attacks on Self-Supervised Learning.,CVPR,2022,"Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash",,https://doi.org/10.1109/CVPR52688.2022.01298
Better Trigger Inversion Optimization in Backdoor Scanning.,CVPR,2022,"Guanhong Tao 0001, Guangyu Shen, Yingqi Liu, Shengwei An, Qiuling Xu, Shiqing Ma, Pan Li, Xiangyu Zhang 0001",,https://doi.org/10.1109/CVPR52688.2022.01301
Complex Backdoor Detection by Symmetric Feature Differencing.,CVPR,2022,"Yingqi Liu, Guangyu Shen, Guanhong Tao 0001, Zhenting Wang, Shiqing Ma, Xiangyu Zhang 0001",,https://doi.org/10.1109/CVPR52688.2022.01458
DEFEAT: Deep Hidden Feature Backdoor Attacks by Imperceptible Perturbation and Latent Representation Constraints.,CVPR,2022,"Zhendong Zhao, Xiaojun Chen 0004, Yuexin Xuan, Ye Dong, Dakui Wang, Kaitai Liang",,https://doi.org/10.1109/CVPR52688.2022.01478
Dual-Key Multimodal Backdoors for Visual Question Answering.,CVPR,2022,"Matthew Walmer, Karan Sikka, Indranil Sur, Abhinav Shrivastava, Susmit Jha",,https://doi.org/10.1109/CVPR52688.2022.01494
FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis.,CVPR,2022,"Yu Feng, Benteng Ma, Jing Zhang 0037, Shanshan Zhao 0001, Yong Xia 0001, Dacheng Tao",,https://doi.org/10.1109/CVPR52688.2022.02021
Few-shot Backdoor Defense Using Shapley Estimation.,CVPR,2022,"Jiyang Guan, Zhuozhuo Tu, Ran He, Dacheng Tao",,https://doi.org/10.1109/CVPR52688.2022.01300
Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks.,CVPR,2022,"Xiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, Kai Bu",,https://doi.org/10.1109/CVPR52688.2022.01299
A Knowledge Distillation-Based Backdoor Attack in Federated Learning.,CoRR,2022,"Yifan Wang, Wei Fan, Keke Yang, Naji Alhusaini, Jing Li 0055",abs/2208.06176,https://doi.org/10.48550/arXiv.2208.06176
ARIBA: Towards Accurate and Robust Identification of Backdoor Attacks in Federated Learning.,CoRR,2022,"Yuxi Mi, Jihong Guan, Shuigeng Zhou",abs/2202.04311,https://arxiv.org/abs/2202.04311
Adaptive Perturbation Generation for Multiple Backdoors Detection.,CoRR,2022,"Yuhang Wang, Huafeng Shi, Rui Min, Ruijia Wu, Siyuan Liang, Yichao Wu, Ding Liang, Aishan Liu",abs/2209.05244,https://doi.org/10.48550/arXiv.2209.05244
Adversarial Fine-tuning for Backdoor Defense: Connect Adversarial Examples to Triggered Samples.,CoRR,2022,"Bingxu Mu, Le Wang 0003, Zhenxing Niu",abs/2202.06312,https://arxiv.org/abs/2202.06312
An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks.,CoRR,2022,"Xinqiao Zhang, Huili Chen, Ke Huang 0001, Farinaz Koushanfar",abs/2204.04329,https://doi.org/10.48550/arXiv.2204.04329
Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning.,CoRR,2022,"Xiaoyi Chen, Baisong Xin, Shengfang Zhai, Shiqing Ma, Qingni Shen, Zhonghai Wu",abs/2210.11082,https://doi.org/10.48550/arXiv.2210.11082
Augmentation Backdoors.,CoRR,2022,"Joseph Rance, Yiren Zhao, Ilia Shumailov, Robert D. Mullins",abs/2209.15139,https://doi.org/10.48550/arXiv.2209.15139
Backdoor Attack against NLP models with Robustness-Aware Perturbation defense.,CoRR,2022,"Shaik Mohammed Maqsood, Viveros Manuela Ceron, Addluri GowthamKrishna",abs/2204.05758,https://doi.org/10.48550/arXiv.2204.05758
Backdoor Attacks in the Supply Chain of Masked Image Modeling.,CoRR,2022,"Xinyue Shen, Xinlei He, Zheng Li 0023, Yun Shen, Michael Backes 0001, Yang Zhang 0016",abs/2210.01632,https://doi.org/10.48550/arXiv.2210.01632
Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution.,CoRR,2022,"Zhixin Pan, Prabhat Mishra 0001",abs/2205.09167,https://doi.org/10.48550/arXiv.2205.09167
Backdoor Attacks on Multiagent Collaborative Systems.,CoRR,2022,"Shuo Chen, Yue Qiu 0004, Jie Zhang",abs/2211.11455,https://doi.org/10.48550/arXiv.2211.11455
Backdoor Attacks on Time Series: A Generative Approach.,CoRR,2022,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey 0001",abs/2211.07915,https://doi.org/10.48550/arXiv.2211.07915
Backdoor Attacks on Vision Transformers.,CoRR,2022,"Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",abs/2206.08477,https://doi.org/10.48550/arXiv.2206.08477
Backdoor Defense in Federated Learning Using Differential Testing and Outlier Detection.,CoRR,2022,"Yein Kim, Huili Chen, Farinaz Koushanfar",abs/2202.11196,https://arxiv.org/abs/2202.11196
Backdoor Detection in Reinforcement Learning.,CoRR,2022,"Junfeng Guo, Ang Li, Cong Liu 0005",abs/2202.03609,https://arxiv.org/abs/2202.03609
Backdoor Vulnerabilities in Normally Trained Deep Learning Models.,CoRR,2022,"Guanhong Tao 0001, Zhenting Wang, Siyuan Cheng 0005, Shiqing Ma, Shengwei An, Yingqi Liu, Guangyu Shen, Zhuo Zhang 0002, Yunshu Mao, Xiangyu Zhang 0001",abs/2211.15929,https://doi.org/10.48550/arXiv.2211.15929
Backdoor Watermarking Deep Learning Classification Models With Deep Fidelity.,CoRR,2022,"Guang Hua 0001, Andrew Beng Jin Teoh",abs/2208.00563,https://doi.org/10.48550/arXiv.2208.00563
Backdooring Explainable Machine Learning.,CoRR,2022,"Maximilian Noppel, Lukas Peter, Christian Wressnegger",abs/2204.09498,https://doi.org/10.48550/arXiv.2204.09498
Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire.,CoRR,2022,"Siddhartha Datta, Nigel Shadbolt",abs/2201.12211,https://arxiv.org/abs/2201.12211
Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape.,CoRR,2022,"Linkun Fan, Fazhi He, Qing Guo, Wei Tang, Xiaolin Hong, Bing Li 0010",abs/2211.16192,https://doi.org/10.48550/arXiv.2211.16192
Black-box Ownership Verification for Dataset Protection via Backdoor Watermarking.,CoRR,2022,"Yiming Li 0004, Mingyan Zhu, Xue Yang 0003, Yong Jiang 0001, Shu-Tao Xia",abs/2209.06015,https://doi.org/10.48550/arXiv.2209.06015
CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences.,CoRR,2022,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang 0001, Yuqing Zhang 0001, Willy Susilo",abs/2206.00145,https://doi.org/10.48550/arXiv.2206.00145
Can Backdoor Attacks Survive Time-Varying Models?,CoRR,2022,"Huiying Li, Arjun Nitin Bhagoji, Ben Y. Zhao, Haitao Zheng 0001",abs/2206.04677,https://doi.org/10.48550/arXiv.2206.04677
Circumventing Backdoor Defenses That Are Based on Latent Separability.,CoRR,2022,"Xiangyu Qi, Tinghao Xie, Saeed Mahloujifar, Prateek Mittal",abs/2205.13613,https://doi.org/10.48550/arXiv.2205.13613
Clean-Annotation Backdoor Attack against Lane Detection Systems in the Wild.,CoRR,2022,"Xingshuo Han, Guowen Xu, Yuan Zhou 0005, Xuehuan Yang, Jiwei Li 0001, Tianwei Zhang 0004",abs/2203.00858,https://doi.org/10.48550/arXiv.2203.00858
Client-Wise Targeted Backdoor in Federated Learning.,CoRR,2022,"Gorka Abad, Servio Paguada, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",abs/2203.08689,https://doi.org/10.48550/arXiv.2203.08689
Close the Gate: Detecting Backdoored Models in Federated Learning based on Client-Side Deep Layer Output Analysis.,CoRR,2022,"Phillip Rieger, Torsten Krauß, Markus Miettinen, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",abs/2210.07714,https://doi.org/10.48550/arXiv.2210.07714
Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer.,CoRR,2022,"Tong Wang, Yuan Yao 0001, Feng Xu 0007, Miao Xu, Shengwei An, Ting Wang",abs/2208.06592,https://doi.org/10.48550/arXiv.2208.06592
Contributor-Aware Defenses Against Adversarial Backdoor Attacks.,CoRR,2022,"Glenn Dawson, Muhammad Umer, Robi Polikar",abs/2206.03583,https://doi.org/10.48550/arXiv.2206.03583
CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning.,CoRR,2022,"Jinghuai Zhang, Hongbin Liu 0005, Jinyuan Jia, Neil Zhenqiang Gong",abs/2211.08229,https://doi.org/10.48550/arXiv.2211.08229
DECK: Model Hardening for Defending Pervasive Backdoors.,CoRR,2022,"Guanhong Tao 0001, Yingqi Liu, Siyuan Cheng 0005, Shengwei An, Zhuo Zhang 0002, Qiuling Xu, Guangyu Shen, Xiangyu Zhang 0001",abs/2206.09272,https://doi.org/10.48550/arXiv.2206.09272
Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World.,CoRR,2022,"Hua Ma, Yinshan Li, Yansong Gao, Alsharif Abuadbba, Zhi Zhang 0001, Anmin Fu, Hyoungshick Kim, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",abs/2201.08619,https://arxiv.org/abs/2201.08619
Defending Against Backdoor Attack on Graph Nerual Network by Explainability.,CoRR,2022,"Bingchen Jiang, Zhao Li",abs/2209.02902,https://doi.org/10.48550/arXiv.2209.02902
Defending Against Stealthy Backdoor Attacks.,CoRR,2022,"Sangeet Sagar, Abhinav Bhatt, Abhijith Srinivas Bidaralli",abs/2205.14246,https://doi.org/10.48550/arXiv.2205.14246
Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons.,CoRR,2022,"Mingyuan Fan, Yang Liu 0118, Cen Chen, Ximeng Liu, Wenzhong Guo",abs/2208.06537,https://doi.org/10.48550/arXiv.2208.06537
Detecting Backdoor Poisoning Attacks on Deep Neural Networks by Heatmap Clustering.,CoRR,2022,"Lukas Schulth, Christian Berghoff, Matthias Neu",abs/2204.12848,https://doi.org/10.48550/arXiv.2204.12848
Detecting Backdoors in Deep Text Classifiers.,CoRR,2022,"You Guo, Jun Wang 0126, Trevor Cohn",abs/2210.11264,https://doi.org/10.48550/arXiv.2210.11264
Enhancing Clean Label Backdoor Attack with Two-phase Specific Triggers.,CoRR,2022,"Nan Luo, Yuanzhang Li, Yajie Wang, Shangbo Wu, Yu-An Tan 0001, Quanxin Zhang",abs/2206.04881,https://doi.org/10.48550/arXiv.2206.04881
FRIB: Low-poisoning Rate Invisible Backdoor Attack based on Feature Repair.,CoRR,2022,"Hui Xia 0001, Xiugui Yang, Xiangyun Qian, Rui Zhang 0050",abs/2207.12863,https://doi.org/10.48550/arXiv.2207.12863
False Memory Formation in Continual Learners Through Imperceptible Backdoor Trigger.,CoRR,2022,"Muhammad Umer, Robi Polikar",abs/2202.04479,https://arxiv.org/abs/2202.04479
Fight Poison with Poison: Detecting Backdoor Poison Samples via Decoupling Benign Correlations.,CoRR,2022,"Xiangyu Qi, Tinghao Xie, Saeed Mahloujifar, Prateek Mittal",abs/2205.13616,https://doi.org/10.48550/arXiv.2205.13616
Fine-Tuning Is All You Need to Mitigate Backdoor Attacks.,CoRR,2022,"Zeyang Sha, Xinlei He, Pascal Berrang, Mathias Humbert, Yang Zhang 0016",abs/2212.09067,https://doi.org/10.48550/arXiv.2212.09067
Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation.,CoRR,2022,"Tianrui Qin, Xianghuan He, Xitong Gao, Yiren Zhao, Kejiang Ye, Cheng-Zhong Xu 0001",abs/2212.09979,https://doi.org/10.48550/arXiv.2212.09979
Hiding Behind Backdoors: Self-Obfuscation Against Generative Models.,CoRR,2022,"Siddhartha Datta, Nigel Shadbolt",abs/2201.09774,https://arxiv.org/abs/2201.09774
ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks.,CoRR,2022,"Tim Clifford, Ilia Shumailov, Yiren Zhao, Ross J. Anderson, Robert D. Mullins",abs/2210.00108,https://doi.org/10.48550/arXiv.2210.00108
Imperceptible and Multi-channel Backdoor Attack against Deep Neural Networks.,CoRR,2022,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Jian Wang 0038, Weiqiang Liu 0001",abs/2201.13164,https://arxiv.org/abs/2201.13164
Invariant Aggregator for Defending Federated Backdoor Attacks.,CoRR,2022,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",abs/2210.01834,https://doi.org/10.48550/arXiv.2210.01834
Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain.,CoRR,2022,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen 0012",abs/2207.04209,https://doi.org/10.48550/arXiv.2207.04209
Label-Smoothed Backdoor Attack.,CoRR,2022,"Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li 0001",abs/2202.11203,https://arxiv.org/abs/2202.11203
Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks.,CoRR,2022,"Siddhartha Datta, Nigel Shadbolt",abs/2203.03692,https://doi.org/10.48550/arXiv.2203.03692
M-to-N Backdoor Paradigm: A Stealthy and Fuzzy Attack to Deep Learning Models.,CoRR,2022,"Linshan Hou, Zhongyun Hua, Yuhong Li, Leo Yu Zhang",abs/2211.01875,https://doi.org/10.48550/arXiv.2211.01875
MACAB: Model-Agnostic Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World.,CoRR,2022,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang 0001, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",abs/2209.02339,https://doi.org/10.48550/arXiv.2209.02339
Mind Your Data! Hiding Backdoors in Offline Reinforcement Learning Datasets.,CoRR,2022,"Chen Gong 0005, Zhou Yang 0003, Yunpeng Bai, Junda He, Jieke Shi, Arunesh Sinha, Bowen Xu, Xinwen Hou, Guoliang Fan, David Lo 0001",abs/2210.04688,https://doi.org/10.48550/arXiv.2210.04688
Model Transferring Attacks to Backdoor HyperNetwork in Personalized Federated Learning.,CoRR,2022,"Phung Lai, NhatHai Phan, Abdallah Khreishah, Issa Khalil, Xintao Wu",abs/2201.07063,https://arxiv.org/abs/2201.07063
Model-Contrastive Learning for Backdoor Defense.,CoRR,2022,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu 0003, Ting Wang 0001, Xian Wei, Mingsong Chen",abs/2205.04411,https://doi.org/10.48550/arXiv.2205.04411
Natural Backdoor Datasets.,CoRR,2022,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Haitao Zheng 0001, Ben Y. Zhao",abs/2206.10673,https://doi.org/10.48550/arXiv.2206.10673
Neighboring Backdoor Attacks on Graph Convolutional Network.,CoRR,2022,"Liang Chen 0001, Qibiao Peng, Jintang Li, Yang Liu 0245, Jiawei Chen 0007, Yong Li, Zibin Zheng",abs/2201.06202,https://arxiv.org/abs/2201.06202
On the Effectiveness of Adversarial Training against Backdoor Attacks.,CoRR,2022,"Yinghua Gao, Dongxian Wu, Jingfeng Zhang, Guanhao Gan, Shu-Tao Xia, Gang Niu 0001, Masashi Sugiyama",abs/2202.10627,https://arxiv.org/abs/2202.10627
PBSM: Backdoor attack against Keyword spotting based on pitch boosting and sound masking.,CoRR,2022,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao 0002, Shunhui Ji",abs/2211.08697,https://doi.org/10.48550/arXiv.2211.08697
PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using Adversarial Perturbations.,CoRR,2022,"Manaar Alam, Esha Sarkar, Michail Maniatakos",abs/2205.13523,https://doi.org/10.48550/arXiv.2205.13523
Physics-Constrained Backdoor Attacks on Power System Fault Localization.,CoRR,2022,"Jianing Bai, Ren Wang, Zuyi Li",abs/2211.04445,https://doi.org/10.48550/arXiv.2211.04445
PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks.,CoRR,2022,"Yue Wang 0055, Wenqing Li, Esha Sarkar, Muhammad Shafique 0001, Michail Maniatakos, Saif Eddin Jabari",abs/2203.09289,https://doi.org/10.48550/arXiv.2203.09289
Planting Undetectable Backdoors in Machine Learning Models.,CoRR,2022,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",abs/2204.06974,https://doi.org/10.48550/arXiv.2204.06974
RFLBAT: A Robust Federated Learning Algorithm against Backdoor Attack.,CoRR,2022,"Yongkang Wang, Dihua Zhai, Yufeng Zhan, Yuanqing Xia",abs/2201.03772,https://arxiv.org/abs/2201.03772
Resurrecting Trust in Facial Recognition: Mitigating Backdoor Attacks in Face Recognition to Prevent Potential Privacy Breaches.,CoRR,2022,"Reena Zelenkova, Jack Swallow, M. A. P. Chamikara, Dongxi Liu, Mohan Baruwal Chhetri, Seyit Camtepe, Marthie Grobler, Mahathir Almashor",abs/2202.10320,https://arxiv.org/abs/2202.10320
Rethink Stealthy Backdoor Attacks in Natural Language Processing.,CoRR,2022,"Lingfeng Shen, Haiyun Jiang, Lemao Liu, Shuming Shi 0001",abs/2201.02993,https://arxiv.org/abs/2201.02993
Rethinking Backdoor Data Poisoning Attacks in the Context of Semi-Supervised Learning.,CoRR,2022,"Marissa Connor, Vincent Emanuele",abs/2212.02582,https://doi.org/10.48550/arXiv.2212.02582
Rickrolling the Artist: Injecting Invisible Backdoors into Text-Guided Image Generation Models.,CoRR,2022,"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",abs/2211.02408,https://doi.org/10.48550/arXiv.2211.02408
"Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models.",CoRR,2022,"Rui Zhu, Di Tang, Siyuan Tang, XiaoFeng Wang 0001, Haixu Tang",abs/2212.04687,https://doi.org/10.48550/arXiv.2212.04687
Solving the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks by Reversing Triggers.,CoRR,2022,"Fangqi Li, Shilin Wang, Yun Zhu",abs/2208.14127,https://doi.org/10.48550/arXiv.2208.14127
Technical Report: Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment.,CoRR,2022,"Tian Liu, Xueyang Hu, Tao Shu",abs/2207.12327,https://doi.org/10.48550/arXiv.2207.12327
Textual Backdoor Attacks with Iterative Trigger Injection.,CoRR,2022,"Jun Yan 0012, Vansh Gupta, Xiang Ren 0001",abs/2205.12700,https://doi.org/10.48550/arXiv.2205.12700
Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning.,CoRR,2022,"Yuxin Wen, Jonas Geiping, Liam Fowl, Hossein Souri, Rama Chellappa, Micah Goldblum, Tom Goldstein",abs/2210.09305,https://doi.org/10.48550/arXiv.2210.09305
Towards A Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures.,CoRR,2022,"Huming Qiu, Hua Ma, Zhi Zhang 0001, Alsharif Abuadbba, Wei Kang, Anmin Fu, Yansong Gao",abs/2204.06273,https://doi.org/10.48550/arXiv.2204.06273
Towards a Defense against Backdoor Attacks in Continual Federated Learning.,CoRR,2022,"Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, Sewoong Oh",abs/2205.11736,https://doi.org/10.48550/arXiv.2205.11736
Trojan Horse Training for Breaking Defenses against Backdoor Attacks in Deep Learning.,CoRR,2022,"Arezoo Rajabi, Bhaskar Ramasubramanian, Radha Poovendran",abs/2203.15506,https://doi.org/10.48550/arXiv.2203.15506
Understanding Impacts of Task Similarity on Backdoor Attack and Detection.,CoRR,2022,"Di Tang, Rui Zhu, XiaoFeng Wang 0001, Haixu Tang, Yi Chen",abs/2210.06509,https://doi.org/10.48550/arXiv.2210.06509
Universal Post-Training Backdoor Detection.,CoRR,2022,"Hang Wang, Zhen Xiang, David J. Miller 0001, George Kesidis",abs/2205.06900,https://doi.org/10.48550/arXiv.2205.06900
VSVC: Backdoor attack against Keyword Spotting based on Voiceprint Selection and Voice Conversion.,CoRR,2022,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao 0002, Shunhui Ji",abs/2212.10103,https://doi.org/10.48550/arXiv.2212.10103
Watermarking Pre-trained Language Models with Backdooring.,CoRR,2022,"Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei Chang, Cho-Jui Hsieh",abs/2210.07543,https://doi.org/10.48550/arXiv.2210.07543
XMAM: X-raying Models with A Matrix to Reveal Backdoor Attacks for Federated Learning.,CoRR,2022,"Jianyi Zhang, Fangjiao Zhang, Qichao Jin, Zhiqiang Wang 0006, Xiaodong Lin, Xiali Hei 0001",abs/2212.13675,https://doi.org/10.48550/arXiv.2212.13675
Backdoor smoothing: Demystifying backdoor attacks on deep neural networks.,Comput. Secur.,2022,"Kathrin Grosse, Taesung Lee, Battista Biggio, Youngja Park, Michael Backes 0001, Ian M. Molloy",120,https://doi.org/10.1016/j.cose.2022.102814
Defense against backdoor attack in federated learning.,Comput. Secur.,2022,"Shiwei Lu, Ruihu Li, Wenbin Liu, Xuan Chen",121,https://doi.org/10.1016/j.cose.2022.102819
PTB: Robust physical backdoor attacks against deep neural networks in real world.,Comput. Secur.,2022,"Mingfu Xue, Can He, Yinghao Wu, Shichang Sun, Yushu Zhang, Jian Wang 0038, Weiqiang Liu 0001",118,https://doi.org/10.1016/j.cose.2022.102726
The triggers that open the NLP model backdoors are hidden in the adversarial samples.,Comput. Secur.,2022,"Kun Shao, Yu Zhang, Junan Yang, Xiaoshuai Li, Hui Liu",118,https://doi.org/10.1016/j.cose.2022.102730
Combining Defences Against Data-Poisoning Based Backdoor Attacks on Neural Networks.,DBSec,2022,"Andrea Milakovic, Rudolf Mayer",,https://doi.org/10.1007/978-3-031-10684-2_3
TextBack: Watermarking Text Classifiers using Backdooring.,DSD,2022,"Nandish Chattopadhyay, Rajan Kataria, Anupam Chattopadhyay",,https://doi.org/10.1109/DSD57027.2022.00053
An Invisible Black-Box Backdoor Attack Through Frequency Domain.,ECCV,2022,"Tong Wang, Yuan Yao 0001, Feng Xu 0007, Shengwei An, Hanghang Tong, Ting Wang",,https://doi.org/10.1007/978-3-031-19778-9_23
Data-Free Backdoor Removal Based on Channel Lipschitzness.,ECCV,2022,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu 0036",,https://doi.org/10.1007/978-3-031-20065-6_11
RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN.,ECCV,2022,"Huy Phan, Cong Shi 0004, Yi Xie 0001, Tianfang Zhang, Zhuohang Li, Tianming Zhao 0001, Jian Liu 0001, Yan Wang 0003, Yingying Chen 0001, Bo Yuan 0001",,https://doi.org/10.1007/978-3-031-19772-7_41
BadDet: Backdoor Attacks on Object Detection.,ECCV Workshops,2022,"Shih-Han Chan, Yinpeng Dong, Jun Zhu 0001, Xiaolu Zhang, Jun Zhou 0011",,https://doi.org/10.1007/978-3-031-25056-9_26
Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling.,EMNLP,2022,"KiYoon Yoo, Nojun Kwak",,https://doi.org/10.18653/v1/2022.emnlp-main.6
Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation.,EMNLP,2022,"Zhiyuan Zhang 0001, Qi Su 0001, Xu Sun 0001",,https://doi.org/10.18653/v1/2022.findings-emnlp.25
Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks.,EMNLP,2022,"Sishuo Chen, Wenkai Yang, Zhiyuan Zhang 0001, Xiaohan Bi, Xu Sun 0001",,https://doi.org/10.18653/v1/2022.findings-emnlp.47
Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models.,EMNLP,2022,"Zhiyuan Zhang 0001, Lingjuan Lyu, Xingjun Ma, Chenguang Wang 0001, Xu Sun 0001",,https://doi.org/10.18653/v1/2022.findings-emnlp.26
Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks.,EMNLP,2022,"Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu 0001, Maosong Sun 0001",,https://doi.org/10.18653/v1/2022.emnlp-main.770
WeDef: Weakly Supervised Backdoor Defense for Text Classification.,EMNLP,2022,"Lesheng Jin, Zihan Wang 0001, Jingbo Shang",,https://doi.org/10.18653/v1/2022.emnlp-main.798
SAT Backdoors: Depth Beats Size.,ESA,2022,"Jan Dreier, Sebastian Ordyniak, Stefan Szeider",,https://doi.org/10.4230/LIPIcs.ESA.2022.46
Kallima: A Clean-Label Framework for Textual Backdoor Attacks.,ESORICS,2022,"Xiaoyi Chen, Yinpeng Dong, Zeyu Sun, Shengfang Zhai, Qingni Shen, Zhonghai Wu",,https://doi.org/10.1007/978-3-031-17140-6_22
The Devil Is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models.,ESORICS,2022,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",,https://doi.org/10.1007/978-3-031-17143-7_41
Dynamic Backdoor Attacks Against Machine Learning Models.,EuroS&amp;P,2022,"Ahmed Salem 0001, Rui Wen 0002, Michael Backes 0001, Shiqing Ma, Yang Zhang 0016",,https://doi.org/10.1109/EuroSP53844.2022.00049
"TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors.",EuroS&amp;P,2022,"Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng 0001, Xiapu Luo, Ting Wang 0006",,https://doi.org/10.1109/EuroSP53844.2022.00048
A Pragmatic Label-Specific Backdoor Attack.,FCS,2022,"Yu Wang, Haomiao Yang, Jiasheng Li, Mengyu Ge",,https://doi.org/10.1007/978-981-19-8445-7_10
Planting Undetectable Backdoors in Machine Learning Models : [Extended Abstract].,FOCS,2022,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",,https://doi.org/10.1109/FOCS54457.2022.00092
A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning.,GLOBECOM,2022,"Yinbo Yu, Jiajia Liu 0001, Shouqing Li, Kepu Huang, Xudong Feng",,https://doi.org/10.1109/GLOBECOM48099.2022.10000751
Propagable Backdoors over Blockchain-based Federated Learning via Sample-Specific Eclipse.,GLOBECOM,2022,"Zheng Yang 0002, Gaolei Li, Jun Wu 0001, Wu Yang 0001",,https://doi.org/10.1109/GLOBECOM48099.2022.10001370
Backdooring Post-Quantum Cryptography: Kleptographic Attacks on Lattice-based KEMs.,IACR Cryptol. ePrint Arch.,2022,"Prasanna Ravi, Shivam Bhasin, Anupam Chattopadhyay, Aikata, Sujoy Sinha Roy",2022,https://eprint.iacr.org/2022/1681
How to Backdoor (Classical) McEliece and How to Guard Against Backdoors.,IACR Cryptol. ePrint Arch.,2022,"Alexander May 0001, Carl Richard Theodor Schneider",2022,https://eprint.iacr.org/2022/362
How to backdoor LWE-like cryptosystems.,IACR Cryptol. ePrint Arch.,2022,,2022,https://eprint.iacr.org/2022/1381
Backdoor Sets on Nowhere Dense SAT.,ICALP,2022,"Daniel Lokshtanov, Fahad Panolan, M. S. Ramanujan 0001",,https://doi.org/10.4230/LIPIcs.ICALP.2022.91
Against Backdoor Attacks In Federated Learning With Differential Privacy.,ICASSP,2022,"Lu Miao, Wei Yang 0011, Rong Hu, Lu Li, Liusheng Huang",,https://doi.org/10.1109/ICASSP43922.2022.9747653
Detecting Backdoor Attacks against Point Cloud Classifiers.,ICASSP,2022,"Zhen Xiang, David J. Miller 0001, Siheng Chen, Xi Li 0015, George Kesidis",,https://doi.org/10.1109/ICASSP43922.2022.9747194
Invisible and Efficient Backdoor Attacks for Compressed Deep Neural Networks.,ICASSP,2022,"Huy Phan, Yi Xie 0001, Jian Liu 0001, Yingying Chen 0001, Bo Yuan 0001",,https://doi.org/10.1109/ICASSP43922.2022.9747582
Stealthy Backdoor Attack with Adversarial Training.,ICASSP,2022,"Le Feng, Sheng Li 0006, Zhenxing Qian, Xinpeng Zhang 0001",,https://doi.org/10.1109/ICASSP43922.2022.9746008
Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural Networks.,ICASSP,2022,"Xi Li 0015, Zhen Xiang, David J. Miller 0001, George Kesidis",,https://doi.org/10.1109/ICASSP43922.2022.9746573
When Does Backdoor Attack Succeed in Image Reconstruction? A Study of Heuristics vs. Bi-Level Solution.,ICASSP,2022,"Vardaan Taneja, Pin-Yu Chen, Yuguang Yao, Sijia Liu 0001",,https://doi.org/10.1109/ICASSP43922.2022.9746433
Toward Cleansing Backdoored Neural Networks in Federated Learning.,ICDCS,2022,"Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra",,https://doi.org/10.1109/ICDCS54860.2022.00084
Towards Backdoor Attack on Deep Learning based Time Series Classification.,ICDE,2022,"Daizong Ding, Mi Zhang 0001, Yuanmin Huang 0001, Xudong Pan, Fuli Feng, Erling Jiang, Min Yang 0002",,https://doi.org/10.1109/ICDE53745.2022.00100
Data Leakage Attack via Backdoor Misclassification Triggers of Deep Learning Models.,ICDIS,2022,"Xiangkai Yang, Wenjian Luo, Licai Zhang, Zhijian Chen, Jiahai Wang",,https://doi.org/10.1109/ICDIS55630.2022.00017
Backdoor Poisoning of Encrypted Traffic Classifiers.,ICDM,2022,"John T. Holodnak, Olivia M. Brown, Jason Matterer, Andrew Lemke",,https://doi.org/10.1109/ICDMW58026.2022.00080
Fooling a Face Recognition System with a Marker-Free Label-Consistent Backdoor Attack.,ICIAP,2022,"Nino Cauli, Alessandro Ortis, Sebastiano Battiato",,https://doi.org/10.1007/978-3-031-06430-2_15
CRAB: Certified Patch Robustness Against Poisoning-Based Backdoor Attacks.,ICIP,2022,"Huxiao Ji, Jie Li 0002, Chentao Wu",,https://doi.org/10.1109/ICIP46576.2022.9897387
AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis.,ICLR,2022,"Junfeng Guo, Ang Li, Cong Liu 0005",,https://openreview.net/forum?id=OM_lYiHXiCL
Adversarial Unlearning of Backdoors via Implicit Hypergradient.,ICLR,2022,"Yi Zeng 0005, Si Chen, Won Park, Zhuoqing Mao, Ming Jin 0002, Ruoxi Jia 0001",,https://openreview.net/forum?id=MeeQkFYVbzW
Backdoor Defense via Decoupling the Training Process.,ICLR,2022,"Kunzhe Huang, Yiming Li 0004, Baoyuan Wu, Zhan Qin, Kui Ren 0001",,https://openreview.net/forum?id=TySnJ-0RdKI
BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models.,ICLR,2022,"Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang 0004, Jiwei Li 0001, Chun Fan",,https://openreview.net/forum?id=Mng8CQ9eBW
Few-Shot Backdoor Attacks on Visual Object Tracking.,ICLR,2022,"Yiming Li 0004, Haoxiang Zhong, Xingjun Ma, Yong Jiang 0001, Shu-Tao Xia",,https://openreview.net/forum?id=qSV5CuSaK_a
How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data.,ICLR,2022,"Zhiyuan Zhang 0001, Lingjuan Lyu, Weiqiang Wang, Lichao Sun 0001, Xu Sun 0001",,https://openreview.net/forum?id=Bn09TnDngN
Poisoning and Backdooring Contrastive Learning.,ICLR,2022,"Nicholas Carlini, Andreas Terzis",,https://openreview.net/forum?id=iC4UHbQ01Mp
Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios.,ICLR,2022,"Zhen Xiang, David J. Miller 0001, George Kesidis",,https://openreview.net/forum?id=MSgB8D4Hy51
Unlabeled Backdoor Poisoning in Semi-Supervised Learning.,ICME,2022,"Le Feng, Sheng Li 0006, Zhenxing Qian, Xinpeng Zhang 0001",,https://doi.org/10.1109/ICME52920.2022.9859941
Constrained Optimization with Dynamic Bound-scaling for Effective NLP Backdoor Defense.,ICML,2022,"Guangyu Shen, Yingqi Liu, Guanhong Tao 0001, Qiuling Xu, Zhuo Zhang 0002, Shengwei An, Shiqing Ma, Xiangyu Zhang 0001",,https://proceedings.mlr.press/v162/shen22e.html
Neurotoxin: Durable Backdoors in Federated Learning.,ICML,2022,"Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Prateek Mittal, Kannan Ramchandran, Joseph Gonzalez 0001",,https://proceedings.mlr.press/v162/zhang22w.html
"A highly efficient, confidential, and continuous federated learning backdoor attack strategy.",ICMLC,2022,"Jiarui Cao, Liehuang Zhu",,https://doi.org/10.1145/3529836.3529845
A Generic Enhancer for Backdoor Attacks on Deep Neural Networks.,ICONIP,2022,"Bilal Hussain Abbasi, Qi Zhong, Leo Yu Zhang, Shang Gao 0003, Antonio Robles-Kelly, Robin Doss",,https://doi.org/10.1007/978-981-99-1648-1_25
Detecting and Mitigating Backdoor Attacks with Dynamic and Invisible Triggers.,ICONIP,2022,"Zhibin Zheng, Zhongyun Hua, Leo Yu Zhang",,https://doi.org/10.1007/978-3-031-30111-7_19
UltraBD: Backdoor Attack against Automatic Speaker Verification Systems via Adversarial Ultrasound.,ICPADS,2022,"Junning Ze, Xinfeng Li, Yushi Cheng, Xiaoyu Ji 0001, Wenyuan Xu 0001",,https://doi.org/10.1109/ICPADS56603.2022.00033
Backdoor Attacks against Deep Neural Networks by Personalized Audio Steganography.,ICPR,2022,"Peng Liu 0044, Shuyi Zhang, Chuanjian Yao, Wenzhe Ye, Xianxian Li",,https://doi.org/10.1109/ICPR56361.2022.9956521
Backdoors in Neural Models of Source Code.,ICPR,2022,"Goutham Ramakrishnan, Aws Albarghouthi",,https://doi.org/10.1109/ICPR56361.2022.9956690
Image Watermarking Backdoor Attacks in CNN-Based Classification Tasks.,ICPR Workshops,2022,"Giovanbattista Abbate, Irene Amerini, Roberto Caldelli",,https://doi.org/10.1007/978-3-031-37745-7_1
Detecting Backdoor Attacks on Deep Neural Networks Based on Model Parameters Analysis.,ICTAI,2022,"Mingyuan Ma, Hu Li, Xiaohui Kuang",,https://doi.org/10.1109/ICTAI56018.2022.00098
A Feature-Based On-Line Detector to Remove Adversarial-Backdoors by Iterative Demarcation.,IEEE Access,2022,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",10,https://doi.org/10.1109/ACCESS.2022.3141077
Backdoor Defence for Voice Print Recognition Model Based on Speech Enhancement and Weight Pruning.,IEEE Access,2022,"Jiawei Zhu, Lin Chen, Dongwei Xu, Wenhong Zhao",10,https://doi.org/10.1109/ACCESS.2022.3217322
Saisiyat Is Where It Is At! Insights Into Backdoors And Debiasing Of Cross Lingual Transformers For Named Entity Recognition.,IEEE Big Data,2022,"Ricardo A. Calix, J. J. Ben-Joseph, Nina Lopatina, Ryan Ashley, Mona Gogia, George Sieniawski, Andrea Brennen",,https://doi.org/10.1109/BigData55660.2022.10020403
Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers.,IEEE Netw.,2022,"Xueluan Gong, Yanjiao Chen, Huayang Huang, Yuqing Liao, Shuai Wang, Qian Wang 0002",36,https://doi.org/10.1109/MNET.011.2000783
Backdoors Against Natural Language Processing: A Review.,IEEE Secur. Priv.,2022,"Shaofeng Li, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Suguo Du, Haojin Zhu",20,https://doi.org/10.1109/MSEC.2022.3181001
Are Backdoor Mandates Ethical? - A Position Paper.,IEEE Technol. Soc. Mag.,2022,"Raphaël Khoury, Sylvain Hallé",41,https://doi.org/10.1109/MTS.2022.3217699
Backdoor Federated Learning-Based mmWave Beam Selection.,IEEE Trans. Commun.,2022,"Zhengming Zhang, Ruming Yang, Xiangyu Zhang 0013, Chunguo Li, Yongming Huang, Luxi Yang",70,https://doi.org/10.1109/TCOMM.2022.3200111
Interpretability-Guided Defense Against Backdoor Attacks to Deep Neural Networks.,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2022,"Wei Jiang 0016, Xiangyu Wen, Jinyu Zhan, Xupeng Wang, Ziwei Song",41,https://doi.org/10.1109/TCAD.2021.3111123
Backdoor Attack on Machine Learning Based Android Malware Detectors.,IEEE Trans. Dependable Secur. Comput.,2022,"Chaoran Li, Xiao Chen 0002, Derui Wang, Sheng Wen, Muhammad Ejaz Ahmed, Seyit Camtepe, Yang Xiang 0001",19,https://doi.org/10.1109/TDSC.2021.3094824
One-to-N &amp; N-to-One: Two Advanced Backdoor Attacks Against Deep Learning Models.,IEEE Trans. Dependable Secur. Comput.,2022,"Mingfu Xue, Can He, Jian Wang 0038, Weiqiang Liu 0001",19,https://doi.org/10.1109/TDSC.2020.3028448
Poison Ink: Robust and Invisible Backdoor Attack.,IEEE Trans. Image Process.,2022,"Jie Zhang 0073, Dongdong Chen 0001, Qidong Huang, Jing Liao 0001, Weiming Zhang 0001, Huamin Feng, Gang Hua 0001, Nenghai Yu",31,https://doi.org/10.1109/TIP.2022.3201472
Mitigating the Backdoor Attack by Federated Filters for Industrial IoT Applications.,IEEE Trans. Ind. Informatics,2022,"Boyu Hou, Jiqiang Gao, Xiaojie Guo 0004, Thar Baker, Ying Zhang 0015, Yanlong Wen, Zheli Liu",18,https://doi.org/10.1109/TII.2021.3112100
Dispersed Pixel Perturbation-Based Imperceptible Backdoor Trigger for Image Classifier Models.,IEEE Trans. Inf. Forensics Secur.,2022,"Yulong Wang, Minghui Zhao, Shenghong Li 0002, Xin Yuan 0004, Wei Ni 0001",17,https://doi.org/10.1109/TIFS.2022.3202687
LinkBreaker: Breaking the Backdoor-Trigger Link in DNNs via Neurons Consistency Check.,IEEE Trans. Inf. Forensics Secur.,2022,"Zhenzhu Chen, Shang Wang, Anmin Fu, Yansong Gao, Shui Yu 0001, Robert H. Deng",17,https://doi.org/10.1109/TIFS.2022.3175616
Stealthy Backdoors as Compression Artifacts.,IEEE Trans. Inf. Forensics Secur.,2022,"Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans 0001",17,https://doi.org/10.1109/TIFS.2022.3160359
Detection of Backdoors in Trained Classifiers Without Access to the Training Set.,IEEE Trans. Neural Networks Learn. Syst.,2022,"Zhen Xiang, David J. Miller 0001, George Kesidis",33,https://doi.org/10.1109/TNNLS.2020.3041202
Model Agnostic Defence Against Backdoor Attacks in Machine Learning.,IEEE Trans. Reliab.,2022,"Sakshi Udeshi, Shanshan Peng, Gerald Woo, Lionell Loh, Louth Rawshan, Sudipta Chattopadhyay 0001",71,https://doi.org/10.1109/TR.2022.3159784
Backdoor Attacks Against Transfer Learning With Pre-Trained Deep Learning Models.,IEEE Trans. Serv. Comput.,2022,"Shuo Wang 0012, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu Chen, Tianle Chen",15,https://doi.org/10.1109/TSC.2020.3000900
Experimental Study of Fault Injection Attack on Image Sensor Interface for Triggering Backdoored DNN Models.,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2022,"Tatsuya Oyama, Shunsuke Okura, Kota Yoshida, Takeshi Fujino",105-A,https://doi.org/10.1587/transfun.2021cip0019
Multi-Model Selective Backdoor Attack with Different Trigger Positions.,IEICE Trans. Inf. Syst.,2022,,105-D,https://doi.org/10.1587/transinf.2021edl8054
Data-Efficient Backdoor Attacks.,IJCAI,2022,"Pengfei Xia, Ziqiang Li 0001, Wei Zhang, Bin Li 0025",,https://doi.org/10.24963/ijcai.2022/554
Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation.,IJCAI,2022,"Jun Xia, Ting Wang 0001, Jiepin Ding, Xian Wei, Mingsong Chen",,https://doi.org/10.24963/ijcai.2022/206
Imperceptible Backdoor Attack: From Input Space to Feature Representation.,IJCAI,2022,"Nan Zhong, Zhenxing Qian, Xinpeng Zhang 0001",,https://doi.org/10.24963/ijcai.2022/242
Membership Inference via Backdooring.,IJCAI,2022,"Hongsheng Hu, Zoran Salcic, Gillian Dobbie, Jinjun Chen, Lichao Sun 0001, Xuyun Zhang",,https://doi.org/10.24963/ijcai.2022/532
PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning.,IJCAI,2022,"Wei Du, Yichun Zhao, Boqun Li, Gongshen Liu, Shilin Wang",,https://doi.org/10.24963/ijcai.2022/96
ACTSS: Input Detection Defense against Backdoor Attacks via Activation Subset Scanning.,IJCNN,2022,"Yuexin Xuan, Xiaojun Chen 0004, Zhendong Zhao, Yangyang Ding, Jianming Lv",,https://doi.org/10.1109/IJCNN55064.2022.9891900
Latent Space-Based Backdoor Attacks Against Deep Neural Networks.,IJCNN,2022,"Adrian Kristanto, Shuo Wang, Carsten Rudolph",,https://doi.org/10.1109/IJCNN55064.2022.9892842
Backdoor Defense with Machine Unlearning.,INFOCOM,2022,"Yang Liu 0118, Mingyuan Fan, Cen Chen, Ximeng Liu, Zhuo Ma, Li Wang 0056, Jianfeng Ma 0001",,https://doi.org/10.1109/INFOCOM48880.2022.9796974
TrojanFlow: A Neural Backdoor Attack to Deep Learning-based Network Traffic Classifiers.,INFOCOM,2022,"Rui Ning, Chunsheng Xin, Hongyi Wu",,https://doi.org/10.1109/INFOCOM48880.2022.9796878
An Improved Method for Making CNN Immune to Backdoor Attack by Activating Clustering.,ISCSIC,2022,"Yuang Zhou, Yichen Lei, Limin Yu, Xianyao Li, Dingding Chen, Tongpo Zhang",,https://doi.org/10.1109/ISCSIC57216.2022.00012
Practical Backdoor Attack Against Speaker Recognition System.,ISPEC,2022,"Yuxiao Luo, Jianwei Tai, Xiaoqi Jia, Shengzhi Zhang",,https://doi.org/10.1007/978-3-031-21280-2_26
Backdoor-resistant identity-based proxy re-encryption for cloud-assisted wireless body area networks.,Inf. Sci.,2022,"Yuyang Zhou, Liang Zhao 0020, Yuqiao Jin, Fagen Li",604,https://doi.org/10.1016/j.ins.2022.05.007
Robust backdoor injection with the capability of resisting network transfer.,Inf. Sci.,2022,"Le Feng, Sheng Li 0006, Zhenxing Qian, Xinpeng Zhang 0001",612,https://doi.org/10.1016/j.ins.2022.08.123
Susceptibility &amp; defense of satellite image-trained convolutional networks to backdoor attacks.,Inf. Sci.,2022,"Ethan Brewer, Jason Lin, Daniel S. Miller Runfola",603,https://doi.org/10.1016/j.ins.2022.05.004
Efficient DNN Backdoor Detection Guided by Static Weight Analysis.,Inscrypt,2022,"Qi Wang, Wenxin Li, Kang Yang, Yiru Zhao, Lei Zhao, Lina Wang 0001",,https://doi.org/10.1007/978-3-031-26553-2_22
A multitarget backdooring attack on deep neural networks with random location trigger.,Int. J. Intell. Syst.,2022,"Xiao Yu 0005, Liu Cong, Mingwen Zheng, Yajie Wang, Xinrui Liu, Song Shuxiao, Ma Yuexuan, Zheng Jun",37,https://doi.org/10.1002/int.22785
Energy-Based Learning for Preventing Backdoor Attack.,KSEM,2022,"Xiangyu Gao, Meikang Qiu",,https://doi.org/10.1007/978-3-031-10989-8_56
Backdoor attacks-resilient aggregation based on Robust Filtering of Outliers in federated learning for image classification.,Knowl. Based Syst.,2022,"Nuria Rodríguez Barroso, Eugenio Martínez-Cámara, María Victoria Luzón, Francisco Herrera",245,https://doi.org/10.1016/j.knosys.2022.108588
I Know Your Triggers: Defending Against Textual Backdoor Attacks with Benign Backdoor Augmentation.,MILCOM,2022,"Yue Gao 0011, Jack W. Stokes, Manoj Ajith Prasad, Andrew T. Marshall, Kassem Fawaz, Emre Kiciman",,https://doi.org/10.1109/MILCOM55135.2022.10017466
Natural Backdoor Attacks on Speech Recognition Models.,ML4CS,2022,"Jinwen Xin, Xixiang Lyu, Jing Ma",,https://doi.org/10.1007/978-3-031-20096-0_45
Breaking Distributed Backdoor Defenses for Federated Learning in Non-IID Settings.,MSN,2022,"Jijia Yang, Jiangang Shu, Xiaohua Jia",,https://doi.org/10.1109/MSN57253.2022.00064
Audio-domain position-independent backdoor attack via unnoticeable triggers.,MobiCom,2022,"Cong Shi 0004, Tianfang Zhang, Zhuohang Li, Huy Phan, Tianming Zhao 0001, Yan Wang 0003, Jian Liu 0001, Bo Yuan 0001, Yingying Chen 0001",,https://doi.org/10.1145/3495243.3560531
BlindNet backdoor: Attack on deep neural network using blind watermark.,Multim. Tools Appl.,2022,"Hyun Kwon, Yongchul Kim",81,https://doi.org/10.1007/s11042-021-11135-0
Triggerless Backdoor Attack for NLP Tasks with Clean Labels.,NAACL-HLT,2022,"Leilei Gan, Jiwei Li 0001, Tianwei Zhang 0004, Xiaoya Li, Yuxian Meng, Fei Wu 0001, Yi Yang 0001, Shangwei Guo, Chun Fan",,https://doi.org/10.18653/v1/2022.naacl-main.214
Distributed Swift and Stealthy Backdoor Attack on Federated Learning.,NAS,2022,"Agnideven Palanisamy Sundar, Feng Li 0001, Xukai Zou, Tianchong Gao",,https://doi.org/10.1109/NAS55553.2022.9925353
ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks.,NDSS,2022,"Xueluan Gong, Yanjiao Chen, Jianshuo Dong, Qian Wang 0002",,https://www.ndss-symposium.org/ndss-paper/auto-draft-238/
DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection.,NDSS,2022,"Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi",,https://www.ndss-symposium.org/ndss-paper/auto-draft-205/
A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks.,NeurIPS,2022,"Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu 0001, Maosong Sun 0001",,http://papers.nips.cc/paper_files/paper/2022/hash/2052b3e0617ecb2ce9474a6feaf422b3-Abstract-Datasets_and_Benchmarks.html
BackdoorBench: A Comprehensive Benchmark of Backdoor Learning.,NeurIPS,2022,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen",,http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html
BadPrompt: Backdoor Attacks on Continuous Prompts.,NeurIPS,2022,"Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang 0015, Xiaojie Yuan",,http://papers.nips.cc/paper_files/paper/2022/hash/f0722b58f02d7793acf7d328928f933a-Abstract-Conference.html
Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples.,NeurIPS,2022,"Weixin Chen, Baoyuan Wu, Haoqian Wang",,http://papers.nips.cc/paper_files/paper/2022/hash/3f9bbf77fbd858e5b6e39d39fe84ed2e-Abstract-Conference.html
Finding Naturally Occurring Physical Backdoors in Image Datasets.,NeurIPS,2022,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Heather Zheng, Ben Y. Zhao",,http://papers.nips.cc/paper_files/paper/2022/hash/8af749935131cc8ea5dae4f6d8cdb304-Abstract-Datasets_and_Benchmarks.html
Handcrafted Backdoors in Deep Neural Networks.,NeurIPS,2022,"Sanghyun Hong 0001, Nicholas Carlini, Alexey Kurakin",,http://papers.nips.cc/paper_files/paper/2022/hash/3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html
Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class.,NeurIPS,2022,"Khoa D. Doan, Yingjie Lao, Ping Li 0001",,http://papers.nips.cc/paper_files/paper/2022/hash/fa0126bb7ebad258bf4ffdbbac2dd787-Abstract-Conference.html
Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models.,NeurIPS,2022,"Biru Zhu, Yujia Qin, Ganqu Cui, Yangyi Chen, Weilin Zhao, Chong Fu, Yangdong Deng, Zhiyuan Liu 0001, Jingang Wang, Wei Wu, Maosong Sun 0001, Ming Gu 0001",,http://papers.nips.cc/paper_files/paper/2022/hash/0799492e7be38b66d10ead5e8809616d-Abstract-Conference.html
One-shot Neural Backdoor Erasing via Adversarial Weight Masking.,NeurIPS,2022,"Shuwen Chai, Jinghui Chen",,http://papers.nips.cc/paper_files/paper/2022/hash/8c0f7107ab85892ccf51f0a814957af1-Abstract-Conference.html
Pre-activation Distributions Expose Backdoor Neurons.,NeurIPS,2022,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu 0036",,http://papers.nips.cc/paper_files/paper/2022/hash/76917808731dae9e6d62c2a7a6afb542-Abstract-Conference.html
Provable Defense against Backdoor Policies in Reinforcement Learning.,NeurIPS,2022,"Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Jerry Zhu",,http://papers.nips.cc/paper_files/paper/2022/hash/5e67e6a814526079ad8505bf6d926fb6-Abstract-Conference.html
Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets.,NeurIPS,2022,"Ruisi Cai, Zhenyu Zhang 0015, Tianlong Chen, Xiaohan Chen, Zhangyang Wang",,http://papers.nips.cc/paper_files/paper/2022/hash/db1d5c63576587fc1d40d33a75190c71-Abstract-Conference.html
Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch.,NeurIPS,2022,"Hossein Souri, Liam Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein",,http://papers.nips.cc/paper_files/paper/2022/hash/79eec295a3cd5785e18c61383e7c996b-Abstract-Conference.html
Training with More Confidence: Mitigating Injected and Natural Backdoors During Training.,NeurIPS,2022,"Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma",,http://papers.nips.cc/paper_files/paper/2022/hash/ec0c9ca85b4ea49c7ebfb503cf55f2ae-Abstract-Conference.html
Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork.,NeurIPS,2022,"Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang",,http://papers.nips.cc/paper_files/paper/2022/hash/ea06e6e9e80f1c3d382317fff67041ac-Abstract-Conference.html
Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection.,NeurIPS,2022,"Yiming Li 0004, Yang Bai, Yong Jiang 0001, Yong Yang 0001, Shu-Tao Xia, Bo Li",,http://papers.nips.cc/paper_files/paper/2022/hash/55bfedfd31489e5ae83c9ce8eec7b0e1-Abstract-Conference.html
How to Backdoor (Classic) McEliece and How to Guard Against Backdoors.,PQCrypto,2022,"Tobias Hemmert, Alexander May 0001, Johannes Mittmann, Carl Richard Theodor Schneider",,https://doi.org/10.1007/978-3-031-17234-2_2
MP-BADNet+: Secure and effective backdoor attack detection and mitigation protocols among multi-participants in private DNNs.,Peer-to-Peer Netw. Appl.,2022,"Congcong Chen, Lifei Wei, Lei Zhang 0080, Ya Peng, Jianting Ning",15,https://doi.org/10.1007/s12083-022-01377-6
Robust Federated Learning for Ubiquitous Computing through Mitigation of Edge-Case Backdoor Attacks.,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2022,"Fatima Elhattab, Sara Bouchenak, Rania Talbi, Vlad Nitu",6,https://doi.org/10.1145/3569492
A Survey on Backdoor Attack and Defense in Natural Language Processing.,QRS,2022,"Xuan Sheng, Zhaoyang Han, Piji Li, Xiangmao Chang",,https://doi.org/10.1109/QRS57517.2022.00086
Transferable Graph Backdoor Attack.,RAID,2022,"Shuiqiao Yang, Bao Gia Doan, Paul Montague, Olivier Y. de Vel, Tamas Abraham, Seyit Camtepe, Damith C. Ranasinghe, Salil S. Kanhere",,https://doi.org/10.1145/3545948.3545976
Deletion-Backdoors for Argumentation Frameworks with Collective Attacks.,SAFA@COMMA,2022,"Wolfgang Dvorák, Matthias König 0002, Stefan Woltran",,https://ceur-ws.org/Vol-3236/paper8.pdf
Backdoor Attack is a Devil in Federated GAN-Based Medical Image Synthesis.,SASHIMI@MICCAI,2022,"Ruinan Jin, Xiaoxiao Li",,https://doi.org/10.1007/978-3-031-16980-9_15
Un-Fair Trojan: Targeted Backdoor Attacks Against Model Fairness.,SDS,2022,"Nicholas Furth, Abdallah Khreishah, Guanxiong Liu, NhatHai Phan, Yaser Jararweh",,https://doi.org/10.1109/SDS57574.2022.10062890
Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment in Mobile Edge Computing.,SECON,2022,"Tian Liu, Xueyang Hu, Tao Shu",,https://doi.org/10.1109/SECON55815.2022.9918550
Inconspicuous Data Augmentation Based Backdoor Attack on Deep Neural Networks.,SOCC,2022,"Chaohui Xu, Wenye Liu, Yue Zheng, Si Wang, Chip-Hong Chang",,https://doi.org/10.1109/SOCC56010.2022.9908113
BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning.,SP,2022,"Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong",,https://doi.org/10.1109/SP46214.2022.9833644
Piccolo: Exposing Complex Backdoors in NLP Transformer Models.,SP,2022,"Yingqi Liu, Guangyu Shen, Guanhong Tao 0001, Shengwei An, Shiqing Ma, Xiangyu Zhang 0001",,https://doi.org/10.1109/SP46214.2022.9833579
Big Brother Is Watching You: A Closer Look at Backdoor Construction.,SPACE,2022,"Anubhab Baksi, Arghya Bhattacharjee, Jakub Breier, Takanori Isobe 0001, Mridul Nandi",,https://doi.org/10.1007/978-3-031-22829-2_5
Never Too Late: Tracing and Mitigating Backdoor Attacks in Federated Learning.,SRDS,2022,"Hui Zeng, Tongqing Zhou, Xinyi Wu, Zhiping Cai",,https://doi.org/10.1109/SRDS55811.2022.00017
VulnerGAN: a backdoor attack through vulnerability amplification against machine learning-based network intrusion detection systems.,Sci. China Inf. Sci.,2022,"Guangrui Liu, Weizhe Zhang, Xinjie Li, Kaisheng Fan, Shui Yu 0001",65,https://doi.org/10.1007/s11432-021-3455-1
Deep Learning Backdoors.,Security and Artificial Intelligence,2022,"Shaofeng Li, Shiqing Ma, Minhui Xue, Benjamin Zi Hao Zhao",,https://doi.org/10.1007/978-3-030-98795-4_13
Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving.,SenSys,2022,"Yan Zhang, Yi Zhu, Zihao Liu, Chenglin Miao, Foad Hajiaghajani, Lu Su, Chunming Qiao",,https://doi.org/10.1145/3560905.3568539
IBD: An Interpretable Backdoor-Detection Method via Multivariate Interactions.,Sensors,2022,"Yixiao Xu, Xiaolei Liu 0001, Kangyi Ding, Bangzhou Xin",22,https://doi.org/10.3390/s22228697
Energy-Based Learning for Polluted Outlier Detection in Backdoor.,SmartCloud,2022,"Xiangyu Gao, Meikang Qiu",,https://doi.org/10.1109/SmartCloud55982.2022.00014
A Novel Backdoor Attack Adapted to Transfer Learning.,SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta,2022,"Peihao Li, Jie Huang 0016, Shuaishuai Zhang, Chunyang Qi, Chuang Liang, Yang Peng",,https://doi.org/10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00246
Patch-Based Backdoors Detection and Mitigation with Feature Masking.,SocialSec,2022,"Tao Wang, Xiaoyu Zhang, Yulin Jin, Chenyang Chen, Fei Zhu",,https://doi.org/10.1007/978-981-19-7242-3_15
A General Backdoor Attack to Graph Neural Networks Based on Explanation Method.,TrustCom,2022,"Luyao Chen, Na Yan, Boyang Zhang, Zhaoyang Wang, Yu Wen, Yanfei Hu",,https://doi.org/10.1109/TrustCom56396.2022.00107
Clean-label Backdoor Attack on Machine Learning-based Malware Detection Models and Countermeasures.,TrustCom,2022,"Wanjia Zheng, Kazumasa Omote",,https://doi.org/10.1109/TrustCom56396.2022.00171
FLAME: Taming Backdoors in Federated Learning.,USENIX Security Symposium,2022,"Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider 0003",,https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen
Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.,USENIX Security Symposium,2022,"Xudong Pan, Mi Zhang 0001, Beina Sheng, Jiaming Zhu, Min Yang 0002",,https://www.usenix.org/conference/usenixsecurity22/presentation/pan-hidden
Low-Poisoning Rate Invisible Backdoor Attack Based on Important Neurons.,WASA,2022,"Xiugui Yang, Xiangyun Qian, Rui Zhang 0050, Ning Huang, Hui Xia 0001",,https://doi.org/10.1007/978-3-031-19214-2_31
Extracting a Minimal Trigger for an Efficient Backdoor Poisoning Attack Using the Activation Values of a Deep Neural Network.,WDC@AsiaCCS,2022,"Hyunsik Na, Daeseon Choi",,https://doi.org/10.1145/3494109.3527192
Can You Hear It?: Backdoor Attacks via Ultrasonic Triggers.,WiseML@WiSec,2022,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",,https://doi.org/10.1145/3522783.3529523
Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings.,AAAI,2021,"Petr Kucera, Petr Savický",,https://doi.org/10.1609/aaai.v35i5.16501
DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation.,AAAI,2021,"Zhicong Yan, Gaolei Li, Yuan Tian 0017, Jun Wu 0001, Shenghong Li 0001, Mingzhe Chen, H. Vincent Poor",,https://doi.org/10.1609/aaai.v35i12.17266
Defending against Backdoors in Federated Learning with Robust Learning Rate.,AAAI,2021,"Mustafa Safa Özdayi, Murat Kantarcioglu, Yulia R. Gel",,https://doi.org/10.1609/aaai.v35i10.17118
Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger.,ACL/IJCNLP,2021,"Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu 0001, Yasheng Wang, Maosong Sun 0001",,https://doi.org/10.18653/v1/2021.acl-long.37
Rethinking Stealthiness of Backdoor Attack against NLP Models.,ACL/IJCNLP,2021,"Wenkai Yang, Yankai Lin, Peng Li 0030, Jie Zhou 0016, Xu Sun 0001",,https://doi.org/10.18653/v1/2021.acl-long.431
Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution.,ACL/IJCNLP,2021,"Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu 0001, Maosong Sun 0001",,https://doi.org/10.18653/v1/2021.acl-long.377
Anti-Distillation Backdoor Attacks: Backdoors Can Really Survive in Knowledge Distillation.,ACM Multimedia,2021,"Yunjie Ge, Qian Wang 0002, Baolin Zheng, Xinlu Zhuang, Qi Li 0002, Chao Shen 0001, Cong Wang 0001",,https://doi.org/10.1145/3474085.3475254
MP-BADNet: A Backdoor-Attack Detection and Identification Protocol among Multi-Participants in Private Deep Neural Networks.,ACM TUR-C,2021,"Congcong Chen, Lifei Wei, Lei Zhang 0080, Jianting Ning",,https://doi.org/10.1145/3472634.3472660
BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements.,ACSAC,2021,"Xiaoyi Chen, Ahmed Salem 0001, Dingfan Chen, Michael Backes 0001, Shiqing Ma, Qingni Shen, Zhonghai Wu, Yang Zhang 0016",,https://doi.org/10.1145/3485832.3485837
DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation.,AsiaCCS,2021,"Han Qiu 0001, Yi Zeng, Shangwei Guo, Tianwei Zhang 0004, Meikang Qiu, Bhavani Thuraisingham",,https://doi.org/10.1145/3433210.3453108
Countermeasures Against Backdoor Attacks Towards Malware Detectors.,CANS,2021,"Shintaro Narisada, Yuki Matsumoto, Seira Hidano, Toshihiro Uchibayashi, Takuo Suganuma, Masahiro Hiji, Shinsaku Kiyomoto",,https://doi.org/10.1007/978-3-030-92548-2_16
Backdoor Pre-trained Models Can Transfer to All.,CCS,2021,"Lujia Shen, Shouling Ji, Xuhong Zhang 0002, Jinfeng Li, Jing Chen 0003, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang 0006",,https://doi.org/10.1145/3460120.3485370
Hidden Backdoors in Human-Centric Language Models.,CCS,2021,"Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu",,https://doi.org/10.1145/3460120.3484576
A Trigger Exploration Method for Backdoor Attacks on Deep Learning-Based Traffic Control Systems.,CDC,2021,"Yue Wang 0055, Michail Maniatakos, Saif Eddin Jabari",,https://doi.org/10.1109/CDC45484.2021.9683577
A physically realizable backdoor attack on 3D point cloud deep learning: work-in-progress.,CODES+ISSS,2021,"Chen Bian, Wei Jiang 0016, Jinyu Zhan, Ziwei Song, Xiangyu Wen, Hong Lei",,https://doi.org/10.1145/3478684.3479254
Reasoning Short Cuts in Infinite Domain Constraint Satisfaction: Algorithms and Lower Bounds for Backdoors.,CP,2021,"Peter Jonsson, Victor Lagerkvist, Sebastian Ordyniak",,https://doi.org/10.4230/LIPIcs.CP.2021.32
Backdoor Attacks Against Deep Learning Systems in the Physical World.,CVPR,2021,"Emily Wenger, Josephine Passananti, Arjun Nitin Bhagoji, Yuanshun Yao, Haitao Zheng 0001, Ben Y. Zhao",,https://openaccess.thecvf.com/content/CVPR2021/html/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.html
A General Framework for Defending Against Backdoor Attacks via Influence Graph.,CoRR,2021,"Xiaofei Sun, Jiwei Li 0001, Xiaoya Li, Ziyao Wang, Tianwei Zhang 0004, Han Qiu 0001, Fei Wu 0001, Chun Fan",abs/2111.14309,https://arxiv.org/abs/2111.14309
A Statistical Difference Reduction Method for Escaping Backdoor Detection.,CoRR,2021,"Pengfei Xia, Hongjing Niu, Ziqiang Li 0001, Bin Li 0025",abs/2111.05077,https://arxiv.org/abs/2111.05077
An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware.,CoRR,2021,"M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang",abs/2110.07683,https://arxiv.org/abs/2110.07683
An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences.,CoRR,2021,"Wei Guo, Benedetta Tondi, Mauro Barni",abs/2111.08429,https://arxiv.org/abs/2111.08429
Anomaly Localization in Model Gradients Under Backdoor Attacks Against Federated Learning.,CoRR,2021,,abs/2111.14683,https://arxiv.org/abs/2111.14683
Backdoor Attack and Defense for Deep Regression.,CoRR,2021,"Xi Li 0015, George Kesidis, David J. Miller 0001, Vladimir Lucic",abs/2109.02381,https://arxiv.org/abs/2109.02381
Backdoor Attack in the Physical World.,CoRR,2021,"Yiming Li 0004, Tongqing Zhai, Yong Jiang 0001, Zhifeng Li 0001, Shu-Tao Xia",abs/2104.02361,https://arxiv.org/abs/2104.02361
Backdoor Attack through Frequency Domain.,CoRR,2021,"Tong Wang, Yuan Yao 0001, Feng Xu 0007, Shengwei An, Hanghang Tong, Ting Wang",abs/2111.10991,https://arxiv.org/abs/2111.10991
Backdoor Attacks on Federated Learning with Lottery Ticket Hypothesis.,CoRR,2021,"Zeyuan Yin, Ye Yuan, Panfeng Guo, Pan Zhou",abs/2109.10512,https://arxiv.org/abs/2109.10512
Backdoor Attacks on Network Certification via Data Poisoning.,CoRR,2021,"Tobias Lorenz 0002, Marta Kwiatkowska, Mario Fritz",abs/2108.11299,https://arxiv.org/abs/2108.11299
Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions.,CoRR,2021,"Antonio Emanuele Cinà, Kathrin Grosse, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",abs/2106.07214,https://arxiv.org/abs/2106.07214
Can You Hear It? Backdoor Attacks via Ultrasonic Triggers.,CoRR,2021,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",abs/2107.14569,https://arxiv.org/abs/2107.14569
CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing.,CoRR,2021,,abs/2112.13064,https://arxiv.org/abs/2112.13064
Check Your Other Door! Establishing Backdoor Attacks in the Frequency Domain.,CoRR,2021,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",abs/2109.05507,https://arxiv.org/abs/2109.05507
Clean-label Backdoor Attack against Deep Hashing based Retrieval.,CoRR,2021,"Kuofeng Gao, Jiawang Bai, Bin Chen 0011, Dongxian Wu, Shu-Tao Xia",abs/2109.08868,https://arxiv.org/abs/2109.08868
DBIA: Data-free Backdoor Injection Attack against Transformer Networks.,CoRR,2021,"Peizhuo Lv, Hualong Ma, Jiachen Zhou, Ruigang Liang, Kai Chen 0012, Shengzhi Zhang, Yunfei Yang",abs/2111.11870,https://arxiv.org/abs/2111.11870
DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations.,CoRR,2021,"Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein",abs/2103.02079,https://arxiv.org/abs/2103.02079
Defending Label Inference and Backdoor Attacks in Vertical Federated Learning.,CoRR,2021,"Yang Liu 0165, Zhihao Yi, Yan Kang 0001, Yuanqin He, Wenhan Liu, Tianyuan Zou, Qiang Yang 0001",abs/2112.05409,https://arxiv.org/abs/2112.05409
EX-RAY: Distinguishing Injected Backdoor from Natural Features in Neural Networks by Examining Differential Feature Symmetry.,CoRR,2021,"Yingqi Liu, Guangyu Shen, Guanhong Tao 0001, Zhenting Wang, Shiqing Ma, Xiangyu Zhang 0001",abs/2103.08820,https://arxiv.org/abs/2103.08820
Explainability Matters: Backdoor Attacks on Medical Imaging.,CoRR,2021,"Munachiso Nwadike, Takumi Miyawaki, Esha Sarkar, Michail Maniatakos, Farah Shamout",abs/2101.00008,https://arxiv.org/abs/2101.00008
Hidden Backdoor Attack against Semantic Segmentation Models.,CoRR,2021,"Yiming Li 0004, Yanjie Li, Yalei Lv, Yong Jiang 0001, Shu-Tao Xia",abs/2103.04038,https://arxiv.org/abs/2103.04038
Machine Learning with Electronic Health Records is vulnerable to Backdoor Trigger Attacks.,CoRR,2021,"Byunggill Joe, Akshay Mehra, Insik Shin, Jihun Hamm",abs/2106.07925,https://arxiv.org/abs/2106.07925
NTD: Non-Transferability Enabled Backdoor Detection.,CoRR,2021,"Yinshan Li, Hua Ma, Zhi Zhang 0001, Yansong Gao, Alsharif Abuadbba, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",abs/2111.11157,https://arxiv.org/abs/2111.11157
On Provable Backdoor Defense in Collaborative Learning.,CoRR,2021,"Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li 0005, Yiran Chen 0001, Hai Li 0001",abs/2101.08177,https://arxiv.org/abs/2101.08177
Poisoning MorphNet for Clean-Label Backdoor Attack to Point Clouds.,CoRR,2021,"Guiyu Tian, Wenhao Jiang, Wei Liu 0005, Yadong Mu",abs/2105.04839,https://arxiv.org/abs/2105.04839
Quantization Backdoors to Deep Learning Models.,CoRR,2021,"Hua Ma, Huming Qiu, Yansong Gao, Zhi Zhang 0001, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Derek Abbott",abs/2108.09187,https://arxiv.org/abs/2108.09187
RABA: A Robust Avatar Backdoor Attack on Deep Neural Network.,CoRR,2021,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong 0002",abs/2104.01026,https://arxiv.org/abs/2104.01026
Red Alarm for Pre-trained Models: Universal Vulnerabilities by Neuron-Level Backdoor Attacks.,CoRR,2021,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu 0001, Yasheng Wang, Xin Jiang 0002, Maosong Sun 0001",abs/2101.06969,https://arxiv.org/abs/2101.06969
SAFELearning: Enable Backdoor Detectability In Federated Learning With Secure Aggregation.,CoRR,2021,"Zhuosheng Zhang 0003, Jiarui Li, Shucheng Yu, Christian Makaya",abs/2102.02402,https://arxiv.org/abs/2102.02402
SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics.,CoRR,2021,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",abs/2104.11315,https://arxiv.org/abs/2104.11315
Spinning Sequence-to-Sequence Models with Meta-Backdoors.,CoRR,2021,,abs/2107.10443,https://arxiv.org/abs/2107.10443
Subnet Replacement: Deployment-stage backdoor attack against deep neural networks in gray-box setting.,CoRR,2021,"Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang",abs/2107.07240,https://arxiv.org/abs/2107.07240
TOP: Backdoor Detection in Neural Networks via Transferability of Perturbation.,CoRR,2021,"Todd Huster, Emmanuel Ekwedike",abs/2103.10274,https://arxiv.org/abs/2103.10274
TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis.,CoRR,2021,"Esha Sarkar, Michail Maniatakos",abs/2108.10132,https://arxiv.org/abs/2108.10132
The Devil is in the GAN: Defending Deep Generative Models Against Backdoor Attacks.,CoRR,2021,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",abs/2108.01644,https://arxiv.org/abs/2108.01644
What Doesn&apos;t Kill You Makes You Robust(er): Adversarial Training against Poisons and Backdoors.,CoRR,2021,"Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael Moeller 0001, Tom Goldstein",abs/2102.13624,https://arxiv.org/abs/2102.13624
Widen The Backdoor To Let More Attackers In.,CoRR,2021,"Siddhartha Datta, Giulio Lovisotto, Ivan Martinovic, Nigel Shadbolt",abs/2110.04571,https://arxiv.org/abs/2110.04571
Backdoor Attack of Graph Neural Networks Based on Subgraph Trigger.,CollaborateCom,2021,"Yu Sheng, Rong Chen, Guanyu Cai, Li Kuang",,https://doi.org/10.1007/978-3-030-92638-0_17
BDDR: An Effective Defense Against Textual Backdoor Attacks.,Comput. Secur.,2021,"Kun Shao, Junan Yang, Yang Ai, Hui Liu, Yu Zhang",110,https://doi.org/10.1016/j.cose.2021.102433
Neural network laundering: Removing black-box backdoor watermarks from deep neural networks.,Comput. Secur.,2021,"William Aiken, Hyoungshick Kim, Simon S. Woo, Jungwoo Ryoo",106,https://doi.org/10.1016/j.cose.2021.102277
Reverse engineering imperceptible backdoor attacks on deep neural networks for detection and training set cleansing.,Comput. Secur.,2021,"Zhen Xiang, David J. Miller 0001, George Kesidis",106,https://doi.org/10.1016/j.cose.2021.102280
Protecting Deep Cerebrospinal Fluid Cell Image Processing Models with Backdoor and Semi-Distillation.,DICTA,2021,"Fang-Qi Li, Shi-Lin Wang, Zhen-Hai Wang",,https://doi.org/10.1109/DICTA52665.2021.9647115
A Random Multi-target Backdooring Attack on Deep Neural Networks.,DMBD,2021,"Xinrui Liu, Xiao Yu 0005, Zhibin Zhang, Quanxin Zhang, Yuanzhang Li, Yu-an Tan 0001",,https://doi.org/10.1007/978-981-16-7502-7_5
Backdoor Filter: Mitigating Visible Backdoor Triggers in Dataset.,DTPI,2021,"Ziqi Wei, Junjian Shi, Yihe Duan, Ranyang Liu, Ye Han, Zheli Liu",,https://doi.org/10.1109/DTPI52967.2021.9540109
BFClass: A Backdoor-free Text Classification Framework.,EMNLP,2021,"Zichao Li 0002, Dheeraj Mekala, Chengyu Dong, Jingbo Shang",,https://doi.org/10.18653/v1/2021.findings-emnlp.40
Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning.,EMNLP,2021,"Linyang Li, Demin Song, Xiaonan Li, Jiehang Zeng, Ruotian Ma, Xipeng Qiu",,https://doi.org/10.18653/v1/2021.emnlp-main.241
Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer.,EMNLP,2021,"Fanchao Qi, Yangyi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu 0001, Maosong Sun 0001",,https://doi.org/10.18653/v1/2021.emnlp-main.374
ONION: A Simple and Effective Defense Against Textual Backdoor Attacks.,EMNLP,2021,"Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu 0001, Maosong Sun 0001",,https://doi.org/10.18653/v1/2021.emnlp-main.752
RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models.,EMNLP,2021,"Wenkai Yang, Yankai Lin, Peng Li 0030, Jie Zhou 0016, Xu Sun 0001",,https://doi.org/10.18653/v1/2021.emnlp-main.659
Generative strategy based backdoor attacks to 3D point clouds: work-in-progress.,EMSOFT,2021,"Xiangyu Wen, Wei Jiang 0016, Jinyu Zhan, Chen Bian, Ziwei Song",,https://doi.org/10.1145/3477244.3477611
Pixdoor: A Pixel-space Backdoor Attack on Deep Learning Models.,EUSIPCO,2021,"Iram Arshad, Mamoona Naveed Asghar, Yuansong Qiao, Brian Lee 0001, Yuhang Ye",,https://doi.org/10.23919/EUSIPCO54536.2021.9616118
Stand-in Backdoor: A Stealthy and Powerful Backdoor Attack.,GLOBECOM,2021,"Shuang Li, Hongwei Li 0001, Hanxiao Chen",,https://doi.org/10.1109/GLOBECOM46510.2021.9685762
Factoring Primes to Factor Moduli: Backdooring and Distributed Generation of Semiprimes.,IACR Cryptol. ePrint Arch.,2021,,2021,https://eprint.iacr.org/2021/1610
How to Backdoor a Cipher.,IACR Cryptol. ePrint Arch.,2021,"Raluca Posteuca, Tomer Ashur",2021,https://eprint.iacr.org/2021/442
Why is Your Trojan NOT Responding? A Quantitative Analysis of Failures in Backdoor Attacks of Neural Networks.,ICA3PP,2021,"Xingbo Hu, Yibing Lan, Ruimin Gao, Guozhu Meng, Kai Chen 0012",,https://doi.org/10.1007/978-3-030-95391-1_47
Backdoor Attack Against Speaker Verification.,ICASSP,2021,"Tongqing Zhai, Yiming Li 0004, Ziqi Zhang, Baoyuan Wu, Yong Jiang 0001, Shu-Tao Xia",,https://doi.org/10.1109/ICASSP39728.2021.9413468
L-Red: Efficient Post-Training Detection of Imperceptible Backdoor Attacks Without Access to the Training Set.,ICASSP,2021,"Zhen Xiang, David J. Miller 0001, George Kesidis",,https://doi.org/10.1109/ICASSP39728.2021.9414562
Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks Without an Accuracy Tradeoff.,ICASSP,2021,"Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas Geiping, Micah Goldblum, Tom Goldstein, Arjun Gupta",,https://doi.org/10.1109/ICASSP39728.2021.9414862
A Backdoor Attack against 3D Point Cloud Classifiers.,ICCV,2021,"Zhen Xiang, David J. Miller 0001, Siheng Chen, Xi Li 0015, George Kesidis",,https://doi.org/10.1109/ICCV48922.2021.00750
Black-box Detection of Backdoor Attacks with Limited Information and Data.,ICCV,2021,"Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang Su 0006, Jun Zhu 0001",,https://doi.org/10.1109/ICCV48922.2021.01617
CLEAR: Clean-up Sample-Targeted Backdoor in Neural Networks.,ICCV,2021,"Liuwan Zhu, Rui Ning, Chunsheng Xin, Chonggang Wang, Hongyi Wu",,https://doi.org/10.1109/ICCV48922.2021.01614
Invisible Backdoor Attack with Sample-Specific Triggers.,ICCV,2021,"Yuezun Li, Yiming Li 0004, Baoyuan Wu, Longkang Li, Ran He 0001, Siwei Lyu",,https://doi.org/10.1109/ICCV48922.2021.01615
"LIRA: Learnable, Imperceptible and Robust Backdoor Attacks.",ICCV,2021,"Khoa D. Doan, Yingjie Lao, Weijie Zhao 0001, Ping Li 0001",,https://doi.org/10.1109/ICCV48922.2021.01175
PointBA: Towards Backdoor Attacks in 3D Point Cloud.,ICCV,2021,"Xinke Li, Zhirui Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim 0001, Joey Tianyi Zhou",,https://doi.org/10.1109/ICCV48922.2021.01618
Rethinking the Backdoor Attacks&apos; Triggers: A Frequency Perspective.,ICCV,2021,"Yi Zeng 0005, Won Park, Z. Morley Mao, Ruoxi Jia 0001",,https://doi.org/10.1109/ICCV48922.2021.01616
BaFFLe: Backdoor Detection via Feedback-based Federated Learning.,ICDCS,2021,"Sébastien Andreina, Giorgia Azzurra Marson, Helen Möllering, Ghassan Karame",,https://doi.org/10.1109/ICDCS51616.2021.00086
Backdoor Investigation and Incident Response: From Zero to Profit.,ICDF2C,2021,"Anthony Cheuk Tung Lai, Ken Wai Kin Wong, Johnny Tsz Wun Wong, Austin Tsz Wai Lau, Alan Po Lun Ho, Shuai Wang, Jogesh Muppala",,https://doi.org/10.1007/978-3-031-06365-7_14
Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks.,ICIP,2021,"Ankita Raj, Ambar Pal, Chetan Arora 0001",,https://doi.org/10.1109/ICIP42928.2021.9506564
Simtrojan: Stealthy Backdoor Attack.,ICIP,2021,"Yankun Ren, Longfei Li, Jun Zhou 0011",,https://doi.org/10.1109/ICIP42928.2021.9506313
Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks.,ICLR,2021,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li 0026, Xingjun Ma",,https://openreview.net/forum?id=9l0K4OM-oXE
WaNet - Imperceptible Warping-based Backdoor Attack.,ICLR,2021,"Tuan Anh Nguyen, Anh Tuan Tran 0001",,https://openreview.net/forum?id=eEn8KTtJOx
Backdoor Scanning for Deep Neural Networks through K-Arm Optimization.,ICML,2021,"Guangyu Shen, Yingqi Liu, Guanhong Tao 0001, Shengwei An, Qiuling Xu, Siyuan Cheng 0005, Shiqing Ma, Xiangyu Zhang 0001",,http://proceedings.mlr.press/v139/shen21c.html
CRFL: Certifiably Robust Federated Learning against Backdoor Attacks.,ICML,2021,"Chulin Xie, Minghao Chen 0001, Pin-Yu Chen, Bo Li 0026",,http://proceedings.mlr.press/v139/xie21a.html
Defense against backdoor attacks via robust covariance estimation.,ICML,2021,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",,http://proceedings.mlr.press/v139/hayase21a.html
Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks.,ICML,2021,"Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P. Dickerson, Tom Goldstein",,http://proceedings.mlr.press/v139/schwarzschild21a.html
ROWBACK: RObust Watermarking for neural networks using BACKdoors.,ICMLA,2021,"Nandish Chattopadhyay, Anupam Chattopadhyay",,https://doi.org/10.1109/ICMLA52953.2021.00274
DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection.,ICSE,2021,"Yuanchun Li, Jiayi Hua, Haoyu Wang 0001, Chunyang Chen, Yunxin Liu",,https://doi.org/10.1109/ICSE43902.2021.00035
Study of scale-free structures in feed-forward neural networks against backdoor attacks.,ICT Express,2021,"Sara Kaviani, Insoo Sohn",7,https://doi.org/10.1016/j.icte.2020.11.004
Use Procedural Noise to Achieve Backdoor Attack.,IEEE Access,2021,"Xuan Chen, Yuena Ma, Shiwei Lu",9,https://doi.org/10.1109/ACCESS.2021.3110239
A Synergetic Attack against Neural Network Classifiers combining Backdoor and Adversarial Examples.,IEEE BigData,2021,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, NhatHai Phan",,https://doi.org/10.1109/BigData52589.2021.9671964
Covid-19 digital Contact-tracing: a doorway to well-being or a backdoor to security vulnerabilities?,IEEE BigData,2021,"Nishit Patel, David Cancel, Moitrayee Chatterjee, Md Shahinoor Rahman",,https://doi.org/10.1109/BigData52589.2021.9671880
Resisting Distributed Backdoor Attacks in Federated Learning: A Dynamic Norm Clipping Approach.,IEEE BigData,2021,"Yifan Guo, Qianlong Wang, Tianxi Ji, Xufei Wang, Pan Li 0001",,https://doi.org/10.1109/BigData52589.2021.9671910
Defense-Resistant Backdoor Attacks Against Deep Neural Networks in Outsourced Cloud Environment.,IEEE J. Sel. Areas Commun.,2021,"Xueluan Gong, Yanjiao Chen, Qian Wang 0002, Huayang Huang, Lingshuo Meng, Chao Shen 0001, Qian Zhang 0001",39,https://doi.org/10.1109/JSAC.2021.3087237
Stability-Based Analysis and Defense against Backdoor Attacks on Edge Computing Services.,IEEE Netw.,2021,"Yi Zhao 0011, Ke Xu 0002, Haiyang Wang, Bo Li 0026, Ruoxi Jia 0001",35,https://doi.org/10.1109/MNET.011.2000265
Bias Busters: Robustifying DL-Based Lithographic Hotspot Detectors Against Backdooring Attacks.,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2021,"Kang Liu 0017, Benjamin Tan 0001, Gaurav Rajavendra Reddy, Siddharth Garg, Yiorgos Makris, Ramesh Karri",40,https://doi.org/10.1109/TCAD.2020.3033749
Training Data Poisoning in ML-CAD: Backdooring DL-Based Lithographic Hotspot Detectors.,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2021,"Kang Liu 0017, Benjamin Tan 0001, Ramesh Karri, Siddharth Garg",40,https://doi.org/10.1109/TCAD.2020.3024780
Invisible Backdoor Attacks on Deep Neural Networks Via Steganography and Regularization.,IEEE Trans. Dependable Secur. Comput.,2021,"Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng Zhang 0001",18,https://doi.org/10.1109/TDSC.2020.3021407
Deep Neural Backdoor in Semi-Supervised Learning: Threats and Countermeasures.,IEEE Trans. Inf. Forensics Secur.,2021,"Zhicong Yan, Jun Wu 0001, Gaolei Li, Shenghong Li 0001, Mohsen Guizani",16,https://doi.org/10.1109/TIFS.2021.3116431
Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-Based Traffic Congestion Control Systems.,IEEE Trans. Inf. Forensics Secur.,2021,"Yue Wang 0055, Esha Sarkar, Wenqing Li, Michail Maniatakos, Saif Eddin Jabari",16,https://doi.org/10.1109/TIFS.2021.3114024
Text Backdoor Detection Using an Interpretable RNN Abstract Model.,IEEE Trans. Inf. Forensics Secur.,2021,"Ming Fan 0002, Ziliang Si, Xiaofei Xie, Yang Liu 0003, Ting Liu 0002",16,https://doi.org/10.1109/TIFS.2021.3103064
FederatedReverse: A Detection and Defense Method Against Backdoor Attacks in Federated Learning.,IH&amp;MMSec,2021,"Chen Zhao, Yu Wen, Shuailou Li, Fucheng Liu, Dan Meng",,https://doi.org/10.1145/3437880.3460403
On the Robustness of Backdoor-based Watermarking in Deep Neural Networks.,IH&amp;MMSec,2021,"Masoumeh Shafieinejad, Nils Lukas, Jiaqi Wang, Xinda Li 0001, Florian Kerschbaum",,https://doi.org/10.1145/3437880.3460401
BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning.,IJCAI,2021,"Lun Wang 0001, Zaynah Javed, Xian Wu, Wenbo Guo 0002, Xinyu Xing, Dawn Song",,https://doi.org/10.24963/ijcai.2021/509
Backdoor DNFs.,IJCAI,2021,"Sebastian Ordyniak, André Schidler, Stefan Szeider",,https://doi.org/10.24963/ijcai.2021/194
Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks.,INFOCOM,2021,"Rui Ning, Jiang Li 0001, Chunsheng Xin, Hongyi Wu",,https://doi.org/10.1109/INFOCOM42981.2021.9488902
TridentShell: a Covert and Scalable Backdoor Injection Attack on Web Applications.,ISC,2021,"Xiaobo Yu, Weizhi Meng 0001, Lei Zhao, Yining Liu 0002",,https://doi.org/10.1007/978-3-030-91356-4_10
AdvDoor: adversarial backdoor attack of deep learning system.,ISSTA,2021,"Quan Zhang, Yifeng Ding, Yongqiang Tian 0001, Jianmin Guo, Min Yuan, Yu Jiang 0001",,https://doi.org/10.1145/3460319.3464809
On-line Functional Testing of Memristor-mapped Deep Neural Networks using Backdoored Checksums.,ITC,2021,"Ching-Yuan Chen, Krishnendu Chakrabarty",,https://doi.org/10.1109/ITC50571.2021.00016
The Design and Development of a Game to Study Backdoor Poisoning Attacks: The Backdoor Game.,IUI,2021,"Zahra Ashktorab, Casey Dugan, James Johnson, Aabhas Sharma, Dustin Ramsey Torres, Ingrid Lange, Benjamin Hoover, Heiko Ludwig, Bryant Chen, Nathalie Baracaldo, Werner Geyer, Qian Pan",,https://doi.org/10.1145/3397481.3450647
BatFL: Backdoor Detection on Federated Learning in e-Health.,IWQoS,2021,"Binhan Xi, Shaofeng Li, Jiachun Li, Hui Liu, Hong Liu, Haojin Zhu",,https://doi.org/10.1109/IWQOS52092.2021.9521339
Embedding asymmetric backdoors into the RSA key generator.,J. Comput. Virol. Hacking Tech.,2021,,17,https://doi.org/10.1007/s11416-020-00363-x
What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors.,KDD,2021,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",,https://doi.org/10.1145/3447548.3467213
Recursive Backdoors for SAT.,MFCS,2021,"Nikolas Mählmann, Sebastian Siebertz, Alexandre Vigny",,https://doi.org/10.4230/LIPIcs.MFCS.2021.73
Adversarial Neuron Pruning Purifies Backdoored Deep Models.,NeurIPS,2021,"Dongxian Wu, Yisen Wang 0001",,https://proceedings.neurips.cc/paper/2021/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html
Anti-Backdoor Learning: Training Clean Models on Poisoned Data.,NeurIPS,2021,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li 0026, Xingjun Ma",,https://proceedings.neurips.cc/paper/2021/hash/7d38b1e9bd793d3f45e0e212a729a93c-Abstract.html
Backdoor Attack with Imperceptible Input and Latent Modification.,NeurIPS,2021,"Khoa D. Doan, Yingjie Lao, Ping Li 0001",,https://proceedings.neurips.cc/paper/2021/hash/9d99197e2ebf03fc388d09f1e94af89b-Abstract.html
Excess Capacity and Backdoor Poisoning.,NeurIPS,2021,"Naren Manoj, Avrim Blum",,https://proceedings.neurips.cc/paper/2021/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html
Detecting Scene-Plausible Perceptible Backdoors in Trained DNNs Without Access to the Training Set.,Neural Comput.,2021,"Zhen Xiang, David J. Miller 0001, Hang Wang, George Kesidis",33,https://doi.org/10.1162/neco_a_01376
Mitigating backdoor attacks in LSTM-based text classification systems by Backdoor Keyword Identification.,Neurocomputing,2021,"Chuanshuai Chen, Jiazhu Dai",452,https://doi.org/10.1016/j.neucom.2021.04.105
A Master Key backdoor for universal impersonation attack against DNN-based face verification.,Pattern Recognit. Lett.,2021,"Wei Guo, Benedetta Tondi, Mauro Barni",144,https://doi.org/10.1016/j.patrec.2021.01.009
Backdoors hidden in facial features: a novel invisible backdoor attack against face recognition systems.,Peer-to-Peer Netw. Appl.,2021,"Mingfu Xue, Can He, Jian Wang 0038, Weiqiang Liu 0001",14,https://doi.org/10.1007/s12083-020-01031-z
Existence versus exploitation: the opacity of backdoors and backbones.,Prog. Artif. Intell.,2021,"Lane A. Hemaspaandra, David E. Narváez",10,https://doi.org/10.1007/s13748-021-00234-6
Identifying and blocking the backdoors in Linux.,RTA-CSIT,2021,"Enkli Ylli, Julian Fejzaj, Igli Tafa",,https://ceur-ws.org/Vol-2872/short07.pdf
Backdoor Attacks to Graph Neural Networks.,SACMAT,2021,"Zaixi Zhang, Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong",,https://doi.org/10.1145/3450569.3463560
A Textual Clean-Label Backdoor Attack Strategy against Spam Detection.,SIN,2021,"Fahri Anil Yerlikaya, Serif Bahtiyar",,https://doi.org/10.1109/SIN54109.2021.9699173
Secure Federated Learning Model Verification: A Client-side Backdoor Triggered Watermarking Scheme.,SMC,2021,"Xiyao Liu 0001, Shuo Shao, Yue Yang, Kangming Wu, Wenyuan Yang, Hui Fang 0003",,https://doi.org/10.1109/SMC52423.2021.9658998
PBDT: Python Backdoor Detection Model Based on Combined Features.,Secur. Commun. Networks,2021,"Yong Fang 0002, Mingyu Xie, Cheng Huang 0003",2021,https://doi.org/10.1155/2021/9923234
"Internet of Things backdoors: Resource management issues, security challenges, and detection methods.",Trans. Emerg. Telecommun. Technol.,2021,"Soheil Hashemi, Mani Zarei",32,https://doi.org/10.1002/ett.4142
Robust Backdoor Attacks against Deep Neural Networks in Real Physical World.,TrustCom,2021,"Mingfu Xue, Can He, Shichang Sun, Jian Wang 0038, Weiqiang Liu 0001",,https://doi.org/10.1109/TrustCom53373.2021.00093
Blind Backdoors in Deep Learning Models.,USENIX Security Symposium,2021,"Eugene Bagdasaryan, Vitaly Shmatikov",,https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan
Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection.,USENIX Security Symposium,2021,"Di Tang, XiaoFeng Wang 0001, Haixu Tang, Kehuan Zhang",,https://www.usenix.org/conference/usenixsecurity21/presentation/tang-di
Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers.,USENIX Security Symposium,2021,"Giorgio Severi, Jim Meyer, Scott E. Coull, Alina Oprea",,https://www.usenix.org/conference/usenixsecurity21/presentation/severi
Graph Backdoor.,USENIX Security Symposium,2021,"Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang 0006",,https://www.usenix.org/conference/usenixsecurity21/presentation/xi
A Backdoor Embedding Method for Backdoor Detection in Deep Neural Networks.,UbiSec,2021,"Meirong Liu, Hong Zheng, Qin Liu 0001, Xiaofei Xing, Yinglong Dai",,https://doi.org/10.1007/978-981-19-0468-4_1
Explainability-based Backdoor Attacks Against Graph Neural Networks.,WiseML@WiSec,2021,"Jing Xu, Minhui Xue, Stjepan Picek",,https://doi.org/10.1145/3468218.3469046
Inaudible Manipulation of Voice-Enabled Devices Through BackDoor Using Robust Adversarial Audio Attacks: Invited Paper.,WiseML@WiSec,2021,"Morriel Kasher, Michael Zhao, Aryeh Greenberg, Devin Gulati, Silvija Kokalj-Filipovic, Predrag Spasojevic",,https://doi.org/10.1145/3468218.3469048
Cryptographic Primitives that Resist Backdooring and Subversion.,,2020,,,http://tuprints.ulb.tu-darmstadt.de/14550/
Hidden Trigger Backdoor Attacks.,AAAI,2020,"Aniruddha Saha, Akshayvarun Subramanya, Hamed Pirsiavash",,https://doi.org/10.1609/aaai.v34i07.6871
GangSweep: Sweep out Neural Backdoors by GAN.,ACM Multimedia,2020,"Liuwan Zhu, Rui Ning, Cong Wang 0006, Chunsheng Xin, Hongyi Wu",,https://doi.org/10.1145/3394171.3413546
Embedding Backdoors as the Facial Features: Invisible Backdoor Attacks Against Face Recognition Systems.,ACM TUR-C,2020,"Can He, Mingfu Xue, Jian Wang 0038, Weiqiang Liu 0001",,https://doi.org/10.1145/3393527.3393567
Optimizing Deep Learning Based Intrusion Detection Systems Defense Against White-Box and Backdoor Adversarial Attacks Through a Genetic Algorithm.,AIPR,2020,"Khaled Alrawashdeh, Stephen Goldsmith",,https://doi.org/10.1109/AIPR50011.2020.9425293
Differentiable Causal Backdoor Discovery.,AISTATS,2020,"Limor Gultchin, Matt J. Kusner, Varun Kanade, Ricardo Silva",,http://proceedings.mlr.press/v108/gultchin20a.html
How To Backdoor Federated Learning.,AISTATS,2020,"Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly Shmatikov",,http://proceedings.mlr.press/v108/bagdasaryan20a.html
Disabling Backdoor and Identifying Poison Data by using Knowledge Distillation in Backdoor Attacks on Deep Neural Networks.,AISec@CCS,2020,"Kota Yoshida, Takeshi Fujino",,https://doi.org/10.1145/3411508.3421375
Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign Features.,CCS,2020,"Junyu Lin, Lei Xu 0003, Yingqi Liu, Xiangyu Zhang 0001",,https://doi.org/10.1145/3372297.3423362
Can Adversarial Weight Perturbations Inject Neural Backdoors.,CIKM,2020,"Siddhant Garg, Adarsh Kumar 0001, Vibhor Goel, Yingyu Liang",,https://doi.org/10.1145/3340531.3412130
Backdoor Embedding in Convolutional Neural Network Models via Invisible Perturbation.,CODASPY,2020,"Haoti Zhong, Cong Liao, Anna Cinzia Squicciarini, Sencun Zhu, David J. Miller 0001",,https://doi.org/10.1145/3374664.3375751
The MALICIOUS Framework: Embedding Backdoors into Tweakable Block Ciphers.,CRYPTO,2020,"Thomas Peyrin, Haoyang Wang 0001",,https://doi.org/10.1007/978-3-030-56877-1_9
Clean-Label Backdoor Attacks on Video Recognition Models.,CVPR,2020,"Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey 0001, Jingjing Chen, Yu-Gang Jiang",,https://openaccess.thecvf.com/content_CVPR_2020/html/Zhao_Clean-Label_Backdoor_Attacks_on_Video_Recognition_Models_CVPR_2020_paper.html
Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs.,CVPR,2020,"Soheil Kolouri, Aniruddha Saha, Hamed Pirsiavash, Heiko Hoffmann",,https://openaccess.thecvf.com/content_CVPR_2020/html/Kolouri_Universal_Litmus_Patterns_Revealing_Backdoor_Attacks_in_CNNs_CVPR_2020_paper.html
Systematic Evaluation of Backdoor Data Poisoning Attacks on Image Classifiers.,CVPR Workshops,2020,"Loc Truong, Chace Jones, Brian Hutchinson, Andrew August, Brenda Praggastis, Robert Jasper, Nicole Nichols, Aaron Tuor",,https://openaccess.thecvf.com/content_CVPRW_2020/html/w47/Truong_Systematic_Evaluation_of_Backdoor_Data_Poisoning_Attacks_on_Image_Classifiers_CVPRW_2020_paper.html
A new measure for overfitting and its implications for backdooring of deep learning.,CoRR,2020,"Kathrin Grosse, Taesung Lee, Youngja Park, Michael Backes 0001, Ian M. Molloy",abs/2006.06721,https://arxiv.org/abs/2006.06721
BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models.,CoRR,2020,"Ahmed Salem 0001, Yannick Sautter, Michael Backes 0001, Mathias Humbert, Yang Zhang 0016",abs/2010.03007,https://arxiv.org/abs/2010.03007
Backdoor Attack with Sample-Specific Triggers.,CoRR,2020,"Yuezun Li, Yiming Li 0004, Baoyuan Wu, Longkang Li, Ran He 0001, Siwei Lyu",abs/2012.03816,https://arxiv.org/abs/2012.03816
Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review.,CoRR,2020,"Yansong Gao, Bao Gia Doan, Zhi Zhang 0001, Siqi Ma, Jiliang Zhang 0002, Anmin Fu, Surya Nepal, Hyoungshick Kim",abs/2007.10760,https://arxiv.org/abs/2007.10760
Backdoor Attacks on Facial Recognition in the Physical World.,CoRR,2020,"Emily Wenger, Josephine Passananti, Yuanshun Yao, Haitao Zheng 0001, Ben Y. Zhao",abs/2006.14580,https://arxiv.org/abs/2006.14580
Backdoor Attacks on Federated Meta-Learning.,CoRR,2020,"Chien-Lun Chen, Leana Golubchik, Marco Paolieri",abs/2006.07026,https://arxiv.org/abs/2006.07026
Backdoor attacks and defenses in feature-partitioned collaborative learning.,CoRR,2020,"Yang Liu 0165, Zhihao Yi, Tianjian Chen",abs/2007.03608,https://arxiv.org/abs/2007.03608
BadNL: Backdoor Attacks Against NLP Models.,CoRR,2020,"Xiaoyi Chen, Ahmed Salem 0001, Michael Backes 0001, Shiqing Ma, Yang Zhang 0016",abs/2006.01043,https://arxiv.org/abs/2006.01043
Can Adversarial Weight Perturbations Inject Neural Backdoors?,CoRR,2020,"Siddhant Garg, Adarsh Kumar 0001, Vibhor Goel, Yingyu Liang",abs/2008.01761,https://arxiv.org/abs/2008.01761
Defending against Backdoor Attack on Deep Neural Networks.,CoRR,2020,"Hao Cheng, Kaidi Xu, Sijia Liu 0001, Pin-Yu Chen, Pu Zhao 0001, Xue Lin",abs/2002.12162,https://arxiv.org/abs/2002.12162
Detecting Backdoors in Neural Networks Using Novel Feature-Based Anomaly Detection.,CoRR,2020,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",abs/2011.02526,https://arxiv.org/abs/2011.02526
Don&apos;t Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks.,CoRR,2020,"Ahmed Salem 0001, Michael Backes 0001, Yang Zhang 0016",abs/2010.03282,https://arxiv.org/abs/2010.03282
Dynamic backdoor attacks against federated learning.,CoRR,2020,,abs/2011.07429,https://arxiv.org/abs/2011.07429
EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks.,CoRR,2020,"Lubin Meng, Jian Huang 0001, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu",abs/2011.00101,https://arxiv.org/abs/2011.00101
Effect of backdoor attacks over the complexity of the latent space distribution.,CoRR,2020,"Henry D. Chacon, Paul Rad",abs/2012.01931,https://arxiv.org/abs/2012.01931
Exploring Backdoor Poisoning Attacks Against Malware Classifiers.,CoRR,2020,"Giorgio Severi, Jim Meyer, Scott E. Coull, Alina Oprea",abs/2003.01031,https://arxiv.org/abs/2003.01031
Exposing Backdoors in Robust Machine Learning Models.,CoRR,2020,"Ezekiel O. Soremekun, Sakshi Udeshi, Sudipta Chattopadhyay 0001, Andreas Zeller",abs/2003.00865,https://arxiv.org/abs/2003.00865
FaceHack: Triggering backdoored facial recognition systems using facial characteristics.,CoRR,2020,"Esha Sarkar, Hadjer Benkraouda, Michail Maniatakos",abs/2006.11623,https://arxiv.org/abs/2006.11623
HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor Attacks for Data Collection Scenarios.,CoRR,2020,"Hassan Ali 0001, Surya Nepal, Salil S. Kanhere, Sanjay Jha 0001",abs/2012.07474,https://arxiv.org/abs/2012.07474
Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition Systems.,CoRR,2020,"Haoliang Li, Yufei Wang, Xiaofei Xie, Yang Liu 0003, Shiqi Wang 0001, Renjie Wan, Lap-Pui Chau, Alex C. Kot",abs/2009.06996,https://arxiv.org/abs/2009.06996
Mitigating Backdoor Attacks in Federated Learning.,CoRR,2020,"Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra",abs/2011.01767,https://arxiv.org/abs/2011.01767
NNoculation: Broad Spectrum and Targeted Treatment of Backdoored DNNs.,CoRR,2020,"Akshaj Kumar Veldanda, Kang Liu 0017, Benjamin Tan 0001, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg",abs/2002.08313,https://arxiv.org/abs/2002.08313
Natural Backdoor Attack on Text Data.,CoRR,2020,,abs/2006.16176,https://arxiv.org/abs/2006.16176
Noise-response Analysis for Rapid Detection of Backdoors in Deep Neural Networks.,CoRR,2020,"N. Benjamin Erichson, Dane Taylor, Qixuan Wu, Michael W. Mahoney",abs/2008.00123,https://arxiv.org/abs/2008.00123
On Certifying Robustness against Backdoor Attacks via Randomized Smoothing.,CoRR,2020,"Binghui Wang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong",abs/2002.11750,https://arxiv.org/abs/2002.11750
On Evaluating Neural Network Backdoor Defenses.,CoRR,2020,"Akshaj Kumar Veldanda, Siddharth Garg",abs/2010.12186,https://arxiv.org/abs/2010.12186
Open-sourced Dataset Protection via Backdoor Watermarking.,CoRR,2020,"Yiming Li 0004, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang 0001, Shu-Tao Xia",abs/2010.05821,https://arxiv.org/abs/2010.05821
"Poisoned classifiers are not only backdoored, they are fundamentally broken.",CoRR,2020,"Mingjie Sun, Siddhant Agarwal, J. Zico Kolter",abs/2010.09080,https://arxiv.org/abs/2010.09080
Rethinking the Trigger of Backdoor Attack.,CoRR,2020,"Yiming Li 0004, Tongqing Zhai, Baoyuan Wu, Yong Jiang 0001, Zhifeng Li 0001, Shutao Xia",abs/2004.04692,https://arxiv.org/abs/2004.04692
TROJANZOO: Everything you ever wanted to know about neural backdoors (but were afraid to ask).,CoRR,2020,"Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng 0001, Ting Wang 0006",abs/2012.09302,https://arxiv.org/abs/2012.09302
Towards a Backdoorless Network Architecture Based on Remote Attestation and Backdoor Inspection.,CoRR,2020,"Takayuki Sasaki, Yusuke Shimada",abs/2007.14748,https://arxiv.org/abs/2007.14748
Watch your back: Backdoor Attacks in Deep Reinforcement Learning-based Autonomous Vehicle Control Systems.,CoRR,2020,"Yue Wang 0055, Esha Sarkar, Michail Maniatakos, Saif Eddin Jabari",abs/2003.07859,https://arxiv.org/abs/2003.07859
What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors.,CoRR,2020,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",abs/2009.10639,https://arxiv.org/abs/2009.10639
TrojDRL: Evaluation of Backdoor Attacks on Deep Reinforcement Learning.,DAC,2020,"Panagiota Kiourti, Kacper Wardega, Susmit Jha, Wenchao Li 0001",,https://doi.org/10.1109/DAC18072.2020.9218663
One-Pixel Signature: Characterizing CNN Models for Backdoor Detection.,ECCV,2020,"Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu",,https://doi.org/10.1007/978-3-030-58583-9_20
Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks.,ECCV,2020,"Yunfei Liu, Xingjun Ma, James Bailey 0001, Feng Lu 0005",,https://doi.org/10.1007/978-3-030-58607-2_11
Scalable Backdoor Detection in Neural Networks.,ECML/PKDD,2020,"Haripriya Harikumar, Vuong Le, Santu Rana, Sourangshu Bhattacharya, Sunil Gupta 0001, Svetha Venkatesh",,https://doi.org/10.1007/978-3-030-67661-2_18
Interpretability Derived Backdoor Attacks Detection in Deep Neural Networks: Work-in-Progress.,EMSOFT,2020,"Xiangyu Wen, Wei Jiang 0016, Jinyu Zhan, Xupeng Wang, Zhiyuan He 0001",,https://doi.org/10.1109/EMSOFT51651.2020.9244019
Trembling triggers: exploring the sensitivity of backdoors in DNN-based face recognition.,EURASIP J. Inf. Secur.,2020,"Cecilia Pasquini, Rainer Böhme",2020,https://doi.org/10.1186/s13635-020-00104-z
Biometric Backdoors: A Poisoning Attack Against Unsupervised Template Updating.,EuroS&amp;P,2020,"Giulio Lovisotto, Simon Eberz, Ivan Martinovic",,https://doi.org/10.1109/EuroSP48549.2020.00020
Bypassing Backdoor Detection Algorithms in Deep Learning.,EuroS&amp;P,2020,"Te Juin Lester Tan, Reza Shokri",,https://doi.org/10.1109/EuroSP48549.2020.00019
"Revealing Backdoors, Post-Training, in DNN Classifiers via Novel Inference on Optimized Perturbations Inducing Group Misclassification.",ICASSP,2020,"Zhen Xiang, David J. Miller 0001, George Kesidis",,https://doi.org/10.1109/ICASSP40776.2020.9054581
Towards Inspecting and Eliminating Trojan Backdoors in Deep Neural Networks.,ICDM,2020,"Wenbo Guo 0002, Lun Wang 0001, Yan Xu, Xinyu Xing, Min Du, Dawn Song",,https://doi.org/10.1109/ICDM50108.2020.00025
TargetNet Backdoor: Attack on Deep Neural Network with Use of Different Triggers.,ICIIT,2020,"Hyun Kwon, Jungmin Roh, Hyunsoo Yoon, Ki-Woong Park",,https://doi.org/10.1145/3385209.3385216
A Defence Against Input-Agnostic Backdoor Attacks on Deep Neural Networks.,ICISS,2020,"Yansong Gao, Surya Nepal",,https://doi.org/10.1007/978-3-030-65610-2_4
Backdooring Deep Learning Architectures: Threats and (some) Opportunities.,ICISSP,2020,,,
DBA: Distributed Backdoor Attacks against Federated Learning.,ICLR,2020,"Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li 0026",,https://openreview.net/forum?id=rkgyS0VFvr
Robust anomaly detection and backdoor attack detection via differential privacy.,ICLR,2020,"Min Du, Ruoxi Jia 0001, Dawn Song",,https://openreview.net/forum?id=SJx0q1rtvS
Segmentation Based Backdoor Attack Detection.,ICMLC,2020,"Natasha Kees, Yaxuan Wang, Yiling Jiang, Fang Lue, Patrick P. K. Chan",,https://doi.org/10.1109/ICMLC51923.2020.9469037
Removing Backdoor-Based Watermarks in Neural Networks with Limited Data.,ICPR,2020,"Xuankai Liu, Fengting Li, Bihan Wen, Qi Li 0002",,https://doi.org/10.1109/ICPR48806.2021.9412684
FriendNet Backdoor: Indentifying Backdoor Attack that is safe for Friendly Deep Neural Network.,ICSIM,2020,"Hyun Kwon, Hyunsoo Yoon, Ki-Woong Park",,https://doi.org/10.1145/3378936.3378938
Application of complex systems in neural networks against Backdoor attacks.,ICTC,2020,"Sara Kaviani, Insoo Sohn, Huaping Liu 0002",,https://doi.org/10.1109/ICTC49870.2020.9289220
Detecting Backdoor Attacks via Class Difference in Deep Neural Networks.,IEEE Access,2020,,8,https://doi.org/10.1109/ACCESS.2020.3032411
Backdoor Suppression in Neural Networks using Input Fuzzing and Majority Voting.,IEEE Des. Test,2020,"Esha Sarkar, Yousif Alkindi, Michail Maniatakos",37,https://doi.org/10.1109/MDAT.2020.2968275
Backdoor Attacks and Defenses for Deep Neural Networks in Outsourced Cloud Environments.,IEEE Netw.,2020,"Yanjiao Chen, Xueluan Gong, Qian Wang 0002, Xing Di, Huayang Huang",34,https://doi.org/10.1109/MNET.011.1900577
Multi-Targeted Backdoor: Indentifying Backdoor Attack for Multiple Deep Neural Networks.,IEICE Trans. Inf. Syst.,2020,"Hyun Kwon, Hyunsoo Yoon, Ki-Woong Park",103-D,https://doi.org/10.1587/transinf.2019EDL8170
Backdooring Convolutional Neural Networks via Targeted Weight Perturbations.,IJCB,2020,"Jacob Dumford, Walter J. Scheirer",,https://doi.org/10.1109/IJCB48548.2020.9304875
Targeted Forgetting and False Memory Formation in Continual Learners through Adversarial Backdoor Attacks.,IJCNN,2020,"Muhammad Umer, Glenn Dawson, Robi Polikar",,https://doi.org/10.1109/IJCNN48605.2020.9206809
Defending Deep Learning Based Anomaly Detection Systems Against White-Box Adversarial Examples and Backdoor Attacks.,ISTAS,2020,"Khaled Alrawashdeh, Stephen Goldsmith",,https://doi.org/10.1109/ISTAS50296.2020.9462227
Backdoors into Two Occurrences.,J. Satisf. Boolean Model. Comput.,2020,,12,https://doi.org/10.3233/sat-200125
A Causally Formulated Hazard Ratio Estimation through Backdoor Adjustment on Structural Causal Model.,MLHC,2020,"Riddhiman Adib, Paul M. Griffin, Sheikh Iqbal Ahamed, Mohammad Adibuzzaman",,http://proceedings.mlr.press/v126/adib20a.html
"Revealing Perceptible Backdoors in DNNs, Without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic.",MLSP,2020,"Zhen Xiang, David J. Miller 0001, Hang Wang, George Kesidis",,https://doi.org/10.1109/MLSP49062.2020.9231861
"Attack of the Tails: Yes, You Really Can Backdoor Federated Learning.",NeurIPS,2020,"Hongyi Wang 0001, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee 0001, Dimitris S. Papailiopoulos",,https://proceedings.neurips.cc/paper/2020/hash/b8ffa41d4e492f0fad2f13e29e1762eb-Abstract.html
Input-Aware Dynamic Backdoor Attack.,NeurIPS,2020,"Tuan Anh Nguyen, Anh Tuan Tran 0001",,https://proceedings.neurips.cc/paper/2020/hash/234e691320c0ad5b45ee3c96d0d7b8f8-Abstract.html
On the Trade-off between Adversarial and Backdoor Robustness.,NeurIPS,2020,"Cheng-Hsin Weng, Yan-Ting Lee, Shan-Hung Wu",,https://proceedings.neurips.cc/paper/2020/hash/8b4066554730ddfaa0266346bdc1b202-Abstract.html
Escaping Backdoor Attack Detection of Deep Learning.,SEC,2020,"Yayuan Xiong, Fengyuan Xu, Sheng Zhong 0002, Qun Li 0001",,https://doi.org/10.1007/978-3-030-58201-2_29
Backdooring and Poisoning Neural Networks with Image-Scaling Attacks.,SP,2020,"Erwin Quiring, Konrad Rieck",,https://doi.org/10.1109/SPW50608.2020.00024
Towards Defeating Backdoored Random Oracles: Indifferentiability with Bounded Adaptivity.,TCC,2020,"Yevgeniy Dodis, Pooya Farshim, Sogol Mazaheri, Stefano Tessaro",,https://doi.org/10.1007/978-3-030-64381-2_9
Detecting acoustic backdoor transmission of inaudible messages using deep learning.,WiseML@WiSec,2020,"Silvija Kokalj-Filipovic, Morriel Kasher, Michael Zhao, Predrag Spasojevic",,https://doi.org/10.1145/3395352.3402629
Backdoors for Linear Temporal Logic.,Algorithmica,2019,"Arne Meier, Sebastian Ordyniak, M. S. Ramanujan 0001, Irena Schindler",81,https://doi.org/10.1007/s00453-018-0515-5
Backdoors to planning.,Artif. Intell.,2019,"Martin Kronegger, Sebastian Ordyniak, Andreas Pfandler",269,https://doi.org/10.1016/j.artint.2018.10.002
Walling up Backdoors in Intrusion Detection Systems.,Big-DAMA@CoNEXT,2019,"Maximilian Bachl, Alexander Hartl, Joachim Fabini, Tanja Zseby",,https://doi.org/10.1145/3359992.3366638
Latent Backdoor Attacks on Deep Neural Networks.,CCS,2019,"Yuanshun Yao, Huiying Li, Haitao Zheng 0001, Ben Y. Zhao",,https://doi.org/10.1145/3319535.3354209
Backdoor Attacks in Neural Networks - A Systematic Evaluation on Multiple Traffic Sign Datasets.,CD-MAKE,2019,"Huma Rehman, Andreas Ekelhart, Rudolf Mayer",,https://doi.org/10.1007/978-3-030-29726-8_18
Adversarial Audio: A New Information Hiding Method and Backdoor for DNN-based Speech Recognition Models.,CoRR,2019,"Yehao Kong, Jiliang Zhang 0002",abs/1904.03829,http://arxiv.org/abs/1904.03829
BSEA-1 - A Stream Cipher Backdooring Technique.,CoRR,2019,,abs/1903.11063,http://arxiv.org/abs/1903.11063
Can You Really Backdoor Federated Learning?,CoRR,2019,"Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan",abs/1911.07963,http://arxiv.org/abs/1911.07963
Design of intentional backdoors in sequential models.,CoRR,2019,"Zhaoyuan Yang, Naresh Iyer, Johan Reimann, Nurali Virani",abs/1902.09972,http://arxiv.org/abs/1902.09972
Invisible Backdoor Attacks Against Deep Neural Networks.,CoRR,2019,"Shaofeng Li, Benjamin Zi Hao Zhao, Jiahao Yu, Minhui Xue, Dali Kaafar, Haojin Zhu",abs/1909.02742,http://arxiv.org/abs/1909.02742
Label-Consistent Backdoor Attacks.,CoRR,2019,"Alexander Turner 0001, Dimitris Tsipras, Aleksander Madry",abs/1912.02771,http://arxiv.org/abs/1912.02771
NeuronInspect: Detecting Backdoors in Neural Networks via Output Explanations.,CoRR,2019,"Xijie Huang, Moustafa Alzantot, Mani B. Srivastava",abs/1911.07399,http://arxiv.org/abs/1911.07399
On the Robustness of the Backdoor-based Watermarking in Deep Neural Networks.,CoRR,2019,"Masoumeh Shafieinejad, Jiaqi Wang, Nils Lukas, Florian Kerschbaum",abs/1906.07745,http://arxiv.org/abs/1906.07745
Poison as a Cure: Detecting &amp; Neutralizing Variable-Sized Backdoor Attacks in Deep Neural Networks.,CoRR,2019,"Alvin Chan, Yew-Soon Ong",abs/1911.08040,http://arxiv.org/abs/1911.08040
Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks.,CoRR,2019,"Yuanshun Yao, Huiying Li, Haitao Zheng 0001, Ben Y. Zhao",abs/1905.10447,http://arxiv.org/abs/1905.10447
"Revealing Perceptible Backdoors, without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic.",CoRR,2019,"Zhen Xiang, David J. Miller 0001, George Kesidis",abs/1911.07970,http://arxiv.org/abs/1911.07970
TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems.,CoRR,2019,"Wenbo Guo 0002, Lun Wang 0001, Xinyu Xing, Min Du, Dawn Song",abs/1908.01763,http://arxiv.org/abs/1908.01763
The Tale of Evil Twins: Adversarial Inputs versus Backdoored Models.,CoRR,2019,"Ren Pang, Xinyang Zhang 0001, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Ting Wang 0006",abs/1911.01559,http://arxiv.org/abs/1911.01559
Cryptography with Disposable Backdoors.,Cryptogr.,2019,"Kai-Min Chung, Marios Georgiou 0001, Ching-Yi Lai, Vassilis Zikas",3,https://doi.org/10.3390/cryptography3030022
I Want to Break Square-free: The 4p - 1 Factorization Method and Its RSA Backdoor Viability.,ICETE,2019,"Vladimir Sedlacek, Dusan Klinec, Marek Sýs, Petr Svenda, Vashek Matyas",,https://doi.org/10.5220/0007786600250036
A New Backdoor Attack in CNNS by Training Set Corruption Without Label Poisoning.,ICIP,2019,"Mauro Barni, Kassem Kallas, Benedetta Tondi",,https://doi.org/10.1109/ICIP.2019.8802997
A Backdoor Attack Against LSTM-Based Text Classification Systems.,IEEE Access,2019,"Jiazhu Dai, Chuanshuai Chen, Yufeng Li 0002",7,https://doi.org/10.1109/ACCESS.2019.2941376
BadNets: Evaluating Backdooring Attacks on Deep Neural Networks.,IEEE Access,2019,"Tianyu Gu, Kang Liu 0017, Brendan Dolan-Gavitt, Siddharth Garg",7,https://doi.org/10.1109/ACCESS.2019.2909068
Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks.,IEEE Symposium on Security and Privacy,2019,"Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao Zheng 0001, Ben Y. Zhao",,https://doi.org/10.1109/SP.2019.00031
True2F: Backdoor-Resistant Authentication Tokens.,IEEE Symposium on Security and Privacy,2019,"Emma Dauterman, Henry Corrigan-Gibbs, David Mazières, Dan Boneh, Dominic Rizzo",,https://doi.org/10.1109/SP.2019.00048
Is Backside the New Backdoor in Modern SoCs?: Invited Paper.,ITC,2019,"Nidish Vashistha, M. Tanjidur Rahman, Olivia P. Paradis, Navid Asadizanjani",,https://doi.org/10.1109/ITC44170.2019.9000127
How to Subvert Backdoored Encryption: Security Against Adversaries that Decrypt All Ciphertexts.,ITCS,2019,"Thibaut Horel, Sunoo Park, Silas Richelson, Vinod Vaikuntanathan",,https://doi.org/10.4230/LIPIcs.ITCS.2019.42
Testing the Human Backdoor: Organizational Response to a Phishing Campaign.,J. Univers. Comput. Sci.,2019,"Anze Mihelic, Matej Jevscek, Simon Vrhovec, Igor Bernik",25,http://www.jucs.org/jucs_25_11/testing_the_human_backdoor
Towards Leveraging Backdoors in Qualitative Constraint Networks.,KI,2019,"Michael Sioutis, Tomi Janhunen",,https://doi.org/10.1007/978-3-030-30179-8_27
A Benchmark Study Of Backdoor Data Poisoning Defenses For Deep Neural Network Classifiers And A Novel Defense.,MLSP,2019,"Zhen Xiang, David J. Miller 0001, George Kesidis",,https://doi.org/10.1109/MLSP.2019.8918908
Luminance-based video backdoor attack against anti-spoofing rebroadcast detection.,MMSP,2019,"Abhir Bhalerao, Kassem Kallas, Benedetta Tondi, Mauro Barni",,https://doi.org/10.1109/MMSP.2019.8901711
Interbank Networks and Backdoor Bailouts: Benefiting from Other Banks&apos; Government Guarantees.,Manag. Sci.,2019,"Tim Eisert, Christian Eufinger",65,https://doi.org/10.1287/mnsc.2017.2968
Defending Neural Backdoors via Generative Distribution Modeling.,NeurIPS,2019,"Ximing Qiao, Yukun Yang 0001, Hai Li 0001",,https://proceedings.neurips.cc/paper/2019/hash/78211247db84d96acf4e00092a7fba80-Abstract.html
On Embedding Backdoor in Malware Detectors Using Machine Learning.,PST,2019,"Shoichiro Sasaki, Seira Hidano, Toshihiro Uchibayashi, Takuo Suganuma, Masahiro Hiji, Shinsaku Kiyomoto",,https://doi.org/10.1109/PST47121.2019.8949034
Existence Versus Exploitation: The Opacity of Backdoors and Backbones Under a Weak Assumption.,SOFSEM,2019,"Lane A. Hemaspaandra, David E. Narváez",,https://doi.org/10.1007/978-3-030-10801-4_20
Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering.,SafeAI@AAAI,2019,"Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian M. Molloy, Biplav Srivastava",,https://ceur-ws.org/Vol-2301/paper_18.pdf
Backdoor detection systems for embedded devices.,,2018,,,https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.753100
On Cryptographic Attacks Using Backdoors for SAT.,AAAI,2018,"Alexander A. Semenov, Oleg Zaikin 0002, Ilya V. Otpuschennikov, Stepan Kochemazov, Alexey Ignatiev",,https://doi.org/10.1609/aaai.v32i1.12205
Real-time Detection of Passive Backdoor Behaviors on Android System.,CNS,2018,"Yao Yao, Lipeng Zhu, He Wang 0014",,https://doi.org/10.1109/CNS.2018.8433190
Learning-Sensitive Backdoors with Restarts.,CP,2018,"Edward Zulkoski, Ruben Martins, Christoph M. Wintersteiger, Robert Robere, Jia Hui Liang, Krzysztof Czarnecki 0001, Vijay Ganesh",,https://doi.org/10.1007/978-3-319-98334-9_30
From Backdoor Key to Backdoor Completability: Improving a Known Measure of Hardness for the Satisfiable CSP.,CPAIOR,2018,"Guillaume Escamocher, Mohamed Siala 0002, Barry O&apos;Sullivan",,https://doi.org/10.1007/978-3-319-93031-2_14
Combiners for Backdoored Random Oracles.,CRYPTO,2018,"Balthazar Bauer, Pooya Farshim, Sogol Mazaheri",,https://doi.org/10.1007/978-3-319-96881-0_10
Backdoored Hash Functions: Immunizing HMAC and HKDF.,CSF,2018,"Marc Fischlin, Christian Janson, Sogol Mazaheri",,https://doi.org/10.1109/CSF.2018.00015
Backdoor Decomposable Monotone Circuits and their Propagation Complete Encodings.,CoRR,2018,"Petr Kucera, Petr Savický",abs/1811.09435,http://arxiv.org/abs/1811.09435
How a simple bug in ML compiler could be exploited for backdoors?,CoRR,2018,,abs/1811.10851,http://arxiv.org/abs/1811.10851
Technical perspective: Backdoor engineering.,Commun. ACM,2018,,61,https://doi.org/10.1145/3266289
Remote Desktop Backdoor Implementation with Reverse TCP Payload Using Open Source Tools for Instructional Use.,EIT,2018,"Yaswanth Kolli, Tauheed Khan Mohd, Ahmad Y. Javaid",,https://doi.org/10.1109/EIT.2018.8500174
Backdoor Attacks on Neural Network Operations.,GlobalSIP,2018,"Joseph Clements 0001, Yingjie Lao",,https://doi.org/10.1109/GlobalSIP.2018.8646335
Cryptography with Dispensable Backdoors.,IACR Cryptol. ePrint Arch.,2018,"Kai-Min Chung, Marios Georgiou 0001, Ching-Yi Lai, Vassilis Zikas",2018,https://eprint.iacr.org/2018/352
On the Existence of Non-Linear Invariants and Algebraic Polynomial Constructive Approach to Backdoors in Block Ciphers.,IACR Cryptol. ePrint Arch.,2018,,2018,https://eprint.iacr.org/2018/807
UFO - Hidden Backdoor Discovery and Security Verification in IoT Device Firmware.,ISSRE Workshops,2018,"Chin-Wei Tien, Tsung-Ta Tsai, Ing-Yi Chen, Sy-Yen Kuo",,https://doi.org/10.1109/ISSREW.2018.00-37
Spectral Signatures in Backdoor Attacks.,NeurIPS,2018,"Brandon Tran, Jerry Li 0001, Aleksander Madry",,https://proceedings.neurips.cc/paper/2018/hash/280cf18baf4311c92aa5a042336587d3-Abstract.html
"Backdoors: Definition, Deniability and Detection.",RAID,2018,"Sam L. Thomas, Aurélien Francillon",,https://doi.org/10.1007/978-3-030-00470-5_5
Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks.,RAID,2018,"Kang Liu 0017, Brendan Dolan-Gavitt, Siddharth Garg",,https://doi.org/10.1007/978-3-030-00470-5_13
ALIAS: A Modular Tool for Finding Backdoors for SAT.,SAT,2018,"Stepan Kochemazov, Oleg Zaikin 0002",,https://doi.org/10.1007/978-3-319-94144-8_25
Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring.,USENIX Security Symposium,2018,"Yossi Adi, Carsten Baum, Moustapha Cissé, Benny Pinkas, Joseph Keshet",,https://www.usenix.org/conference/usenixsecurity18/presentation/adi
Backdoor Trees for Answer Set Programming.,ASPOCP@LPNMR,2017,"Johannes Klaus Fichte, Stefan Szeider",,https://ceur-ws.org/Vol-1868/p9.pdf
Backdoor attacks against learning systems.,CNS,2017,"Yujie Ji, Xinyang Zhang 0001, Ting Wang 0006",,https://doi.org/10.1109/CNS.2017.8228656
Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning.,CoRR,2017,"Xinyun Chen, Chang Liu 0021, Bo Li 0026, Kimberly Lu, Dawn Song",abs/1712.05526,http://arxiv.org/abs/1712.05526
The Opacity of Backbones and Backdoors Under a Weak Assumption.,CoRR,2017,"Lane A. Hemaspaandra, David E. Narváez",abs/1706.04582,http://arxiv.org/abs/1706.04582
Stringer: Measuring the Importance of Static Data Comparisons to Detect Backdoors and Undocumented Functionality.,ESORICS,2017,"Sam L. Thomas, Tom Chothia, Flavio D. Garcia",,https://doi.org/10.1007/978-3-319-66399-9_28
"BackDoor: Sounds that a microphone can record, but that humans can&apos;t hear.",GetMobile Mob. Comput. Commun.,2017,"Nirupam Roy, Haitham Hassanieh, Romit Roy Choudhury",21,https://doi.org/10.1145/3191789.3191799
Mathematical Backdoors in Symmetric Encryption Systems - Proposal for a Backdoored AES-like Block Cipher.,ICISSP,2017,"Arnaud Bannier, Eric Filiol",,https://doi.org/10.5220/0006244406220631
Low-cost detection of backdoor malware.,ICITST,2017,"Huicong Loi, Aspen Olmsted",,https://doi.org/10.23919/ICITST.2017.8356377
Backdoors into heterogeneous classes of SAT and CSP.,J. Comput. Syst. Sci.,2017,"Serge Gaspers, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider, Stanislav Zivný",85,https://doi.org/10.1016/j.jcss.2016.10.007
Open Sesame! Design and Implementation of Backdoor to Secretly Unlock Android Devices.,J. Internet Serv. Inf. Secur.,2017,"Junsung Cho, Geumhwan Cho, Sangwon Hyun, Hyoungshick Kim",7,https://doi.org/10.22667/JISIS.2017.11.30.035
BackDoor: Making Microphones Hear Inaudible Sounds.,MobiSys,2017,"Nirupam Roy, Haitham Hassanieh, Romit Roy Choudhury",,https://doi.org/10.1145/3081333.3081366
Indiscreet Logs: Diffie-Hellman Backdoors in TLS.,NDSS,2017,"Kristen Dorey, Nicholas Chang-Fong, Aleksander Essex",,https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/indiscreet-logs-persistent-diffie-hellman-backdoors-tls/
Backdoor Treewidth for SAT.,SAT,2017,"Robert Ganian, M. S. Ramanujan 0001, Stefan Szeider",,https://doi.org/10.1007/978-3-319-66263-3_2
Combining Treewidth and Backdoors for CSP.,STACS,2017,"Robert Ganian, M. S. Ramanujan 0001, Stefan Szeider",,https://doi.org/10.4230/LIPIcs.STACS.2017.36
Backdoor Sets for CSP.,The Constraint Satisfaction Problem,2017,"Serge Gaspers, Sebastian Ordyniak, Stefan Szeider",,https://doi.org/10.4230/DFU.Vol7.15301.5
Backdoors to q-Horn.,Algorithmica,2016,"Serge Gaspers, Sebastian Ordyniak, M. S. Ramanujan 0001, Saket Saurabh 0001, Stefan Szeider",74,https://doi.org/10.1007/s00453-014-9958-5
Backdoors to Tractable Valued CSP.,CP,2016,"Robert Ganian, M. S. Ramanujan 0001, Stefan Szeider",,https://doi.org/10.1007/978-3-319-44953-1_16
Backdoors in Pseudorandom Number Generators: Possibility and Impossibility Results.,CRYPTO,2016,"Jean Paul Degabriele, Kenneth G. Paterson, Jacob C. N. Schuldt, Joanne Woodage",,https://doi.org/10.1007/978-3-662-53018-4_15
Strong Backdoors for Linear Temporal Logic.,CoRR,2016,"Arne Meier, Sebastian Ordyniak, M. S. Ramanujan 0001, Irena Schindler",abs/1602.04934,http://arxiv.org/abs/1602.04934
No backdoor required or expected.,Commun. ACM,2016,,59,https://doi.org/10.1145/2931085
Backdoors to SAT.,Encyclopedia of Algorithms,2016,,,https://doi.org/10.1007/978-1-4939-2864-4_781
A Formal Treatment of Backdoored Pseudorandom Generators.,IACR Cryptol. ePrint Arch.,2016,"Yevgeniy Dodis, Chaya Ganesh, Alexander Golovnev, Ari Juels, Thomas Ristenpart",2016,http://eprint.iacr.org/2016/306
DEcryption Contract ENforcement Tool (DECENT): A Practical Alternative to Government Decryption Backdoors.,IACR Cryptol. ePrint Arch.,2016,,2016,http://eprint.iacr.org/2016/245
How to Backdoor Diffie-Hellman.,IACR Cryptol. ePrint Arch.,2016,,2016,http://eprint.iacr.org/2016/644
Indiscreet Logs: Persistent Diffie-Hellman Backdoors in TLS.,IACR Cryptol. ePrint Arch.,2016,"Kristen Dorey, Nicholas Chang-Fong, Aleksander Essex",2016,http://eprint.iacr.org/2016/999
Controlled Randomness - A Defense Against Backdoors in Cryptographic Devices.,Mycrypt,2016,"Lucjan Hanzlik, Kamil Kluczniak, Miroslaw Kutylowski",,https://doi.org/10.1007/978-3-319-61273-7_11
Detecting Stealthy Backdoors and Port Knocking Sequences through Flow Analysis.,Prax. Inf.verarb. Kommun.,2016,"Felix von Eye, Michael Grabatin, Wolfgang Hommel",38,http://www.degruyter.com/view/j/piko.2015.38.issue-3-4/pik-2015-0011/pik-2015-0011.xml
Strong Backdoors for Default Logic.,SAT,2016,"Johannes Klaus Fichte, Arne Meier, Irina Schindler",,https://doi.org/10.1007/978-3-319-40970-2_4
Variable-Deletion Backdoors to Planning.,AAAI,2015,"Martin Kronegger, Sebastian Ordyniak, Andreas Pfandler",,https://doi.org/10.1609/aaai.v29i1.9662
Backdoors to Normality for Disjunctive Logic Programs.,ACM Trans. Comput. Log.,2015,"Johannes Klaus Fichte, Stefan Szeider",17,https://doi.org/10.1145/2818646
Backdoors to tractable answer set programming.,Artif. Intell.,2015,"Johannes Klaus Fichte, Stefan Szeider",220,https://doi.org/10.1016/j.artint.2014.12.001
Internet-facing PLCs as a network backdoor.,CNS,2015,"Johannes Klick, Stephan Lau, Daniel Marzin, Jan-Ole Malchow, Volker Roth 0002",,https://doi.org/10.1109/CNS.2015.7346865
Netzbasierte Erkennung von mittels Port Knocking verstecksten Dienstern und Backdoors.,DFN-Forum Kommunikationstechnologien,2015,"Felix von Eye, Michael Grabatin, Wolfgang Hommel",,https://dl.gi.de/handle/20.500.12116/2362
Integrated Sensor: A Backdoor for Hardware Trojan Insertions?,DSD,2015,"Xuan Thuy Ngo, Zakaria Najm, Shivam Bhasin, Debapriya Basu Roy, Jean-Luc Danger, Sylvain Guilley",,https://doi.org/10.1109/DSD.2015.119
Covert remote syscall communication at kernel level: A SPOOKY backdoor.,MALWARE,2015,"Florian Kerber, Dominik Teubert, Ulrike Meyer",,https://doi.org/10.1109/MALWARE.2015.7413687
Devil in a box: Installing backdoors in electronic door locks.,PST,2015,"Seongyeol Oh, Joon-Sung Yang, Andrea Bianchi, Hyoungshick Kim",,https://doi.org/10.1109/PST.2015.7232965
Solving d-SAT via Backdoors to Small Treewidth.,SODA,2015,"Fedor V. Fomin, Daniel Lokshtanov, Neeldhara Misra, M. S. Ramanujan 0001, Saket Saurabh 0001",,https://doi.org/10.1137/1.9781611973730.43
Tradeoffs in the complexity of backdoors to satisfiability: dynamic sub-solvers and learning during search.,Ann. Math. Artif. Intell.,2014,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",70,https://doi.org/10.1007/s10472-014-9407-9
On Backdoors to Tractable Constraint Languages.,CP,2014,"Clément Carbonnel, Martin C. Cooper, Emmanuel Hebrard",,https://doi.org/10.1007/978-3-319-10428-7_18
Backdoor.,Datenschutz und Datensicherheit,2014,,38,https://doi.org/10.1007/s11623-014-0045-5
Answer Set Solver Backdoors.,JELIA,2014,"Emilia Oikarinen, Matti Järvisalo",,https://doi.org/10.1007/978-3-319-11558-0_51
Backdoors to Tractability of Answer-Set Programming.,AAAI,2013,,,https://doi.org/10.1609/aaai.v27i1.8505
Implementation and implications of a stealth hard-drive backdoor.,ACSAC,2013,"Jonas Zaddach, Anil Kurmus, Davide Balzarotti, Erik-Oliver Blass, Aurélien Francillon, Travis Goodspeed, Moitrayee Gupta, Ioannis Koltsidas",,https://doi.org/10.1145/2523649.2523661
Towards reducing the attack surface of software backdoors.,CCS,2013,"Felix Schuster, Thorsten Holz",,https://doi.org/10.1145/2508859.2516716
A generalized backdoor criterion.,CoRR,2013,"Marloes H. Maathuis, Diego Colombo",abs/1307.5636,http://arxiv.org/abs/1307.5636
Backdoors to Abduction,CoRR,2013,"Andreas Pfandler, Stefan Rümmele, Stefan Szeider",abs/1304.5961,http://arxiv.org/abs/1304.5961
Backdoors to Normality for Disjunctive Logic Programs,CoRR,2013,"Johannes Klaus Fichte, Stefan Szeider",abs/1301.1391,http://arxiv.org/abs/1301.1391
Upper and Lower Bounds for Weak Backdoor Set Detection,CoRR,2013,"Neeldhara Misra, Sebastian Ordyniak, Venkatesh Raman 0001, Stefan Szeider",abs/1304.5518,http://arxiv.org/abs/1304.5518
Preventing Backdoors in Server Applications with a Separated Software Architecture - (Short Paper).,DIMVA,2013,"Felix Schuster, Stefan Rüster, Thorsten Holz",,https://doi.org/10.1007/978-3-642-39235-1_12
Strong Backdoors to Bounded Treewidth SAT.,FOCS,2013,"Serge Gaspers, Stefan Szeider",,https://doi.org/10.1109/FOCS.2013.59
Backdoors to Abduction.,IJCAI,2013,"Andreas Pfandler, Stefan Rümmele, Stefan Szeider",,http://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6912
Crowdsourcing Backdoor Identification for Combinatorial Optimization.,IJCAI,2013,"Ronan LeBras, Richard Bernstein, Carla P. Gomes, Bart Selman, R. Bruce van Dover",,http://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6993
Backdoor Branching.,INFORMS J. Comput.,2013,"Matteo Fischetti, Michele Monaci",25,https://doi.org/10.1287/ijoc.1120.0531
Upper and Lower Bounds for Weak Backdoor Set Detection.,SAT,2013,"Neeldhara Misra, Sebastian Ordyniak, Venkatesh Raman 0001, Stefan Szeider",,https://doi.org/10.1007/978-3-642-39071-5_29
Vulnerability-Based Backdoors: Threats from Two-step Trojans.,SERE,2013,"Kai Chen 0012, Yingjun Zhang, Yifeng Lian",,https://doi.org/10.1109/SERE.2013.19
Backdoors to the Tractability of Answer Set Programming.,Theory Pract. Log. Program.,2013,,13,http://static.cambridge.org/resource/id/urn:cambridge.org:id:binary:20161018085635834-0697:S1471068413000112:tlp2013034.pdf
Breakthrough Silicon Scanning Discovers Backdoor in Military Chip.,CHES,2012,"Sergei Skorobogatov, Christopher Woods",,https://doi.org/10.1007/978-3-642-33027-8_2
Strong Backdoors to Bounded Treewidth SAT,CoRR,2012,"Serge Gaspers, Stefan Szeider",abs/1204.6233,http://arxiv.org/abs/1204.6233
Strong Backdoors to Nested Satisfiability,CoRR,2012,"Serge Gaspers, Stefan Szeider",abs/1202.4331,http://arxiv.org/abs/1202.4331
Backdoors to Acyclic SAT.,ICALP,2012,"Serge Gaspers, Stefan Szeider",,https://doi.org/10.1007/978-3-642-31594-7_31
A Framework to Eliminate Backdoors from Response-Computable Authentication.,IEEE Symposium on Security and Privacy,2012,"Shuaifu Dai, Tao Wei, Chao Zhang 0008, Tielei Wang, Yu Ding, Zhenkai Liang, Wei Zou",,https://doi.org/10.1109/SP.2012.10
Detecting Stealthy Backdoors with Association Rule Mining.,Networking,2012,"Stefan Hommes, Radu State, Thomas Engel 0001",,https://doi.org/10.1007/978-3-642-30054-7_13
Strong Backdoors to Nested Satisfiability.,SAT,2012,"Serge Gaspers, Stefan Szeider",,https://doi.org/10.1007/978-3-642-31612-8_7
Backdoors to Satisfaction.,The Multivariate Algorithmic Revolution and Beyond,2012,"Serge Gaspers, Stefan Szeider",,https://doi.org/10.1007/978-3-642-30891-8_15
TorusDesktop: pointing via the backdoor is sometimes shorter.,CHI,2011,"Stéphane Huot, Olivier Chapuis, Pierre Dragicevic",,https://doi.org/10.1145/1978942.1979064
Finding Small Backdoors in SAT Instances.,Canadian AI,2011,"Zijie Li, Peter van Beek",,https://doi.org/10.1007/978-3-642-21043-3_33
Backdoors to Acyclic SAT,CoRR,2011,"Serge Gaspers, Stefan Szeider",abs/1110.6384,http://arxiv.org/abs/1110.6384
Backdoors to Satisfaction,CoRR,2011,"Serge Gaspers, Stefan Szeider",abs/1110.6387,http://arxiv.org/abs/1110.6387
Backdoors to Tractable Answer-Set Programming,CoRR,2011,"Johannes Klaus Fichte, Stefan Szeider",abs/1104.2788,http://arxiv.org/abs/1104.2788
Silencing Hardware Backdoors.,IEEE Symposium on Security and Privacy,2011,"Adam Waksman, Simha Sethumadhavan",,https://doi.org/10.1109/SP.2011.27
Backdoors to Tractable Answer-Set Programming.,IJCAI,2011,"Johannes Klaus Fichte, Stefan Szeider",,https://doi.org/10.5591/978-1-57735-516-8/IJCAI11-150
Trusting the open latent IC backdoors.,STC@CCS,2011,,,https://doi.org/10.1145/2046582.2046584
Static detection of application backdoors - Detecting both malicious software behavior and malicious indicators from the static analysis of executable code.,Datenschutz und Datensicherheit,2010,"Chris Wysopal, Chris Eng, Tyler Shields",34,https://doi.org/10.1007/s11623-010-0024-4
A chipset level network backdoor: bypassing host-based firewall &amp; IDS.,AsiaCCS,2009,"Sherri Sparks, Shawn Embleton, Cliff Changchun Zou",,https://doi.org/10.1145/1533057.1533076
Backdoors to Combinatorial Optimization: Feasibility and Optimality.,CPAIOR,2009,"Bistra Dilkina, Carla P. Gomes, Yuri Malitsky, Ashish Sabharwal, Meinolf Sellmann",,https://doi.org/10.1007/978-3-642-01929-6_6
A study on intrusion protection techniques against Linux kernel backdoor.,ICHIT,2009,"Jin Taek Kim, Jeong-Ho Kho, Min-Seok Hong, Choul Woong Son, Do-Won Lee, Sang-Jo Youk, Geuk Lee",,https://doi.org/10.1145/1644993.1645009
Simple Backdoors on RSA Modulus by Using RSA Vulnerability.,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2009,"Hung-Min Sun, Mu-En Wu, Cheng-Ta Yang",92-A,https://doi.org/10.1587/transfun.E92.A.2326
Backdoor Sets of Quantified Boolean Formulas.,J. Autom. Reason.,2009,"Marko Samer, Stefan Szeider",42,https://doi.org/10.1007/s10817-008-9114-5
"CPU bugs, CPU backdoors and consequences on security.",J. Comput. Virol.,2009,,5,https://doi.org/10.1007/s11416-008-0109-x
Matched Formulas and Backdoor Sets.,J. Satisf. Boolean Model. Comput.,2009,,6,https://doi.org/10.3233/sat190059
Backdoors in the Context of Learning.,SAT,2009,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",,https://doi.org/10.1007/978-3-642-02777-2_9
Backdoor Trees.,AAAI,2008,"Marko Samer, Stefan Szeider",,http://www.aaai.org/Library/AAAI/2008/aaai08-057.php
A New Empirical Study of Weak Backdoors.,CP,2008,"Peter Gregory, Maria Fox 0001, Derek Long",,https://doi.org/10.1007/978-3-540-85958-1_53
"Tradeoffs in Backdoors: Inconsistency Detection, Dynamic Simplification, and Preprocessing.",ISAIM,2008,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",,http://isaim2008.unl.edu/PAPERS/TechnicalProgram/ISAIM2008_0068_52aac45cbd48da479711d1c960b7be35.pdf
A New Bound for an NP-Hard Subclass of 3-SAT Using Backdoors.,SAT,2008,"Stephan Kottler, Michael Kaufmann 0001, Carsten Sinz",,https://doi.org/10.1007/978-3-540-79719-7_16
Computation of Renameable Horn Backdoors.,SAT,2008,"Stephan Kottler, Michael Kaufmann 0001, Carsten Sinz",,https://doi.org/10.1007/978-3-540-79719-7_15
Tradeoffs in the Complexity of Backdoor Detection.,CP,2007,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",,https://doi.org/10.1007/978-3-540-74970-7_20
Detecting and Guarding against Kernel Backdoors through Packet Flow Differentials.,IEICE Trans. Commun.,2007,"Cheolho Lee, Kiwook Sohn",90-B,https://doi.org/10.1093/ietcom/e90-b.10.2638
A Timing-Resistant Elliptic Curve Backdoor in RSA.,Inscrypt,2007,"Adam L. Young, Moti Yung",,https://doi.org/10.1007/978-3-540-79499-8_33
From Horn Strong Backdoor Sets to Ordered Strong Backdoor Sets.,MICAI,2007,"Lionel Paris, Richard Ostrowski, Pierre Siegel, Lakhdar Sais",,https://doi.org/10.1007/978-3-540-76631-5_11
COTS and other electronic voting backdoors.,Commun. ACM,2006,"Rebecca T. Mercuri, Vincent J. Lipsio, Beth Feehan",49,https://doi.org/10.1145/1167838.1167866
Computing Horn Strong Backdoor Sets Thanks to Local Search.,ICTAI,2006,"Lionel Paris, Richard Ostrowski, Pierre Siegel, Lakhdar Sais",,https://doi.org/10.1109/ICTAI.2006.43
An Elliptic Curve Backdoor Algorithm for RSASSA.,Information Hiding,2006,"Adam L. Young, Moti Yung",,https://doi.org/10.1007/978-3-540-74124-4_24
Backbones and Backdoors in Satisfiability.,AAAI,2005,"Philip Kilby, John K. Slaney, Sylvie Thiébaux, Toby Walsh",,http://www.aaai.org/Library/AAAI/2005/aaai05-217.php
Backdoor Sets for DLL Subsolvers.,J. Autom. Reason.,2005,,35,https://doi.org/10.1007/s10817-005-9007-9
A Space Efficient Backdoor in RSA and Its Applications.,Selected Areas in Cryptography,2005,"Adam L. Young, Moti Yung",,https://doi.org/10.1007/11693383_9
The Backdoor Key: A Path to Understanding Problem Hardness.,AAAI,2004,"Yongshao Ruan, Henry A. Kautz, Eric Horvitz",,http://www.aaai.org/Library/AAAI/2004/aaai04-020.php
Backdoor Creativity: Collaborative Creativity in Technology Supported Teams.,COOP,2004,"Hillevi Sundholm, Henrik Artman, Robert Ramberg",,https://hdl.handle.net/20.500.12015/3039
Remote Repair of Operating System State Using Backdoors.,ICAC,2004,"Aniruddha Bohra, Iulian Neamtiu, Pascal Gallard, Florin Sultan, Liviu Iftode",,https://doi.ieeecomputersociety.org/10.1109/ICAC.2004.49
A self-checking signature scheme for checking backdoor security attacks in Internet.,J. High Speed Networks,2004,"Mohammed Fadle Abdulla, C. P. Ravikumar",13,http://content.iospress.com/articles/journal-of-high-speed-networks/jhs251
Detecting Backdoor Sets with Respect to Horn and Binary Clauses.,SAT,2004,"Naomi Nishimura, Prabhakar Ragde, Stefan Szeider",,http://www.satisfiability.org/SAT04/programme/51.pdf
Backdoor Attacks on Black-Box Ciphers Exploiting Low-Entropy Plaintexts.,ACISP,2003,"Adam L. Young, Moti Yung",,https://doi.org/10.1007/3-540-45067-X_26
Simple Backdoors for RSA Key Generation.,CT-RSA,2003,"Claude Crépeau, Alain Slakmon",,https://doi.org/10.1007/3-540-36563-X_28
Automatic Backdoor Analysis with Network Intrusion Detection System and Integrated Service Checker.,IAW,2003,"Jukka Juslin, Teemupekka Virtanen",,
Backdoors To Typical Case Complexity.,IJCAI,2003,"Ryan Williams 0001, Carla P. Gomes, Bart Selman",,http://ijcai.org/Proceedings/03/Papers/168.pdf
Simple backdoors to RSA key generation.,IACR Cryptol. ePrint Arch.,2002,"Claude Crépeau, Alain Slakmon",2002,http://eprint.iacr.org/2002/183
Detecting Backdoors.,USENIX Security Symposium,2000,"Yin Zhang 0001, Vern Paxson",,https://www.usenix.org/conference/9th-usenix-security-symposium/detecting-backdoors
