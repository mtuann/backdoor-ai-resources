# Table of Contents
1. [Backdoor Learning Papers](#backdoor-learning-papers)
2. [Other Research Topics](#other-research-topics)
3. [Backdoor Learning Papers with Code](#backdoor-learning-papers-with-code)
4. [Data Sources](#data-sources)
5. [Contributing](#contributing)
6. [Support](#support)

## Backdoor Learning Papers
This GitHub repository contains an updated list of Backdoor Learning papers as of **January 08, 2026**. 

### Overview
- **Total Papers**: Updated regularly with latest publications
- **Coverage**: Papers from 2016 to present
- **Sources**: Collected from arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML conferences and journals
- **Interactive Search**: For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/)

### Key Features
- üìä **Comprehensive Coverage**: Papers from major AI/ML venues
- üîç **Advanced Search**: Filter by title, author, venue, year
- üìÖ **Regular Updates**: Automated collection of new papers
- üíª **Code Availability**: Identifies papers with available code
- üìà **Trending Research**: Focus on cutting-edge developments

---

## Other Research Topics
Explore additional research papers on the following topics:

### Machine Learning & AI
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** - LLM research and applications
- **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** - Distributed machine learning
- **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** - Adversarial machine learning
- **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)** - Data removal and privacy

### Computing & Systems
- **[Serverless Computing](https://mtuann.shinyapps.io/research-papers/)** - Cloud computing architectures
- **[Multi-Modal Learning](https://mtuann.shinyapps.io/research-papers/)** - Multi-modal AI systems

### Interactive Platforms
- **[Research Papers App](https://mtuann.shinyapps.io/research-papers/)** - Search and explore all papers
- **[Paper Collections](https://github.com/mtuann/research-papers)** - Main repository with all datasets

---

## Data Sources
The papers are collected from the following sources:

### Academic Databases
- **arXiv** (1991-present) - Preprints and published papers
- **OpenReview** - Conference submissions and peer reviews
- **ACM Digital Library** - Computer science publications
- **Springer** - Academic journals and conferences
- **ScienceDirect** - Elsevier publications
- **Nature** - High-impact research papers
- **DBLP** - Computer science bibliography
- **Google Scholar** - Academic search engine
- **CrossRef** - DOI registration agency
- **OpenAlex** - Open scholarly data

### Major Conferences & Journals
- **Machine Learning**: NeurIPS, ICML, ICLR, JMLR, TMLR
- **Natural Language Processing**: ACL, EMNLP, NAACL, COLING
- **Computer Vision**: CVPR, ICCV, ECCV, PAMI, IJCV
- **Artificial Intelligence**: AAAI, IJCAI, AAMAS
- **Data Mining**: KDD, ICDM, SDM, TKDD
- **Security & Privacy**: CCS, USENIX Security, NDSS
- **And many more...**

---

## Backdoor Learning Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publication date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

<!-- 
### Summary Statistics
- **Total Papers in Dataset**: 3,221
- **Papers with Available Code**: 304
- **Code Availability Rate**: 9.4%
- **Last Updated**: January 08, 2026

### Paper Statistics
- **Total Papers**: 3221
- **Papers with Code**: 3221
- **Latest Update**: 3221
- **Coverage Period**: 2016 - Present -->

---

## Contributing
We welcome contributions to improve this paper collection:

### How to Contribute
1. **Add Missing Papers**: Submit papers that should be included
2. **Improve Metadata**: Help enhance paper information
3. **Report Issues**: Identify bugs or missing features
4. **Suggest Improvements**: Propose new features or enhancements

### Contact Information
- **Email**: [tuannm0312@gmail.com](mailto:tuannm0312@gmail.com)
- **GitHub Issues**: [Create an issue](https://github.com/mtuann/research-papers/issues)
- **Discussions**: [Join the discussion](https://github.com/mtuann/research-papers/discussions)

---

## Support
If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:

### Payment Methods
- **Techcombank (Vietnam)**: 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card**: [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

### Why Support?
Your support helps maintain and improve:
- ü§ñ Automated paper collection pipeline
- üåê Interactive web application
- üìä Regular data updates
- üîß System maintenance and improvements
- üìö New research area coverage

---

**Note**: This repository is regularly updated with new papers. For the most current data, check the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/) or the individual topic repositories linked above.


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures|Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li|2025-12-17|in IEEE Transactions on Information Forensics and Security, vol. 20, pp. 10082-10097, 2025|https://github.com/SeRAlab/ArcGen.|https://doi.org/10.48550/arxiv.2512.19730|
|2|Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs|Han Yang, Shaofeng Li, Tian Dong, Xiangyu Xu, Guangchi Liu, Zhen Ling|2025-12-11|arXiv (Cornell University)|https://github.com/PlayerYangh/Authority-Trigger|http://arxiv.org/abs/2512.10600v1|
|3|Patronus: Identifying and Mitigating Transferable Backdoors in Pre-trained Language Models|Zhao, Tianhang, Du, Wei, Zhao, Haodong, Duan, Sufeng, Liu, Gongshen|2025-12-01|arXiv (Cornell University)|https://github.com/zth855/Patronus.|https://doi.org/10.48550/arxiv.2512.06899|
|4|Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-11-29|arXiv (Cornell University)|https://github.com/Robin-WZQ/AMDET|http://arxiv.org/abs/2512.00343v1|
|5|Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck|Liu Xin-yu, Zhang Xu, Chen Can, Wang Ren|2025-11-26|arXiv (Cornell University)|https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git.|https://doi.org/10.48550/arxiv.2511.21923|
|6|AutoBackdoor: Automating Backdoor Attacks via LLM Agents|Li, Yige, Li Zhe, Zhao Wei, Min, Nay Myat, Huang, Hanxun, Ma, Xingjun, Sun Jun|2025-11-20|arXiv (Cornell University)|https://github.com/bboylyg/BackdoorLLM.|https://doi.org/10.48550/arxiv.2511.16709|
|7|Enhancing All-to-X Backdoor Attacks with Optimized Target Class Mapping|Wang Lei, Tian Yu-long, Han Hao, Xu Fengyuan|2025-11-17|arXiv (Cornell University)|https://github.com/kazefjj/A2X-backdoor|https://doi.org/10.48550/arxiv.2511.13356|
|8|MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models|Wang Zihan, Pang, Guansong, Miao Wenjun, Zheng Jin, Bai Xiao|2025-11-13|arXiv (Cornell University)|https://github.com/mala-lab/MTAttack.|https://doi.org/10.48550/arxiv.2511.10098|
|9|Flareon: Stealthy all2all Backdoor Injection via Poisoned Augmentation|Tianrui Qin, Xuan Wang, Xianghuan He, Yiren Zhao, Kejiang Ye, Chengzhong Xu, Xitong Gao|2025-11-03|ACM Transactions on Knowledge Discovery from Data|https://github.com/lafeat/flareon.|https://openreview.net/pdf/8f5e6d6b8c53b5115dfb5e4950961efed881feaa.pdf|
|10|BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models|Li Juncheng, Li Yige, Huang, Hanxun, Chen Yunhao, Wang Xin, Wang YiXu, Ma, Xingjun, Jiang, Yu-Gang|2025-11-01|arXiv (Cornell University)|https://github.com/bin015/BackdoorVLM|https://doi.org/10.48550/arxiv.2511.18921|
|11|Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning|Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu|2025-10-19|arXiv|https://github.com/OPTML-Group/Unlearn-Backdoor.|https://doi.org/10.48550/arXiv.2510.17021|
|12|CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor|Association for Computational Linguistics 2025, Han Meng, Lin Changting, Tian Shengwei, Xu Zhenhua, Yue Xubin, Zhao Xi-x...|2025-10-10|Underline Science Inc.|https://github.com/Xuzhenhua55/CTCC|https://doi.org/10.48550/arXiv.2509.09703|
|13|On the Out-of-Distribution Backdoor Attack for Federated Learning|Jin-Sen Xu, Zikai Zhang, Rui Hu|2025-09-16|OpenAlex|https://github.com/JiiahaoXU/SoDa-BNGuard.|https://doi.org/10.48550/arXiv.2509.13219|
|14|Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers|Simin Chen, Jinjun Peng, Yixin He, Junfeng Yang, Baishakhi Ray|2025-09-14|arXiv|https://github.com/SeekingDream/DLCompilerAttack|https://doi.org/10.48550/arXiv.2509.11173|
|15|CABIN: Debiasing Vision-Language Models Using Backdoor Adjustments|B. Y. Pang, Tingrui Qiao, Caroline Walker, Chris Cunningham, Yun Sing Koh|2025-09-01|OpenAlex|https://github.com/ipangbo/causal-debias|https://doi.org/10.24963/ijcai.2025/55|
|16|FedDLAD: A Federated Learning Dual-Layer Anomaly Detection Framework for Enhancing Resilience Against Backdoor Attacks|Binbin Ding, Penghui Yang, Sheng-Jun Huang|2025-09-01|OpenAlex|https://github.com/dingbinb/FedDLAD.|https://doi.org/10.24963/ijcai.2025/559|
|17|PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning|Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang|2025-09-01|OpenAlex|https://github.com/azure-123/PNAct.|https://doi.org/10.48550/arXiv.2507.00485|
|18|Virus Infection Attack on LLMs: Your Poisoning Can Spread "VIA" Synthetic Data|Zi Liang, Qingqing Ye, Xuan Liu, Yanyun Wang, Jianliang Xu, Haibo Hu|2025-09-01|arXiv|https://github.com/liangzid/VirusInfectionAttack|http://arxiv.org/abs/2509.23041v2|
|19|Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution|Chen Chen, Yuchen Sun, Jiaxin Gao, Xueluan Gong, Qian Wang, Ziyao Wang, Yongsen Zheng, Kwok-Yan Lam|2025-08-28|Zenodo (CERN European Organization for Nuclear Research)|https://github.com/azshue/AutoPoison|https://doi.org/10.48550/arXiv.2508.21004|
|20|Coward: Collision-based Watermark for Proactive Federated Backdoor Detection|Wenjie Li, Siying Gu, Yiming Li, Kangjie Chen, Zhili Chen, Tianwei Zhang, Shu-Tao Xia, Dacheng Tao|2025-08-01|arXiv|https://github.com/still2009/cowardFL.|http://arxiv.org/abs/2508.02115v3|
|21|CLIP-Guided Backdoor Defense through Entropy-Based Poisoned Dataset   Separation|Binyan Xu, Fan Yang, Xilin Dai, Di Tang, Kehuan Zhang|2025-07-01|OpenAlex|https://github.com/binyxu/CGD.|https://doi.org/10.48550/arXiv.2507.05113|
|22|BackFed: An Efficient &amp; Standardized Benchmark Suite for Backdoor Attacks in Federated Learning|Thinh Dao, Dung Thuy Nguyen, Khoa D. Doan, Kok-Seng Wong|2025-07-01|arXiv|https://github.com/thinh-dao/BackFed.|https://doi.org/10.48550/arXiv.2507.04903|
|23|Invisible Backdoor Attack against Self-supervised Learning|Hanrong Zhang, Zhenting Wang, Boheng Li, Fulin Lin, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqi...|2025-06-10|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/Zhang-Henry/INACTIVE.|https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.html|
|24|SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in   VLMs|Shuhan Xu, Siyuan Liang, Hongling Zheng, Aishan Liu, Xinbiao Wang, Yong Luo, Fu Lin, Leszek Rutkowski, Dacheng Tao|2025-06-01|arXiv|https://github.com/Ciconey/SRD.git.|https://doi.org/10.48550/arXiv.2506.04743|
|25|TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor   Attacks on Deep Reinforcement Learning|Mingxuan Zhang, Oubo Ma, Kang Wei, Songze Li, Shouling Ji|2025-06-01|arXiv|https://github.com/S3IC-Lab/TooBadRL.|https://doi.org/10.48550/arXiv.2506.09562|
|26|Defending the Edge: Representative-Attention for Mitigating Backdoor   Attacks in Federated Learning|Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa|2025-05-01|arXiv|https://github.com/Peatech/FeRA_defense.git.|https://doi.org/10.48550/arXiv.2505.10297|
|27|Towards Dataset Copyright Evasion Attack against Personalized   Text-to-Image Diffusion Models|Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia|2025-05-01|arXiv|https://github.com/csyufei/CEAT2I.|http://arxiv.org/abs/2505.02824v1|
|28|Dynamic Attention Analysis for Backdoor Detection in Text-to-Image   Diffusion Models|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-04-01|arXiv|https://github.com/Robin-WZQ/DAA.|https://doi.org/10.48550/arXiv.2504.20518|
|29|Propaganda via AI? A Study on Semantic Backdoors in Large Language   Models|Nay Myat Min, Long H. Pham, Yige Li, Jun Sun|2025-04-01|arXiv|https://github.com/NayMyatMin/RAVEN.|https://doi.org/10.48550/arXiv.2504.12344|
|30|Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature   Awareness|Yu Feng, Dingxin Zhang, Runkai Zhao, Yong Xia, Heng Huang, Tom Weidong Cai|2025-03-01|arXiv|https://github.com/HazardFY/SPBA.|https://doi.org/10.48550/arXiv.2503.09336|
|31|Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-03-01|arXiv|https://github.com/Robin-WZQ/TwT.|http://arxiv.org/abs/2503.17724v2|
|32|CBW: Towards Dataset Ownership Verification for Speaker Verification via   Clustering-based Backdoor Watermarking|Yiming Li, Kaiying Yan, Shuo Shao, Tongqing Zhai, Shu-Tao Xia, Zhan Qin, Dacheng Tao|2025-03-01|arXiv|https://github.com/Radiant0726/CBW|https://doi.org/10.48550/arXiv.2503.05794|
|33|Detecting Backdoor Attacks in Federated Learning via Direction Alignment   Inspection|Jiahao Xu, Zikai Zhang, Rui Hu|2025-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/JiiahaoXU/AlignIns.|https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.html|
|34|DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on   LLM-based Agent|Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su|2025-02-18|arXiv|https://github.com/whfeLingYu/DemonAgent.|https://doi.org/10.48550/arXiv.2502.12575|
|35|BackdoorDM: A Comprehensive Benchmark for Backdoor Learning in Diffusion   Model|Weilin Lin, Nanjun Zhou, Yanyun Wang, Jianze Li, Hui Xiong, Li Liu|2025-02-17|arXiv|https://github.com/linweiii/BackdoorDM.|https://doi.org/10.48550/arXiv.2502.11798|
|36|BoT: Breaking Long Thought Processes of o1-like Large Language Models   through Backdoor Attack|Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu|2025-02-16|arXiv|https://github.com/zihao-ai/BoT|https://doi.org/10.48550/arXiv.2502.12202|
|37|Revisiting the Auxiliary Data in Backdoor Purification|Shaokui Wei, Shanchao Yang, Jiayin Liu, Hongyuan Zha|2025-02-10|arXiv|https://github.com/shawkui/BackdoorBenchER.|https://doi.org/10.48550/arXiv.2502.07231|
|38|Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in   Multilingual LLMs|Himanshu Beniwal, Sailesh Panda, Birudugadda Srivibhav, Mayank Singh|2025-02-01|arXiv|https://github.com/himanshubeniwal/X-BAT.|https://doi.org/10.48550/arXiv.2502.16901|
|39|Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on   Diffusion Models|Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu|2025-02-01|arXiv|https://github.com/paoche11/Gungnir.|https://doi.org/10.48550/arXiv.2502.20650|
|40|Detecting Backdoor Samples in Contrastive Language Image Pretraining|Hanxun Huang, Sarah Monazam Erfani, Yige Li, Xingjun Ma, James Bailey|2025-02-01|arXiv|https://github.com/HanxunH/Detect-CLIP-Backdoor-Samples|https://openreview.net/forum?id=KmQEsIfhr9|
|41|BadRefSR: Backdoor Attacks Against Reference-based Image Super   Resolution|Xue Yang, Tao Chen, Lei Guo, Wenbo Jiang, Ji Guo, Yongming Li, Jiaming He|2025-02-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/xuefusiji/BadRefSR.|https://doi.org/10.1109/icassp49660.2025.10889523|
|42|UNIDOOR: A Universal Framework for Action-Level Backdoor Attacks in Deep   Reinforcement Learning|Oubo Ma, Linkang Du, Yang Dai, Chunyi Zhou, Qingming Li, Yuwen Pu, Shouling Ji|2025-01-26|arXiv|https://github.com/maoubo/UNIDOOR.|https://doi.org/10.48550/arXiv.2501.15529|
|43|Mechanistic Exploration of Backdoored Large Language Model Attention Patterns|Mohammed Abu Baker, Lakshmi Babu Saheer|2025-01-01|arXiv|https://github.com/mshahoyi/sa_attn_analysis.|https://doi.org/10.48550/arXiv.2508.15847|
|44|Vertical Federated Unlearning via Backdoor Certification|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025-01-01|IEEE Transactions on Services Computing|https://github.com/mengde-han/VFL-unlearn.|https://doi.org/10.48550/arXiv.2412.11476|
|45|UFID: A Unified Framework for Black-box Input-level Backdoor Detection on Diffusion Models|Zihan Guan, Mengxuan Hu, Sheng Li, Anil Kumar S. Vullikanti|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/GuanZihan/official_UFID.|https://doi.org/10.1609/aaai.v39i26.34941|
|46|ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training|Xin Yao, Haiyang Zhao, Yimin Chen, Jiawei Guo, Kecheng Huang, Ming Zhao|2025-01-01|arXiv|https://github.com/xinyaocse/ToxicTextCLIP|https://doi.org/10.48550/arXiv.2511.00446|
|47|Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-01-01|arXiv|https://github.com/Robin-WZQ/IBA.|https://doi.org/10.48550/arXiv.2503.17724|
|48|The Ripple Effect: On Unforeseen Complications of Backdoor Attacks|Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang|2025-01-01|arXiv|https://github.com/zhangrui4041/Backdoor_Complications.|https://openreview.net/forum?id=sw1Sm72dmV|
|49|Test-Time Multimodal Backdoor Detection by Contrastive Prompting|Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng|2025-01-01|ICML|https://github.com/Purshow/BDetCLIP.|https://openreview.net/forum?id=1jd25AlvHS|
|50|Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack|Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren|2025-01-01|arXiv|https://github.com/WhitolfChen/SCAR.|https://doi.org/10.48550/arXiv.2509.23871|
|51|TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood Screening|Nam Le, Leo Yu Zhang, Kewen Liao, Shirui Pan, Wei Luo|2025-01-01|arXiv|https://github.com/namle-w/TEDpp.|https://doi.org/10.48550/arXiv.2510.14299|
|52|Sealing The Backdoor: Unlearning Adversarial Text Triggers In Diffusion Models Using Knowledge Distillation|Ashwath Vaithinathan Aravindan, Abha Jha, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz|2025-01-01|arXiv|https://github.com/Mystic-Slice/Sealing-The-Backdoor|https://doi.org/10.48550/arXiv.2508.18235|
|53|Rounding-Guided Backdoor Injection in Deep Learning Model Quantization|Xiangxiang Chen, Peixin Zhang, Jun Sun, Wenhai Wang, Jingyi Wang|2025-01-01|arXiv|https://github.com/cxx122/QuRA.|https://doi.org/10.48550/arXiv.2510.09647|
|54|REFINE: Inversion-Free Backdoor Defense via Model Reprogramming|Yukun Chen, Shuo Shao, Enhao Huang, Yiming Li, Pin-Yu Chen, Zhan Qin, Kui Ren|2025-01-01|ICLR|https://github.com/THUYimingLi/BackdoorBox|https://openreview.net/forum?id=4IYdCws9fc|
|55|SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs|Zhengxian Wu, Juan Wen, Wanli Peng, Haowei Chang, Yinghan Zhou, Yiming Xue|2025-01-01|arXiv|https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs|https://doi.org/10.48550/arXiv.2508.06153|
|56|Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking|Yu-Feng Chen, Tzuhsuan Huang, Pin-Yen Chiu, Jun-Cheng Chen|2025-01-01|arXiv|https://github.com/aiiu-lab/BackdoorImageEditing|https://doi.org/10.1109/AVSS65446.2025.11149824|
|57|Circumventing Backdoor Space via Weight Symmetry|Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He|2025-01-01|arXiv|https://github.com/JiePeng104/TSC.|https://openreview.net/forum?id=dqYO5LVyYh|
|58|Backdoor Token Unlearning: Exposing and Defending Backdoors in   Pretrained Language Models|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/XDJPH/BTU.|https://doi.org/10.1609/aaai.v39i23.34605|
|59|FLARE: Towards Universal Dataset Purification against Backdoor Attacks|Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li|2025-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/THUYimingLi/BackdoorBox|https://doi.org/10.1109/TIFS.2025.3581719|
|60|BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit|Biao Yi, Zekun Fei, Jianing Geng, Tong Li, Lihai Nie, Zheli Liu, Yiming Li|2025-01-01|arXiv|https://github.com/FZaKK/BadReasoner.|https://doi.org/10.48550/arXiv.2507.18305|
|61|BeDKD: Backdoor Defense based on Dynamic Knowledge Distillation and Directional Mapping Modulator|Zhengxian Wu, Juan Wen, Wanli Peng, Yinghan Zhou, Changtong dou, Yiming Xue|2025-01-01|AAAI 2026|https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs|https://doi.org/10.48550/arXiv.2508.01595|
|62|Cert-SSB: Toward Certified Sample-Specific Backdoor Defense|Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li|2025-01-01|arXiv|https://github.com/NcepuQiaoTing/Cert-SSB.|https://doi.org/10.48550/arXiv.2504.21730|
|63|Backdooring Self-Supervised Contrastive Learning by Noisy Alignment|Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu|2025-01-01|arXiv|https://github.com/jsrdcht/Noisy-Alignment.|https://doi.org/10.48550/arXiv.2508.14015|
|64|Claim-Guided Textual Backdoor Attack for Practical Applications|Minkyoo Song, Hanna Kim, Jaehan Kim, Youngjin Jin, Seungwon Shin|2025-01-01|Findings of the Association for Computational Linguistics: NAACL 2022|https://github.com/PaperCGBA/CGBA.|https://doi.org/10.18653/v1/2025.findings-naacl.64|
|65|Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems|Pengyu Zhu, Lijun Li, Yaxing Lyu, Li Sun, Sen Su, Jing Shao|2025-01-01|arXiv|https://github.com/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS.|https://doi.org/10.48550/arXiv.2510.11246|
|66|DUP: Detection-guided Unlearning for Backdoor Purification in Language Models|Man Hu, Yahui Ding, Yatao Yang, Liangyu Chen, Yanhao Jia, Shuai Zhao|2025-01-01|arXiv|https://github.com/ManHu2025/DUP.|https://doi.org/10.48550/arXiv.2508.01647|
|67|Energy Backdoor Attack to Deep Neural Networks|Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier D√©forges, Kassem Kallas|2025-01-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/hbrachemi/energy_backdoor.|https://doi.org/10.1109/icassp49660.2025.10888330|
|68|Exploring Backdoor Vulnerabilities of Chat Models|Wenkai Yang, Yunzhuo Hao, Yankai Lin|2025-01-01|COLING|https://github.com/hychaochao/Chat-Models-Backdoor-Attacking|https://aclanthology.org/2025.coling-main.62/|
|69|Double Landmines: Invisible Textual Backdoor Attacks based on   Dual-Trigger|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-23|Cybersecurity|https://github.com/HoyaAm/Double-Landmines.|https://doi.org/10.1186/s42400-025-00512-z|
|70|Gracefully Filtering Backdoor Samples for Generative Large Language   Models without Retraining|Zongru Wu, Pengzhou Cheng, Lingyong Fang, Zhuosheng Zhang, Gongshen Liu|2024-12-03|COLING|https://github.com/ZrW00/GraceFul.|https://aclanthology.org/2025.coling-main.220/|
|71|BadMerging: Backdoor Attacks Against Model Merging|Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian|2024-12-02|OpenAlex|https://github.com/jzhang538/BadMerging.|https://doi.org/10.48550/arXiv.2408.07362|
|72|Fisher Information guided Purification against Backdoor Attacks|Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard|2024-12-02|OpenAlex|https://github.com/nazmul-karim170/FIP-Fisher-Backdoor-Removal|https://doi.org/10.48550/arXiv.2409.00863|
|73|Backdoor Attacks against No-Reference Image Quality Assessment Models   via a Scalable Trigger|Yi Yu, Song Xia, Xun Lin, Wenhan Yang, Shijian Lu, Yap‚ÄêPeng Tan, Alex C. Kot|2024-12-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/yuyi-sd/BAIQA.|https://doi.org/10.48550/arXiv.2412.07277|
|74|Invisible Textual Backdoor Attacks based on Dual-Trigger|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-01|arXiv|https://github.com/HoyaAm/Double-Landmines.|http://arxiv.org/abs/2412.17531v3|
|75|Perturb and Recover: Fine-tuning for Effective Backdoor Removal from   CLIP|Naman Deep Singh, Francesco Croce, Matthias Hein|2024-12-01|arXiv|https://github.com/nmndeep/PerturbAndRecover.|https://doi.org/10.48550/arXiv.2412.00727|
|76|T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2024-11-26|Lecture notes in computer science|https://github.com/Robin-WZQ/T2IShield.|https://doi.org/10.1007/978-3-031-73013-9_7|
|77|BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for   Backdoor Defense Evaluation|Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Pengzhou Cheng, Ping Yi, Yue Wu|2024-11-17|OpenAlex|https://github.com/SJTUHaiyangYu/BackdoorMBTI.|https://doi.org/10.48550/arXiv.2411.11006|
|78|Your Semantic-Independent Watermark is Fragile: A Semantic Perturbation   Attack against EaaS Watermark|Zekun Fei, Biao Yi, Jianing Geng, Ruiqi He, Lihai Nie, Zheli Liu|2024-11-01|arXiv|https://github.com/Zk4-ps/EaaS-Embedding-Watermark.|http://arxiv.org/abs/2411.09359v2|
|79|Identify Backdoored Model in Federated Learning via Individual   Unlearning|Jiahao Xu, Zikai Zhang, Rui Hu|2024-11-01|arXiv|https://github.com/JiiahaoXU/MASA|https://doi.org/10.1109/WACV61041.2025.00773|
|80|UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening|Siyuan Cheng, Guangyu Shen, Kaiyuan Zhang, Guanhong Tao, Shengwei An, Hanxi Guo, Shiqing Ma, Xiangyu Zhang|2024-10-31|Lecture notes in computer science|https://github.com/Megum1/UNIT.|https://doi.org/10.1007/978-3-031-73033-7_15|
|81|Mitigating the Backdoor Effect for Multi-Task Model Merging via   Safety-Aware Subspace|Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu|2024-10-16|arXiv|https://github.com/Yangjinluan/DAM.|https://openreview.net/forum?id=dqMqAaw7Sq|
|82|Adversarially Guided Stateful Defense Against Backdoor Attacks in   Federated Deep Learning|Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay K. Jha|2024-10-01|OpenAlex|https://github.com/hassanalikhatim/AGSD.|https://doi.org/10.1109/ACSAC63791.2024.00070|
|83|Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and   Defenses in LLM-based Agents|Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang|2024-10-01|arXiv|https://github.com/agiresearch/ASB.|http://arxiv.org/abs/2410.02644v4|
|84|Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via   Exposed Models|Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang|2024-10-01|arXiv|https://github.com/bboylyg/Expose-Before-You-Defend.|https://doi.org/10.48550/arXiv.2410.19427|
|85|Event Trojan: Asynchronous Event-Based Backdoor Attacks|Ruofei Wang, Qing Guo, Haoliang Li, Renjie Wan|2024-09-28|Lecture notes in computer science|https://github.com/rfww/EventTrojan.|https://doi.org/10.1007/978-3-031-72667-5_18|
|86|Mask-Based Invisible Backdoor Attacks on Object Detection|Shin Jeong Jin|2024-09-27|2022 IEEE International Conference on Image Processing (ICIP)|https://github.com/jeongjin0/invisible-backdoor-object-detection|https://doi.org/10.36227/techrxiv.171440796.64142276/v1|
|87|Obliviate: Neutralizing Task-agnostic Backdoors within the   Parameter-efficient Fine-tuning Paradigm|Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin|2024-09-21|Findings of the Association for Computational Linguistics: NAACL 2022|https://github.com/obliviateARR/Obliviate.|https://doi.org/10.18653/v1/2025.findings-naacl.71|
|88|TERD: A Unified Framework for Safeguarding Diffusion Models Against   Backdoors|Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, Yisen Wang|2024-09-08|International Conference on Machine Learning 2024|https://github.com/PKU-ML/TERD.|https://openreview.net/forum?id=lpHjmPvxW1|
|89|NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack   Through White Gaussian Noise|Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi|2024-09-03|arXiv|https://github.com/SiSL-URI/NoiseAttack|https://doi.org/10.48550/arXiv.2409.02251|
|90|Exploiting the Vulnerability of Large Language Models via Defense-Aware   Architectural Backdoor|Abdullah Arafat Miah, Yu Bi|2024-09-03|arXiv|https://github.com/SiSL-URI/Arch_Backdoor_LLM.|https://doi.org/10.48550/arXiv.2409.01952|
|91|Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual   Perturbations Against Backdoor Attacks|Oscar Chew, Po-Yi Lu, Jayden Lin, Hsuan-Tien Lin|2024-08-28|arXiv|https://github.com/oscarchew/t2i-backdoor-defense.|https://doi.org/10.48550/arXiv.2408.15721|
|92|VFLIP: A Backdoor Defense for Vertical Federated Learning via   Identification and Purification|Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek|2024-08-28|Lecture notes in computer science|https://github.com/blingcho/VFLIP-esorics24|https://doi.org/10.1007/978-3-031-70903-6_15|
|93|MakeupAttack: Feature Space Black-box Backdoor Attack on Face   Recognition via Makeup Transfer|Ming Sun, Lihua Jing, Zixuan Zhu, Rui Wang|2024-08-22|Frontiers in artificial intelligence and applications|https://github.com/AaronSun2000/MakeupAttack.|https://doi.org/10.48550/arXiv.2408.12312|
|94|MEGen: Generative Backdoor into Large Language Models via Model Editing|Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao, Yun Li, Qianren Wang|2024-08-20|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/MonoQ-hub/MEGen.|https://doi.org/10.18653/v1/2025.findings-acl.584|
|95|BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses   on Large Language Models|Li Yige, Huang, Hanxun, Zhao Yunhan, Ma, Xingjun, Sun Jun|2024-08-01|Singapore Management University Institutional Knowledge (InK) (Singapore Management University)|https://github.com/bboylyg/BackdoorLLM.|https://ink.library.smu.edu.sg/sis_research/10422|
|96|Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion   Models|Hao Jiang, Jin Xiao, Xiaoguang Hu, Chen Tianyou, Zhao Jiajia|2024-07-30|ICME|https://github.com/shymuel/diff-cleanse.|https://doi.org/10.1109/ICME59968.2025.11210014|
|97|BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor   Learning|Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen|2024-07-29|International Journal of Computer Vision|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/backdoorbench-a-comprehensive-benchmark-of/code)|http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html|
|98|Flatness-aware Sequential Learning Generates Resilient Backdoors|Hoang N. Pham, The-Anh Ta, Anh Tran, Khoa D. Doan|2024-07-19|Lecture notes in computer science|https://github.com/mail-research/SBL-resilient-backdoors|https://doi.org/10.1007/978-3-031-73021-4_6|
|99|Provable Robustness of (Graph) Neural Networks Against Data Poisoning   and Backdoor Attacks|Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan G√ºnnemann|2024-07-15|Trans. Mach. Learn. Res.|https://github.com/saper0/qpcert|https://openreview.net/forum?id=jIAPLDdGVx|
|100|Distributed Backdoor Attacks on Federated Graph Learning and Certified   Defenses|Yuxin Yang, Qiang Li, Jinyuan Jia, Yuan Hong, Binghui Wang|2024-07-11|OpenAlex|https://github.com/Yuxin104/Opt-GDBA.|https://doi.org/10.48550/arXiv.2407.08935|
|101|Future Events as Backdoor Triggers: Investigating Temporal   Vulnerabilities in LLMs|Sara Price, Arjun Panickssery, Samuel R. Bowman, Asa Cooper Stickland|2024-07-04|arXiv|https://github.com/sbp354/Future_triggered_backdoors|https://doi.org/10.48550/arXiv.2407.04108|
|102|IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields|Wenxiang Jiang, Hanwei Zhang, Shuo Zhao, Zhongwen Guo, Hao Wang|2024-07-01|arXiv|https://github.com/jiang-wenxiang/IPA-NeRF.|http://arxiv.org/abs/2407.11921v2|
|103|Towards Clean-Label Backdoor Attacks in the Physical World|Thinh Dao, Cuong Phan Minh Le, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|https://github.com/21thinh/Clean-Label-Physical-Backdoor-Attacks.|https://doi.org/10.48550/arXiv.2407.19203|
|104|ShadowCode: Towards (Automatic) External Prompt Injection Attack against   Code LLMs|Yuchen Yang, Yiming Li, Hongwei Yao, Bingrun Yang, Yiling He, Tianwei Zhang, Dacheng Tao, Zhan Qin|2024-07-01|arXiv|https://github.com/LianPing-cyber/ShadowCodeEPI.|http://arxiv.org/abs/2407.09164v6|
|105|Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks   in Federated Learning|Son Nguyen, Thinh Viet Nguyen, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|https://github.com/nguyenhongson1902/Venomancer.|https://doi.org/10.48550/arXiv.2407.03144|
|106|Defending Against Repetitive-based Backdoor Attacks on Semi-supervised   Learning through Lens of Rate-Distortion-Perception Trade-off|Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu, Chu-Song Chen|2024-07-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/chengyi-chris/UPure|https://doi.org/10.1109/WACV61041.2025.00630|
|107|Clean-Label Physical Backdoor Attacks with Data Distillation|Thinh Dao, Khoa D Doan, Kok-Seng Wong|2024-07-01|arXiv|https://github.com/thinh-dao/Clean-Label-Physical-Backdoor-Attacks.|http://arxiv.org/abs/2407.19203v4|
|108|Backdoor Graph Condensation|Jiahao Wu, Ning Lu, Zeiyu Dai, Kun Wang, Wenqi Fan, Shengcai Liu, Qing Li, Ke Tang|2024-07-01|arXiv|https://github.com/JiahaoWuGit/BGC.|https://doi.org/10.1109/ICDE65448.2025.00172|
|109|A Whole-Process Certifiably Robust Aggregation Method Against Backdoor   Attacks in Federated Learning|Anqi Zhou, Yezheng Liu, Yidong Chai, Hongyi Zhu, Xinyue Ge, Yuanchun Jiang, Meng Wang|2024-06-30|arXiv|https://github.com/brick-brick/WPCRAM.|https://doi.org/10.48550/arXiv.2407.00719|
|110|Lotus: Evasive and Resilient Backdoor Attacks through Sub-Partitioning|Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, ...|2024-06-16|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/Megum1/LOTUS.|https://doi.org/10.1109/cvpr52733.2024.02342|
|111|BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents|Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian|2024-06-05|OpenAlex|https://github.com/DPamK/BadAgent|https://doi.org/10.18653/v1/2024.acl-long.530|
|112|Invisible Backdoor Attacks on Diffusion Models|Sen Li, Junchi Ma, Minhao Cheng|2024-06-02|arXiv|https://github.com/invisibleTriggerDiffusion/invisible_triggers_for_diffusion.|https://doi.org/10.48550/arXiv.2406.00816|
|113|Let the Noise Speak: Harnessing Noise for a Unified Defense Against   Adversarial and Backdoor Attacks|Md Hasan Shahriar, Ning Wang, Naren Ramakrishnan, Y. Thomas Hou, Wenjing Lou|2024-06-01|Lecture notes in computer science|https://github.com/shahriar0651/NoiSec.|https://doi.org/10.1007/978-3-032-07884-1_19|
|114|BAN: Detecting Backdoors Activated by Adversarial Neuron Noise|Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek|2024-05-30|NeurIPS|https://github.com/xiaoyunxxy/ban|http://papers.nips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html|
|115|Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor|Shaokui Wei, Hongyuan Zha, Baoyuan Wu|2024-05-25|NeurIPS|https://github.com/shawkui/Proactive_Defensive_Backdoor.|http://papers.nips.cc/paper_files/paper/2024/hash/9374af323abb65ce551168d44b09ad5f-Abstract-Conference.html|
|116|Towards Imperceptible Backdoor Attack in Self-supervised Learning|Hanrong Zhang, Zhenting Wang, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma|2024-05-23|arXiv|https://github.com/Zhang-Henry/IMPERATIVE.|https://doi.org/10.48550/arXiv.2405.14672|
|117|IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling   Consistency|Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li|2024-05-15|ICML|https://github.com/THUYimingLi/BackdoorBox|https://openreview.net/forum?id=YCzbfs2few|
|118|EmInspector: Combating Backdoor Attacks in Federated Self-Supervised   Learning Through Embedding Inspection|Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo|2024-05-01|arXiv|https://github.com/ShuchiWu/EmInspector.|https://doi.org/10.48550/arXiv.2405.13080|
|119|Not All Prompts Are Secure: A Switchable Backdoor Attack Against   Pre-trained Vision Transformers|Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/20000yshust/SWARM.|https://doi.org/10.1109/CVPR52733.2024.02306|
|120|Nearest is Not Dearest: Towards Practical Defense against   Quantization-conditioned Backdoor Attacks|Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/AntigoneRandy/QuantBackdoor_EFRAP.|https://doi.org/10.1109/CVPR52733.2024.02315|
|121|Beyond Traditional Threats: A Persistent Backdoor Attack on Federated   Learning|Tao Liu, Yuhang Zhang, Feng Zhu, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang|2024-04-26||https://github.com/PhD-TaoLiu/FCBA.|https://doi.org/10.1609/aaai.v38i19.30131|
|122|Privacy Backdoors: Stealing Data with Corrupted Pretrained Models|Shanglun Feng, Florian Tram√®r|2024-03-30|ICML|https://github.com/ShanglunFengatETHZ/PrivacyBackdoor|https://openreview.net/forum?id=7yixJXmzb8|
|123|Generating Potent Poisons and Backdoors from Scratch with Guided   Diffusion|Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellapp...|2024-03-24|arXiv|https://github.com/hsouri/GDP|https://doi.org/10.48550/arXiv.2403.16365|
|124|Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain|Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/f-lk/IBAPC.|https://doi.org/10.1609/aaai.v38i19.30099|
|125|Progressive Poisoned Data Isolation for Training-Time Backdoor Defense|Yiming Chen, Haiwei Wu, Jiantao Zhou|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/RorschachChen/PIPD.git.|https://doi.org/10.1609/aaai.v38i10.29023|
|126|COMBAT: Alternated Training for Near-Perfect Clean-Label Backdoor Attacks|Tran Ngoc Huynh, Dang Minh Nguyen, Tung Pham, Anh Tuan Tran|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/VinAIResearch/COMBAT.|https://openreview.net/pdf/c182fdd518fe8ec0aeafeb8d1b2b55bb8e46a463.pdf|
|127|BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning|Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/7777777cc/code.|https://doi.org/10.1609/aaai.v38i10.29052|
|128|An Embarrassingly Simple Defense Against Backdoor Attacks On SSL|Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade|2024-03-23|arXiv|https://github.com/Aryan-Satpathy/Backdoor.|https://doi.org/10.48550/arXiv.2403.15918|
|129|PoisonPrompt: Backdoor Attack on Prompt-Based Large Language Models|Hongwei Yao, Jian Lou, Zhan Qin|2024-03-18|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/grasses/PoisonPrompt|https://doi.org/10.1109/icassp48485.2024.10446267|
|130|Invisible Black-Box Backdoor Attack against Deep Cross-Modal Hashing Retrieval|Tianshi Wang, Fengling Li, Lei Zhu, Jingjing Li, Zheng Zhang, Heng Tao Shen|2024-03-02|ACM transactions on office information systems|https://github.com/tswang0116/IB3A.|https://doi.org/10.1145/3650205|
|131|Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized   Scaled Prediction Consistency|Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu|2024-03-01|ICLR|https://github.com/OPTML-Group/BackdoorMSPC.|https://openreview.net/forum?id=1OfAO2mes1|
|132|BapFL: You can Backdoor Personalized Federated Learning|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2024-02-23|ACM Transactions on Knowledge Discovery from Data|https://github.com/BapFL/code|https://doi.org/10.1145/3649316|
|133|Acquiring Clean Language Models from Backdoor Poisoned Datasets by   Downscaling Frequency Space|Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu|2024-02-19|OpenReview|https://github.com/ZrW00/MuScleLoRA.|https://openreview.net/pdf/9eb71f0c75e3630c53671cf8b0175e95463726f1.pdf|
|134|Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery   Detection|Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao|2024-02-18|ICLR|https://github.com/JWLiang007/PFF|https://openreview.net/forum?id=8iTpB4RNvP|
|135|Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based   Agents|Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun|2024-02-17|NeurIPS|https://github.com/lancopku/agent-backdoor-attacks|http://papers.nips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html|
|136|OrderBkd: Textual backdoor attack through repositioning|Irina Alekseevskaia, Konstantin Arkhipenko|2024-02-12|OpenAlex|https://github.com/alekseevskaia/OrderBkd.|https://doi.org/10.1109/ispras60948.2023.10508175|
|137|Backdoor Attacks on Dense Retrieval via Public and Unintentional   Triggers|Quanyu Long, Yue Deng, LeiLei Gan, Wenya Wang, Sinno Jialin Pan|2024-02-01|arXiv|https://github.com/ruyue0001/Backdoor_DPR.|http://arxiv.org/abs/2402.13532v3|
|138|SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via   Syntactic Transfer|Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Zhuosheng Zhang, Gongshen Liu|2024-02-01|Findings of the Association for Computational Linguistics: NAACL 2022|https://github.com/Zhou-CyberSecurity-AI/SynGhost.|https://doi.org/10.18653/v1/2025.findings-naacl.196|
|139|TransTroj: Transferable Backdoor Attacks to Pre-trained Models via   Embedding Indistinguishability|Hao Wang, Tao Xiang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang|2024-01-28|arXiv|https://github.com/haowang-cqu/TransTroj|https://doi.org/10.48550/arXiv.2401.15883|
|140|A Closer Look at Robustness of Vision Transformers to Backdoor Attacks|Akshayvarun Subramanya, Soroush Abbasi Koohpayegani, Aniruddha Saha, Ajinkya Tejankar, Hamed Pirsiavash|2024-01-03|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/UCDvision/backdoor_transformer.git|https://doi.org/10.1109/wacv57701.2024.00383|
|141|How to Craft Backdoors with Unlabeled Data Alone?|Yifei Wang, Wenhan Ma, Stefanie Jegelka, Yisen Wang|2024-01-01|arXiv|https://github.com/PKU-ML/nlb.|https://doi.org/10.48550/arXiv.2404.06694|
|142|Toward Stealthy Backdoor Attacks Against Speech Recognition via Elements of Sound|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2024-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/HanboCai/BadSpeech_SoE.|https://doi.org/10.1109/tifs.2024.3404885|
|143|Shortcuts Everywhere and Nowhere: Exploring Multi-Trigger Backdoor   Attacks|Yige Li, Jiabo He, Hanxun Huang, Jun Sun, Xingjun Ma, Yu-Gang Jiang|2024-01-01|arXiv|https://github.com/bboylyg/Multi-Trigger-Backdoor-Attacks.|http://arxiv.org/abs/2401.15295v3|
|144|PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection|Wei Li, Pin-Yu Chen, Sijia Liu, Ren Wang|2024-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/WL-619/PSBD.|https://openaccess.thecvf.com/content/CVPR2025/html/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.html|
|145|PBP: Post-training Backdoor Purification for Malware Classifiers|Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach|2024-01-01|OpenAlex|https://github.com/judydnguyen/pbp-backdoor-purification-official|https://www.ndss-symposium.org/ndss-paper/pbp-post-training-backdoor-purification-for-malware-classifiers/|
|146|Model Supply Chain Poisoning: Backdooring Pre-trained Models via   Embedding Indistinguishability|Hao Wang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang, Tao Xiang|2024-01-01|WWW|https://github.com/haowang-cqu/TransTroj|https://doi.org/10.1145/3696410.3714624|
|147|How to Backdoor Consistency Models?|Chengen Wang, Murat Kantarcioglu|2024-01-01|Lecture notes in computer science|https://github.com/chengenw/backdoorCM|https://doi.org/10.1007/978-981-96-8295-9_23|
|148|Defending Against Backdoor Attacks by Quarantine Training|Chengxu Yu, Yulai Zhang|2024-01-01|IEEE Access|https://github.com/Chengx-Yu/Quarantine-Training.|https://doi.org/10.1109/access.2024.3354385|
|149|BadCM: Invisible Backdoor Attack Against Cross-Modal Learning|Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie|2024-01-01||https://github.com/xandery-geek/BadCM.|https://doi.org/10.48550/arXiv.2410.02182|
|150|Backdoor Contrastive Learning via Bi-level Trigger Optimization|Weiyu Sun, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, Jinghui Chen, Lu Lin|2024-01-01|ICLR|https://github.com/SWY666/SSL-backdoor-BLTO.|https://openreview.net/forum?id=oxjeePpgSP|
|151|BackTime: Backdoor Attacks on Multivariate Time Series Forecasting|Xiaola Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong|2024-01-01|NeurIPS|https://github.com/xiaolin-cs/BackTime|http://papers.nips.cc/paper_files/paper/2024/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html|
|152|Adversarial Feature Map Pruning for Backdoor|Dong Huang, Qingwen Bu|2024-01-01|ICLR|https://github.com/retsuh-bqw/FMP.|https://openreview.net/forum?id=IOEEDkla96|
|153|OCGEC: One-class Graph Embedding Classification for DNN Backdoor   Detection|Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi|2023-12-01|2022 International Joint Conference on Neural Networks (IJCNN)|https://github.com/jhy549/OCGEC.|https://doi.org/10.1109/ijcnn60899.2024.10650468|
|154|UltraClean: A Simple Framework to Train Robust Neural Networks against   Backdoor Attacks|Bingyin Zhao, Yingjie Lao|2023-12-01|arXiv|https://github.com/bxz9200/UltraClean.|https://doi.org/10.48550/arXiv.2312.10657|
|155|A Practical Clean-Label Backdoor Attack with Limited Information in Vertical Federated Learning|Peng Chen, Jirui Yang, Junxiong Lin, Zhihui Lu, Qiang Duan, Hongfeng Chai|2023-12-01|2021 IEEE International Conference on Data Mining (ICDM)|https://github.com/13thDayOLunarMay/TECB-attack|https://doi.org/10.1109/icdm58522.2023.00013|
|156|Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking|Shengsheng Qian, Dizhan Xue, Yifei Wang, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu|2023-12-01|arXiv|https://github.com/LivXue/PoisonCAM.|https://doi.org/10.48550/arXiv.2312.07955|
|157|Activation Gradient based Poisoned Sample Detection Against Backdoor   Attacks|Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu|2023-12-01|ICLR|https://github.com/SCLBD/bdzoo2|https://openreview.net/forum?id=VNMJfBBUd5|
|158|TextGuard: Provable Defense against Backdoor Attacks on Text   Classification|Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song|2023-11-01|OpenAlex|https://github.com/AI-secure/TextGuard.|https://www.ndss-symposium.org/ndss-paper/textguard-provable-defense-against-backdoor-attacks-on-text-classification/|
|159|ACQ: Few-shot Backdoor Defense via Activation Clipping and Quantizing|Yulin Jin, Xiaoyu Zhang, Jian Lou, Xiaofeng Chen|2023-10-26|ACM Multimedia|https://github.com/Backdoor-defense/ACQ|https://doi.org/10.1145/3581783.3612410|
|160|Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks|Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu|2023-10-21|OpenAlex|https://github.com/GuanZihan/Deep-Backdoor-Attack.|https://doi.org/10.1145/3583780.3614784|
|161|An Embarrassingly Simple Backdoor Attack on Self-supervised Learning|Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/meet-cjli/CTRL|https://doi.org/10.1109/iccv51070.2023.00403|
|162|Computation and Data Efficient Backdoor Attacks|Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/WU-YU-TONG/computational_efficient_backdoor|https://doi.org/10.1109/iccv51070.2023.00443|
|163|FLTracer: Accurate Poisoning Attack Provenance in Federated Learning|Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren|2023-10-01|arXiv|https://github.com/Eyr3/FLTracer|http://arxiv.org/abs/2310.13424v1|
|164|XGBD: Explanation-Guided Graph Backdoor Detection|Zihan Guan, Mengnan Du, Ninghao Liu|2023-09-28|Frontiers in artificial intelligence and applications|https://github.com/GuanZihan/GNN_backdoor_detection.|https://doi.org/10.48550/arXiv.2308.04406|
|165|Resisting Backdoor Attacks in Federated Learning via Bidirectional   Elections and Individual Perspective|Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng|2023-09-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/zhenqincn/Snowball|https://doi.org/10.48550/arXiv.2309.16456|
|166|TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal   Backdoored Models|Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha|2023-08-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/SRI-CSL/TIJO.|https://doi.org/10.1109/iccv51070.2023.00022|
|167|Towards Stealthy Backdoor Attacks against Speech Recognition via   Elements of Sound|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2023-07-01|arXiv|https://github.com/HanboCai/BadSpeech_SoE|https://doi.org/10.48550/arXiv.2307.08208|
|168|Detecting Backdoors in Pre-trained Encoders|Shiwei Feng, Guanhong Tao, Siyuan Cheng, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/GiantSeaweed/DECREE.|https://doi.org/10.1109/cvpr52729.2023.01569|
|169|VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion   Models|Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho|2023-06-01|NeurIPS|https://github.com/IBM/villandiffusion|http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html|
|170|Single Image Backdoor Inversion via Robust Smoothed Classifiers|Mingjie Sun, J. Zico Kolter|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/locuslab/smoothinv.|https://doi.org/10.1109/cvpr52729.2023.00784|
|171|Efficient Backdoor Attacks for Deep Neural Networks in Real-world   Scenarios|Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li|2023-06-01|arXiv|https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios|https://openreview.net/forum?id=vRyp2dhEQp|
|172|DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via   Restricted Adversarial Distillation|Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao|2023-06-01|OpenAlex|https://github.com/yanzhicong/DHBE|https://doi.org/10.48550/arXiv.2306.08009|
|173|Backdoor Cleansing with Unlabeled Data|Lu Pang, Tong Sun, Haibin Ling, Chao Chen|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/luluppang/BCU.|https://openreview.nethttps://arxiv.org/pdf/2211.12044|
|174|Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated   Graph Neural Network|Fan Liu, Siqi Lai, Yansong Ning, Hao Liu|2023-06-01|Lecture notes in computer science|https://github.com/usail-hkust/BkdFedGCN.|https://doi.org/10.1007/978-3-032-05981-9_22|
|175|Backdoor Defense via Deconfounded Representation Learning|Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/zaixizhang/CBD.|https://doi.org/10.1109/cvpr52729.2023.01177|
|176|An Empirical Study of Backdoor Attacks on Masked Auto Encoders|Shuli Zhuang, Pengfei Xia, Bin Li|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/zhuangshuli/MAE-Backdoor.|https://doi.org/10.1109/icassp49357.2023.10095201|
|177|Going in Style: Audio Backdoors Through Stylistic Transformations|Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/skoffas/going-in-style.|https://doi.org/10.1109/icassp49357.2023.10096332|
|178|Text-to-Image Diffusion Models can be Easily Backdoored through   Multimodal Data Poisoning|Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su|2023-05-01|ACM Multimedia|https://github.com/sf-zhai/BadT2I.|https://doi.org/10.48550/arXiv.2305.04175|
|179|Training-free Lexical Backdoor Attacks on Language Models|Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen|2023-04-26|Proceedings of the ACM Web Conference 2022|https://github.com/Jinxhy/TFLexAttack.|https://doi.org/10.48550/arXiv.2302.04116|
|180|Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware   Minimization|Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu|2023-04-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/SCLBD/BackdoorBench.|https://doi.org/10.1109/iccv51070.2023.00412|
|181|Defending Against Patch-based Backdoor Attacks on Self-Supervised   Learning|Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan|2023-04-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/UCDvision/PatchSearch|https://doi.org/10.1109/cvpr52729.2023.01178|
|182|Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection|Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen|2023-03-30|IEEE Transactions on Computational Social Systems|https://github.com/Seaocn/Link-Backdoor.|https://doi.org/10.1109/tcss.2023.3260833|
|183|AdaptGuard: Defending Against Universal Attacks for Model Adaptation|Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan|2023-03-01|arXiv|https://github.com/TomSheng21/AdaptGuard.|http://arxiv.org/abs/2303.10594v2|
|184|Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based   Artificial Bias|Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu|2023-03-01|IEEE Transactions on Circuits and Systems for Video Technology|https://github.com/KirinNg/DBA.|https://doi.org/10.1109/tcsvt.2025.3548657|
|185|CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive   Learning|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023-03-01|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf|
|186|Detecting Backdoors During the Inference Stage Based on Corruption   Robustness Consistency|Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao|2023-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/CGCL-codes/TeCo|https://doi.org/10.1109/cvpr52729.2023.01570|
|187|Mask and Restore: Blind Backdoor Defense at Test Time with Masked   Autoencoder|Tao Sun, Lu Pang, Weimin Lyu, Chao Chen, Haibin Ling|2023-03-01|arXiv|https://github.com/tsun/BDMAE.|https://doi.org/10.48550/arXiv.2303.15564|
|188|Revisiting Personalized Federated Learning: Robustness Against Backdoor   Attacks|Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng|2023-02-01|Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining|https://github.com/alibaba/FederatedScope|https://openreview.nethttps://arxiv.org/pdf/2302.01677.pdf|
|189|TrojText: Test-time Invisible Textual Trojan Insertion|Qian Lou, Yepeng Liu, Bo Feng|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/trojtext-test-time-invisible-textual-trojan/code)|https://openreview.net/pdf/090c1fa0cc728fa6eb032fe3c74b8b5125be7e94.pdf|
|190|SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via   Analyzing Scaled Prediction Consistency|Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu|2023-02-01|ICLR 2023 poster|https://github.com/JunfengGo/SCALE-UP.|https://openreview.net/pdf/341ae2d07a7459242b24bb6e6ff7e2aec7a756e1.pdf|
|191|Towards Robust Model Watermark via Reducing Parametric Vulnerability|Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia|2023-02-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/towards-robust-model-watermark-via-reducing/code)|https://openreview.net/pdf/c3ea0d03202ba1e2fbf2a003a936364bb447ce98.pdf|
|192|Backdoor Learning for NLP: Recent Advances, Challenges, and Future   Research Directions|Marwan Omar|2023-02-01|arXiv|https://github.com/marwanomar1/Backdoor-Learning-for-NLP.|https://doi.org/10.48550/arXiv.2302.06801|
|193|ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep   Learning Paradigms|Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia|2023-02-01|USENIX Security Symposium|https://github.com/ruoxi-jia-group/ASSET.|https://www.usenix.org/conference/usenixsecurity23/presentation/pan|
|194|Backdoor Attacks on Time Series: A Generative Approach|Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey|2023-02-01|SaTML 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/backdoor-attacks-on-time-series-a-generative/code)|https://openreview.net/pdf/b15b1e53dab0744f34198d60d727ddab895c8074.pdf|
|195|Learning to Backdoor Federated Learning|Henger Li, Wu Chen, Senchun Zhu, Zizhan Zheng|2023-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learning-to-backdoor-federated-learning/code)|https://openreview.net/pdf/b3222725885adf97fe0f200feabe9bbd3df94344.pdf|
|196|You Can Backdoor Personalized Federated Learning|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2023-01-01|ACM Trans. Knowl. Discov. Data 2024|https://github.com/BapFL/code.|https://doi.org/10.48550/arXiv.2307.15971|
|197|Universal Backdoor Attacks|Benjamin Schneider, Nils Lukas, Florian Kerschbaum|2023-01-01|arXiv|https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks.|https://openreview.net/forum?id=3QkzYBSWqL|
|198|UNICORN: A Unified Backdoor Trigger Inversion Framework|Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma|2023-01-01|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unicorn-a-unified-backdoor-trigger-inversion/code)|https://openreview.net/pdf/edd35173abda536a0bd486d49c34c8ce04e56652.pdf|
|199|Towards Stable Backdoor Purification through Feature Shift Tuning|Rui Min, Zeyu Qin, Li Shen, Minhao Cheng|2023-01-01|NeurIPS|https://github.com/AISafety-HKUST/stable_backdoor_purification.|http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html|
|200|The &quot;Beatrix&quot; Resurrections: Robust Backdoor Detection via Gram Matrices|Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang|2023-01-01|OpenAlex|https://github.com/wanlunsec/Beatrix|https://www.ndss-symposium.org/ndss-paper/the-beatrix-resurrections-robust-backdoor-detection-via-gram-matrices/|
|201|RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks|Marwan Omar|2023-01-01|arXiv|https://github.com/marwanomar1/Backdoor-Learning-for-NLP|https://doi.org/10.48550/arXiv.2302.09420|
|202|Removing Backdoors in Pre-trained Models by Regularized Continual Pre-training|Biru Zhu, Ganqu Cui, Yangyi Chen, Yujia Qin, Lifan Yuan, Chong Fu, Yangdong Deng, Zhiyuan Liu, Maosong Sun, Ming Gu|2023-01-01|Transactions of the Association for Computational Linguistics|https://github.com/thunlp/RECIPE.|https://openreview.net/pdf/b90599e4935794e4f111f07737fb0e5a485048f3.pdf|
|203|Reconstructive Neuron Pruning for Backdoor Defense|Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang|2023-01-01|ICML|https://github.com/bboylyg/RNP|https://proceedings.mlr.press/v202/li23v.html|
|204|NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models|Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma|2023-01-01|OpenAlex|https://github.com/RU-System-Software-and-Security/Notable.|https://doi.org/10.18653/v1/2023.acl-long.867|
|205|SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning|Harsh Chaudhari, Matthew Jagielski, Alina Oprea|2023-01-01|SaTML 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.09986/code)|https://openreview.net/pdf/512a5c7a02310e8ac2b28531e9e0c6518ad1c4e6.pdf|
|206|From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models|Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu|2023-01-01|arXiv|https://github.com/OPTML-Group/BiBadDiff.|https://doi.org/10.48550/arXiv.2311.02373|
|207|Distilling Cognitive Backdoor Patterns within an Image|Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey|2023-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/distilling-cognitive-backdoor-patterns-within/code)|https://openreview.net/pdf/9582391717db932771feaf1c877a1ff5a58478f5.pdf|
|208|Black-box Backdoor Defense via Zero-shot Image Purification|Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu|2023-01-01|NeurIPS|https://github.com/sycny/ZIP.|http://papers.nips.cc/paper_files/paper/2023/hash/b36554b97da741b1c48c9de05c73993e-Abstract-Conference.html|
|209|Beating Backdoor Attack at Its Own Game|Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue|2023-01-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/damianliumin/non-adversarial_backdoor.|https://doi.org/10.1109/ICCV51070.2023.00426|
|210|BackdoorBox: A Python Toolbox for Backdoor Learning|Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia|2023-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/backdoorbox-a-python-toolbox-for-backdoor/code)|https://openreview.net/pdf/81b89920b0128744bafa5c1943ac1ed8b0a871c7.pdf|
|211|Backdoor Defense via Adaptively Splitting Poisoned Dataset|Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/KuofengGao/ASD.|https://doi.org/10.1109/CVPR52729.2023.00390|
|212|Backdoor Attacks for Remote Sensing Data With Wavelet Transform|Nikolaus Dr√§ger, Yonghao Xu, Pedram Ghamisi|2023-01-01|IEEE Trans. Geos. Remote Sens., vol. 61, pp. 1-15, 2023|https://github.com/ndraeger/waba.|https://doi.org/10.1109/tgrs.2023.3289307|
|213|Backdoor Attack with Sparse and Invisible Trigger|Yinghua Gao, Yiming Li, Xueluan Gong, Zhifeng Li, Shu-Tao Xia, Qian Wang|2023-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/YinghuaGao/SIBA|https://doi.org/10.48550/arXiv.2306.06209|
|214|Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment|Haoran Wang, Kai Shu|2023-01-01|arXiv|https://github.com/wang2226/Backdoor-Activation-Attack|https://doi.org/10.48550/arXiv.2311.09433|
|215|BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models|J Kerekes Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian|2023-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/JJ-Vice/BAGM|https://doi.org/10.1109/tifs.2024.3386058|
|216|FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks|Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui|2023-01-01|arXiv|https://github.com/retsuh-bqw/FMP.|https://doi.org/10.48550/arXiv.2307.11565|
|217|Rethinking Backdoor Data Poisoning Attacks in the Context of   Semi-Supervised Learning|Marissa Catherine Connor, Vincent Emanuele|2022-12-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/rethinking-backdoor-data-poisoning-attacks-in/code)|https://openreview.net/pdf/1e8864ea33570efedf181847e8e700fc3a7e8855.pdf|
|218|Rickrolling the Artist: Injecting Backdoors into Text Encoders for   Text-to-Image Synthesis|Lukas Struppek, Dominik Hintersdorf, Kristian Kersting|2022-11-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/LukasStruppek/Rickrolling-the-Artist.|https://doi.org/10.1109/iccv51070.2023.00423|
|219|CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive   Learning|Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong|2022-11-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/corruptencoder-data-poisoning-based-backdoor/code)|https://openreview.net/pdf/a71769013eb8042087131d5a81891020c7af2964.pdf|
|220|BagFlip: A Certified Defense Against Data Poisoning|Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/bagflip-a-certified-defense-against-data/code)|https://openreview.net/pdf/960044f35c0a2651737dc6ac8644ffd315d6a2dc.pdf|
|221|Rethinking the Reverse-engineering of Trojan Triggers|Zhenting Wang, Kai Mei, Hailun Ding, Juan Zhai, Shiqing Ma|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/rethinking-the-reverse-engineering-of-trojan/code)|https://openreview.net/pdf/e8ad6cc8620c4cec22babbe51c8f36d680dcd00c.pdf|
|222|Towards Out-of-Distribution Sequential Event Prediction: A Causal Treatment|Chenxiao Yang, Qitian Wu, Qingsong Wen, Zhiqiang Zhou, Liang Sun, Junchi Yan|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/towards-out-of-distribution-sequential-event/code)|https://openreview.net/pdf/b5224a60869a26365b6e70239acbac055a762b08.pdf|
|223|Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems|Qiang Liu, Tongqing Zhou, Zhiping Cai, Yonghao Tang|2022-10-10|Proceedings of the 30th ACM International Conference on Multimedia|https://github.com/lqsunshine/DABA.|https://openreview.nethttps://dl.acm.org/doi/abs/10.1145/3503161.3548261|
|224|Expose Backdoors on the Way: A Feature-Based Efficient Defense against   Textual Backdoor Attacks|Sishuo Chen, Wenkai Yang, Zhiyuan Zhang, Xiaohan Bi, Xu Sun|2022-10-01|OpenAlex|https://github.com/lancopku/DAN.|https://doi.org/10.18653/v1/2022.findings-emnlp.47|
|225|FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated   Learning|Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, ...|2022-10-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/flip-a-provable-defense-framework-for/code)|https://openreview.net/pdf/6731b5784520aedd43f4da6cb01e5587b66819be.pdf|
|226|Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks   via Motifs|Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang|2022-10-01|IEEE Transactions on Computational Social Systems|https://github.com/Seaocn/Motif-Backdoor|https://doi.org/10.1109/tcss.2023.3267094|
|227|Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor   Attacks in Federated Learning|Yuxin Wen, Jonas Geiping, Liam H Fowl, Hossein Souri, Rama Chellappa, Micah Goldblum, Tom Goldstein|2022-10-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/thinking-two-moves-ahead-anticipating-other/code)|https://openreview.net/pdf/f0d55f776bc33c4bd42632e2a4a381cc8a49356b.pdf|
|228|Trap and Replace: Defending Backdoor Attacks by Trapping Them into an   Easy-to-Replace Subnetwork|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|2022-10-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/trap-and-replace-defending-backdoor-attacks/code)|http://papers.nips.cc/paper_files/paper/2022/hash/ea06e6e9e80f1c3d382317fff67041ac-Abstract-Conference.html|
|229|Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset   Copyright Protection|Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li|2022-10-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/untargeted-backdoor-watermark-towards/code)|http://papers.nips.cc/paper_files/paper/2022/hash/55bfedfd31489e5ae83c9ce8eec7b0e1-Abstract-Conference.html|
|230|TransCAB: Transferable Clean-Annotation Backdoor to Object Detection   with Natural Trigger in Real-World|Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, ‚Ä™Surya Nepal‚Ä¨, Derek Abbott|2022-09-01|OpenAlex|https://github.com/inconstance/T-shirt-natural-backdoor-dataset|https://doi.org/10.1109/SRDS60354.2023.00018|
|231|Deep Fidelity in DNN Watermarking: A Study of Backdoor Watermarking for   Classification Models|Guang Hua, Andrew Beng Jin Teoh|2022-08-01|Pattern Recognition, Vol. 144, Dec. 2023|https://github.com/ghua-ac/dnn_watermark.|https://doi.org/10.1016/j.patcog.2023.109844|
|232|Friendly Noise against Adversarial Noise: A Powerful Defense against   Data Poisoning Attacks|Tian Yu Liu, Yu Yang, Baharan Mirzasoleiman|2022-08-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/friendly-noise-against-adversarial-noise-a/code)|https://openreview.net/pdf/d929e1c412e3fecf6a4fb8991f306a09330510c6.pdf|
|233|RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact   DNN|Huy P. Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan|2022-08-01|European Conference on Computer Vision (ECCV 2022)|https://github.com/huyvnphan/ECCV2022-RIBAC|https://doi.org/10.1007/978-3-031-19772-7_41|
|234|Data-Efficient Backdoor Attacks|Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li|2022-07-01|Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence|https://github.com/xpf/Data-Efficient-Backdoor-Attacks.|https://openreview.nethttps://www.ijcai.org/proceedings/2022/0554.pdf|
|235|A Unified Evaluation of Textual Backdoor Learning: Frameworks and   Benchmarks|Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun|2022-06-01|NeurIPS 2022 Datasets and Benchmarks |[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/a-unified-evaluation-of-textual-backdoor/code)|http://papers.nips.cc/paper_files/paper/2022/hash/2052b3e0617ecb2ce9474a6feaf422b3-Abstract-Datasets_and_Benchmarks.html|
|236|Backdoor Attacks on Self-Supervised Learning|Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash|2022-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/UMBCvision/SSL-Backdoor|https://doi.org/10.1109/cvpr52688.2022.01298|
|237|Imperceptible Backdoor Attack: From Input Space to Feature   Representation|Nan Zhong, Zhenxing Qian, Xinpeng Zhang|2022-05-01|Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence|https://github.com/Ekko-zn/IJCAI2022-Backdoor.|https://doi.org/10.48550/arXiv.2205.03190|
|238|Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free|Tianlong Chen, Zhenyu Zhang, Yihua Zhang, Shiyu Chang, Sijia Liu, Zhangyang Wang|2022-05-01|arXiv|https://github.com/VITA-Group/Backdoor-LTH.|http://arxiv.org/abs/2205.11819v1|
|239|Enhancing Backdoor Attacks With Multi-Level MMD Regularization|Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li|2022-03-28|IEEE Transactions on Dependable and Secure Computing|https://github.com/xpf/Multi-Level-MMD-Regularization.|https://doi.org/10.1109/tdsc.2022.3161477|
|240|Partial Identification with Noisy Covariates: A Robust Optimization Approach|Wenshuo Guo, Mingzhang Yin, Yixin Wang, Michael Jordan|2022-02-09|CLeaR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/partial-identification-with-noisy-covariates/code)|https://openreview.net/pdf/e1406a39171680783aba296614172a44fd6bdbf7.pdf|
|241|Under-confidence Backdoors Are Resilient and Stealthy Backdoors|Minlong Peng, Zidi Xiong, Quang H. Nguyen, Mingming Sun, Khoa D. Doan, Ping Li|2022-02-01|arXiv|https://github.com/v-mipeng/LabelSmoothedAttack.git|http://arxiv.org/abs/2202.11203v2|
|242|Training with More Confidence: Mitigating Injected and Natural Backdoors   During Training|Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma|2022-02-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2202.06382/code)|http://papers.nips.cc/paper_files/paper/2022/hash/ec0c9ca85b4ea49c7ebfb503cf55f2ae-Abstract-Conference.html|
|243|Trigger Hunting with a Topological Prior for Trojan Detection|Xiaoling Hu, Xiao Lin, Michael Cogswell, Yi Yao, Susmit Jha, Chao Chen|2022-01-28|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/trigger-hunting-with-a-topological-prior-for/code)|https://openreview.net/pdf/4db1d42d467c296c5ec7fa3f38e37dcb5c140e84.pdf|
|244|Few-shot Backdoor Attacks via Neural Tangent Kernels|Jonathan Hayase, Sewoong Oh|2022-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/few-shot-backdoor-attacks-via-neural-tangent/code)|https://openreview.net/pdf/fbf6611dad17d0a7975a0a139013d45d767f9c59.pdf|
|245|Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks|Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu, Maosong Sun|2022-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/thunlp/StyleAttack.|https://openreview.net/pdf/09ec283781ceeabec1fbbbfda26653cf25e8db09.pdf|
|246|Stealthy Backdoors as Compression Artifacts|Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans|2022-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/yulongtzzz/Stealthy-Backdoors-as-Compression-Artifacts|https://doi.org/10.1109/tifs.2022.3160359|
|247|Provable Defense against Backdoor Policies in Reinforcement Learning|Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Xiaojin Zhu|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/provable-defense-against-backdoor-policies-in/code)|http://papers.nips.cc/paper_files/paper/2022/hash/5e67e6a814526079ad8505bf6d926fb6-Abstract-Conference.html|
|248|Post-Training Detection of Backdoor Attacks for Two-Class and   Multi-Attack Scenarios|Zhen Xiang, David J. Miller, George Kesidis|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/post-training-detection-of-backdoor-attacks/code)|https://openreview.net/pdf/ab4bf90af1442414ba5fa816448b5b73d44ecb92.pdf|
|249|Model-Contrastive Learning for Backdoor Elimination|Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen|2022-01-01|ACM Multimedia|https://github.com/WeCanShow/MCL.|https://doi.org/10.48550/arXiv.2205.04411|
|250|Label-Smoothed Backdoor Attack|Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li|2022-01-01|arXiv|https://github.com/v-mipeng/LabelSmoothedAttack.git|https://arxiv.org/abs/2202.11203|
|251|Imperceptible and Robust Backdoor Attack in 3D Point Cloud|Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia|2022-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/KuofengGao/IRBA|https://doi.org/10.48550/arXiv.2208.08052|
|252|Identifying a Training-Set Attack's Target Using Renormalized Influence   Estimation|Zayd Hammoudeh, Daniel Lowd|2022-01-01|arXiv|https://github.com/ZaydH/target_identification.|http://arxiv.org/abs/2201.10055v2|
|253|How to Backdoor Diffusion Models?|Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho|2022-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/how-to-backdoor-diffusion-models/code)|https://openreview.net/pdf/1dc679066d3bc93c7cd365d2948a2a48e4d2ff3a.pdf|
|254|Backdoor Defense via Decoupling the Training Process|Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 9 code implementations](https://www.catalyzex.com/paper/backdoor-defense-via-decoupling-the-training/code)|https://openreview.net/pdf/825a2fee50fe494bcf13085113d2a7565af192b6.pdf|
|255|Few-Shot Backdoor Attacks on Visual Object Tracking|Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/few-shot-backdoor-attacks-on-visual-object/code)|https://openreview.net/pdf/132d1b18d6c8d837cebbdb801781870f713295cb.pdf|
|256|Data-Free Backdoor Removal Based on Channel Lipschitzness|Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu|2022-01-01|Lecture notes in computer science|https://github.com/rkteddy/channel-Lipschitzness-based-pruning.|https://doi.org/10.1007/978-3-031-20065-6_11|
|257|Black-box Dataset Ownership Verification via Backdoor Watermarking|Yiming Li, Mingyan Zhu, Xue Yang, Yong Jiang, Tao Wei, Shu-Tao Xia|2022-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/THUYimingLi/DVBW.|https://doi.org/10.1109/TIFS.2023.3265535|
|258|BadPrompt: Backdoor Attacks on Continuous Prompts|Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, Xiaojie Yuan|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/badprompt-backdoor-attacks-on-continuous/code)|http://papers.nips.cc/paper_files/paper/2022/hash/f0722b58f02d7793acf7d328928f933a-Abstract-Conference.html|
|259|Backdoor Attacks on Vision Transformers|Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash|2022-01-01|arXiv|https://github.com/UCDvision/backdoor_transformer.git|https://doi.org/10.48550/arXiv.2206.08477|
|260|Backdoor Attacks in the Supply Chain of Masked Image Modeling|Xinyue Shen, Xinlei He, Zheng Li, Yun Shen, Michael Backes, Yang Zhang|2022-01-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/backdoor-attacks-in-the-supply-chain-of/code)|https://openreview.net/pdf/0c5ec0b08ce9e3512fdc3d80cd06802dbb8ef089.pdf|
|261|Augmentation Backdoors|Joseph Rance, Yiren Zhao, Ilia Shumailov, Robert D. Mullins|2022-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/augmentation-backdoors/code)|https://openreview.net/pdf/59a474155bd99e72fd1d60447640fe322d4f340d.pdf|
|262|Architectural Backdoors in Neural Networks|Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot|2022-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/architectural-backdoors-in-neural-networks/code)|https://openreview.net/pdf/c202e3f7b58579019c2ae7534b94815d06eda13d.pdf|
|263|An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks|Xinqiao Zhang, Huili Chen, Ke Huang, Farinaz Koushanfar|2022-01-01|arXiv|https://github.com/xinqiaozhang/adatrojan|https://doi.org/10.48550/arXiv.2204.04329|
|264|FIBA: Frequency-Injection based Backdoor Attack in Medical Image   Analysis|Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao|2021-12-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/HazardFY/FIBA.|https://doi.org/10.1109/cvpr52688.2022.02021|
|265|Manipulating SGD with Data Ordering Attacks|Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A. Erdogdu, Ross Anderson|2021-11-09|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/manipulating-sgd-with-data-ordering-attacks/code)|https://openreview.net/pdf/38b5087efcece7a26b421cd3cd7e0a2a30c8096e.pdf|
|266|Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving Adversarial Outcomes|Sanghyun Hong, Michael-Andrei Panaitescu-Liess, Yigitcan Kaya, Tudor Dumitras|2021-11-09|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/qu-anti-zation-exploiting-quantization/code)|https://openreview.net/pdf/d99b499610c11e58db2b8e2b8b421fbd7ec493a8.pdf|
|267|Anomaly Localization in Model Gradients Under Backdoor Attacks Against   Federated Learning|Zeki Bilgin|2021-11-01|OpenAlex|https://github.com/ArcelikAcikKaynak/Federated_Learning.git|https://dblp.uni-trier.de/db/journals/corr/corr2111.html#abs-2111-14683|
|268|A Kernel Test for Causal Association via Noise Contrastive Backdoor   Adjustment|Robert Hu, Dino Sejdinovic, Robin J. Evans|2021-11-01|J. Mach. Learn. Res.|https://github.com/MrHuff/kgformula|https://jmlr.org/papers/v25/21-1409.html|
|269|Adversarial Neuron Pruning Purifies Backdoored Deep Models|Dongxian Wu, Yisen Wang|2021-10-27|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/adversarial-neuron-pruning-purifies/code)|https://proceedings.neurips.cc/paper/2021/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html|
|270|Anti-Backdoor Learning: Training Clean Models on Poisoned Data|Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma|2021-10-21|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/anti-backdoor-learning-training-clean-models/code)|https://proceedings.neurips.cc/paper/2021/hash/7d38b1e9bd793d3f45e0e212a729a93c-Abstract.html|
|271|A Backdoor Attack against 3D Point Cloud Classifiers|Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis|2021-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/zhenxianglance/PCBA.|https://doi.org/10.1109/iccv48922.2021.00750|
|272|AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value   Analysis|Junfeng Guo, Ang Li, Cong Liu|2021-10-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/aeva-black-box-backdoor-detection-using/code)|https://openreview.net/pdf/b8ad85b4ddd615a5abac4d7c1d5713fc92b9f0e9.pdf|
|273|Invisible Backdoor Attack with Sample-Specific Triggers|Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu|2021-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/yuezunli/ISSBA.|https://doi.org/10.1109/iccv48922.2021.01615|
|274|Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text   Style Transfer|Fanchao Qi, Yang‚ÄêYi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun|2021-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/thunlp/StyleAttack.|https://doi.org/10.18653/v1/2021.emnlp-main.374|
|275|RAP: Robustness-Aware Perturbations for Defending against Backdoor   Attacks on NLP Models|Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun|2021-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/lancopku/RAP.|https://doi.org/10.18653/v1/2021.emnlp-main.659|
|276|Backdoor Attack on Hash-based Image Retrieval via Clean-label Data   Poisoning|Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia|2021-09-01|BMVC|https://github.com/KuofengGao/CIBA.|http://proceedings.bmvc2023.org/172/|
|277|BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning|Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song|2021-08-01|OpenAlex|https://github.com/wanglun1996/multi_agent_rl_backdoor_videos.|https://doi.org/10.24963/ijcai.2021/509|
|278|BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised   Learning|Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong|2021-08-01|2022 IEEE Symposium on Security and Privacy (SP)|https://github.com/jjy1994/BadEncoder.|https://openreview.nethttps://arxiv.org/pdf/2108.00352.pdf|
|279|Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word   Substitution|Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun|2021-06-01|ACL/IJCNLP|https://github.com/thunlp/BkdAtk-LWS.|https://doi.org/10.18653/v1/2021.acl-long.377|
|280|Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks   Trained from Scratch|Hossein Souri, Liam H Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein|2021-06-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/sleeper-agent-scalable-hidden-trigger/code)|http://papers.nips.cc/paper_files/paper/2022/hash/79eec295a3cd5785e18c61383e7c996b-Abstract-Conference.html|
|281|Incompatibility Clustering as a Defense Against Backdoor Poisoning   Attacks|Charles Jin, Melinda Sun, Martin C. Rinard|2021-05-01|ICLR 2023 poster|https://github.com/charlesjin/compatibility_clustering|https://openreview.net/pdf/e27bb4c7787b3770053151428e69c5ab0f279dd2.pdf|
|282|SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics|Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh|2021-04-22|arXiv|https://github.com/SewoongLab/spectre-defense|http://export.arxiv.org/pdf/2104.11315|
|283|Targeted Attack against Deep Neural Networks via Flipping Limited Weight   Bits|Jiawang Bai, Baoyuan Wu, Yong Zhang, Yiming Li, Zhifeng Li, Shu-Tao Xia|2021-02-01|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/targeted-attack-against-deep-neural-networks/code)|https://openreview.net/pdf/ed4d75e28ae70ba28f4895cf7097cf634745d11a.pdf|
|284|Neural Attention Distillation: Erasing Backdoor Triggers from Deep   Neural Networks|Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma|2021-01-14|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 8 code implementations](https://www.catalyzex.com/paper/neural-attention-distillation-erasing/code)|https://openreview.net/pdf/42f5786a622e8cdc4ce43d79d5d83ebe8e4feeeb.pdf|
|285|Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching|Jonas Geiping, Liam H Fowl, W. Ronny Huang, Wojciech Czaja, Gavin Taylor, Michael Moeller, Tom Goldstein|2021-01-12|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/witches-brew-industrial-scale-data-poisoning/code)|https://openreview.net/pdf/3a3c570da85848de52605f6669aae395d063027b.pdf|
|286|Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger|Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun|2021-01-01|ACL/IJCNLP|https://github.com/thunlp/HiddenKiller.|https://doi.org/10.18653/v1/2021.acl-long.37|
|287|WaNet -- Imperceptible Warping-based Backdoor Attack|Tuan Anh Nguyen, Anh Tuan Tran|2021-01-01|International Conference on Learning Representations|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/wanet-imperceptible-warping-based-backdoor/code)|https://openreview.net/pdf/db3277f5b47619abfe13880772b864960e98f643.pdf|
|288|Use Procedural Noise to Achieve Backdoor Attack|Xuan Chen, Yuena Ma, Shiwei Lu|2021-01-01|IEEE Access|https://github.com/928082786/pnoiseattack.|https://doi.org/10.1109/access.2021.3110239|
|289|Red Alarm for Pre-trained Models: Universal Vulnerabilities by Neuron-Level Backdoor Attacks|Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun|2021-01-01|ICML 2021 Workshop AML Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/red-alarm-for-pre-trained-models-universal/code)|https://openreview.net/pdf/1cc11ab778ba03f41a45f941b3a3e42ccb867cc6.pdf|
|290|ONION: A Simple and Effective Defense Against Textual Backdoor Attacks|Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu, Maosong Sun|2021-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/thunlp/ONION.|https://doi.org/10.18653/v1/2021.emnlp-main.752|
|291|Adversarial Unlearning of Backdoors via Implicit Hypergradient|Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia|2021-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-of-backdoors-via/code)|https://openreview.net/pdf/6aeb6e81c9d0eadbb4cfbefb6caac0f155d561ea.pdf|
|292|Handcrafted Backdoors in Deep Neural Networks|Sanghyun Hong, Nicholas Carlini, Alexey Kurakin|2021-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/handcrafted-backdoors-in-deep-neural-networks/code)|http://papers.nips.cc/paper_files/paper/2022/hash/3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html|
|293|Excess Capacity and Backdoor Poisoning|Naren Sarayu Manoj, Avrim Blum|2021-01-01|NeurIPS 2021 Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/excess-capacity-and-backdoor-poisoning/code)|https://proceedings.neurips.cc/paper/2021/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html|
|294|CRFL: Certifiably Robust Federated Learning against Backdoor Attacks|Chulin Xie, Minghao Chen, Pin-Yu Chen, Bo Li|2021-01-01|OpenAlex|https://github.com/AI-secure/CRFL.|http://proceedings.mlr.press/v139/xie21a.html|
|295|An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware|M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang|2021-01-01|ICLR 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/an-optimization-perspective-on-realizing/code)|https://openreview.net/pdf/628fdbcebf74b3b22b28cf024722d2d5b78c9136.pdf|
|296|Poisoned classifiers are not only backdoored, they are fundamentally   broken|Mingjie Sun, Siddhant Agarwal, J. Zico Kolter|2020-10-01|ICLR 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/poisoned-classifiers-are-not-only-backdoored/code)|https://openreview.net/pdf/4959459ccc8a6c2d401fe6ca978ce4b82b4f3ff0.pdf|
|297|Weight Poisoning Attacks on Pre-trained Models|Keita Kurita, Paul Michel, Graham Neubig|2020-04-01|arXiv|https://github.com/neulab/RIPPLe.|http://arxiv.org/abs/2004.06660v1|
|298|Backdoor Attack against Speaker Verification|Tongqing Zhai, Yiming Li, Ziqi Zhang, Baoyuan Wu, Yong Jiang, Shu-Tao Xia|2020-01-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/zhaitongqing233/Backdoor-attack-against-speaker-verification.|https://doi.org/10.1109/ICASSP39728.2021.9413468|
|299|Backdoor Learning: A Survey|Yiming Li, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia|2020-01-01|IEEE Transactions on Neural Networks and Learning Systems|https://github.com/THUYimingLi/backdoor-learning-resources|https://doi.org/10.1109/TNNLS.2022.3182979|
|300|Graph Backdoor|Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang|2020-01-01|USENIX Security Symposium|https://github.com/HarrialX/GraphBackdoor|https://www.usenix.org/conference/usenixsecurity21/presentation/xi|
|301|Input-Aware Dynamic Backdoor Attack|Tuan Anh Nguyen, Anh Tuan Tran|2020-01-01|Neural Information Processing Systems|https://github.com/VinAIResearch/input-aware-backdoor-attack-release.|https://openreview.nethttp://proceedings.neurips.cc/paper/2020/file/234e691320c0ad5b45ee3c96d0d7b8f8-Paper.pdf|
|302|Rethinking the Trigger of Backdoor Attack|Yiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia|2020-01-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/rethinking-the-trigger-of-backdoor-attack/code)|https://openreview.net/pdf/f41085225b4c2960c0e50e0201c0c0ab536e020f.pdf|
|303|Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness|Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue Lin|2019-12-19|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/bridging-mode-connectivity-in-loss-landscapes/code)|https://openreview.net/pdf/fb8082dd5515e11c88f59b0f4911266f1891fb61.pdf|
|304|Attack-Resistant Federated Learning with Residual-based Reweighting|Shuhao Fu, Chulin Xie, Bo Li, Qifeng Chen|2019-12-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/attack-resistant-federated-learning-with/code)|https://openreview.net/pdf/1ea807b624ecc563e3b617f0948502afeee0ec8c.pdf|
