# Backdoor Learning Papers

Updated list of Backdoor Learning papers as of **January 08, 2026**. 

## Quick Access
üîç **[Interactive Search & Browse](https://mtuann.github.io/papers/)** - Filter, search, and explore all papers with an intuitive interface

## Overview
- **Coverage**: Papers from 2016 to present
- **Sources**: arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML venues
- **Updates**: Automated collection of new publications
- **Features**: Advanced search, code availability tracking, and multi-venue coverage

## Related Topics
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** | **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** | **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** | **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)**
- **[Serverless Computing](https://mtuann.github.io/papers/)** | **[Multi-Modal Learning](https://mtuann.github.io/papers/)**

## Backdoor Learning Papers with Code
This section lists papers with available code (sorted by publication date). For the complete paper list, visit the [Research Papers Page](https://mtuann.github.io/papers/).

---

## Support
If you find this resource helpful, consider supporting its development:

- **Ko-fi** (PayPal/Card): [ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)
- **Techcombank** (Vietnam): 5877 5555 55 (Nguyen Thi Lan Phuong)

---

*This repository is regularly updated. For the latest data, visit the [Research Papers Page](https://mtuann.github.io/papers/).*


|No.|Title|Authors|Publish Date|Venue|Code|
|---|---|---|---|---|---|
|1|[ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures](https://doi.org/10.48550/arxiv.2512.19730)|Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li|2025-12-17|in IEEE Transactions on Information Forensics and Security, vol. 20, pp. 10082-10097, 2025|[![Star](https://img.shields.io/github/stars/SeRAlab/ArcGen)](https://github.com/SeRAlab/ArcGen)|
|2|[Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs](http://arxiv.org/abs/2512.10600v1)|Han Yang, Shaofeng Li, Tian Dong, Xiangyu Xu, Guangchi Liu, Zhen Ling|2025-12-11|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/PlayerYangh/Authority-Trigger)](https://github.com/PlayerYangh/Authority-Trigger)|
|3|[Patronus: Identifying and Mitigating Transferable Backdoors in Pre-trained Language Models](https://doi.org/10.48550/arxiv.2512.06899)|Zhao, Tianhang, Du, Wei, Zhao, Haodong, Duan, Sufeng, Liu, Gongshen|2025-12-01|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/zth855/Patronus)](https://github.com/zth855/Patronus)|
|4|[Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models](http://arxiv.org/abs/2512.00343v1)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-11-29|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/Robin-WZQ/AMDET)](https://github.com/Robin-WZQ/AMDET)|
|5|[Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck](https://doi.org/10.48550/arxiv.2511.21923)|Liu Xin-yu, Zhang Xu, Chen Can, Wang Ren|2025-11-26|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/XinyuLiu71/Information_Bottleneck_Backdoor)](https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git)|
|6|[AutoBackdoor: Automating Backdoor Attacks via LLM Agents](https://doi.org/10.48550/arxiv.2511.16709)|Li, Yige, Li Zhe, Zhao Wei, Min, Nay Myat, Huang, Hanxun, Ma, Xingjun, Sun Jun|2025-11-20|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/bboylyg/BackdoorLLM)](https://github.com/bboylyg/BackdoorLLM)|
|7|[Enhancing All-to-X Backdoor Attacks with Optimized Target Class Mapping](https://doi.org/10.48550/arxiv.2511.13356)|Wang Lei, Tian Yu-long, Han Hao, Xu Fengyuan|2025-11-17|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/kazefjj/A2X-backdoor)](https://github.com/kazefjj/A2X-backdoor)|
|8|[MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models](https://doi.org/10.48550/arxiv.2511.10098)|Wang Zihan, Pang, Guansong, Miao Wenjun, Zheng Jin, Bai Xiao|2025-11-13|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/mala-lab/MTAttack)](https://github.com/mala-lab/MTAttack)|
|9|[Flareon: Stealthy all2all Backdoor Injection via Poisoned Augmentation](https://openreview.net/pdf/8f5e6d6b8c53b5115dfb5e4950961efed881feaa.pdf)|Tianrui Qin, Xuan Wang, Xianghuan He, Yiren Zhao, Kejiang Ye, Chengzhong Xu, Xitong Gao|2025-11-03|ACM Transactions on Knowledge Discovery from Data|[![Star](https://img.shields.io/github/stars/lafeat/flareon)](https://github.com/lafeat/flareon)|
|10|[BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://doi.org/10.48550/arxiv.2511.18921)|Li Juncheng, Li Yige, Huang, Hanxun, Chen Yunhao, Wang Xin, Wang YiXu, Ma, Xingjun, Jiang, Yu-Gang|2025-11-01|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/bin015/BackdoorVLM)](https://github.com/bin015/BackdoorVLM)|
|11|[Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning](https://doi.org/10.48550/arXiv.2510.17021)|Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu|2025-10-19|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Backdoor)](https://github.com/OPTML-Group/Unlearn-Backdoor)|
|12|[CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://doi.org/10.48550/arXiv.2509.09703)|Association for Computational Linguistics 2025, Han Meng, Lin Changting, Tian Shengwei, Xu Zhenhua, Yue Xubin, Zhao Xi-x...|2025-10-10|Underline Science Inc.|[![Star](https://img.shields.io/github/stars/Xuzhenhua55/CTCC)](https://github.com/Xuzhenhua55/CTCC)|
|13|[On the Out-of-Distribution Backdoor Attack for Federated Learning](https://doi.org/10.48550/arXiv.2509.13219)|Jin-Sen Xu, Zikai Zhang, Rui Hu|2025-09-16|OpenAlex|[![Star](https://img.shields.io/github/stars/JiiahaoXU/SoDa-BNGuard)](https://github.com/JiiahaoXU/SoDa-BNGuard)|
|14|[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](https://doi.org/10.48550/arXiv.2509.11173)|Simin Chen, Jinjun Peng, Yixin He, Junfeng Yang, Baishakhi Ray|2025-09-14|arXiv|[![Star](https://img.shields.io/github/stars/SeekingDream/DLCompilerAttack)](https://github.com/SeekingDream/DLCompilerAttack)|
|15|[CABIN: Debiasing Vision-Language Models Using Backdoor Adjustments](https://doi.org/10.24963/ijcai.2025/55)|B. Y. Pang, Tingrui Qiao, Caroline Walker, Chris Cunningham, Yun Sing Koh|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/ipangbo/causal-debias)](https://github.com/ipangbo/causal-debias)|
|16|[FedDLAD: A Federated Learning Dual-Layer Anomaly Detection Framework for Enhancing Resilience Against Backdoor Attacks](https://doi.org/10.24963/ijcai.2025/559)|Binbin Ding, Penghui Yang, Sheng-Jun Huang|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/dingbinb/FedDLAD)](https://github.com/dingbinb/FedDLAD)|
|17|[PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning](https://doi.org/10.48550/arXiv.2507.00485)|Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/azure-123/PNAct)](https://github.com/azure-123/PNAct)|
|18|[Virus Infection Attack on LLMs: Your Poisoning Can Spread "VIA" Synthetic Data](http://arxiv.org/abs/2509.23041v2)|Zi Liang, Qingqing Ye, Xuan Liu, Yanyun Wang, Jianliang Xu, Haibo Hu|2025-09-01|arXiv|[![Star](https://img.shields.io/github/stars/liangzid/VirusInfectionAttack)](https://github.com/liangzid/VirusInfectionAttack)|
|19|[Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://doi.org/10.48550/arXiv.2508.21004)|Chen Chen, Yuchen Sun, Jiaxin Gao, Xueluan Gong, Qian Wang, Ziyao Wang, Yongsen Zheng, Kwok-Yan Lam|2025-08-28|Zenodo (CERN European Organization for Nuclear Research)|[![Star](https://img.shields.io/github/stars/azshue/AutoPoison)](https://github.com/azshue/AutoPoison)|
|20|[Coward: Collision-based Watermark for Proactive Federated Backdoor Detection](http://arxiv.org/abs/2508.02115v3)|Wenjie Li, Siying Gu, Yiming Li, Kangjie Chen, Zhili Chen, Tianwei Zhang, Shu-Tao Xia, Dacheng Tao|2025-08-01|arXiv|[![Star](https://img.shields.io/github/stars/still2009/cowardFL)](https://github.com/still2009/cowardFL)|
|21|[CLIP-Guided Backdoor Defense through Entropy-Based Poisoned Dataset   Separation](https://doi.org/10.48550/arXiv.2507.05113)|Binyan Xu, Fan Yang, Xilin Dai, Di Tang, Kehuan Zhang|2025-07-01|OpenAlex|[![Star](https://img.shields.io/github/stars/binyxu/CGD)](https://github.com/binyxu/CGD)|
|22|[BackFed: An Efficient &amp; Standardized Benchmark Suite for Backdoor Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2507.04903)|Thinh Dao, Dung Thuy Nguyen, Khoa D. Doan, Kok-Seng Wong|2025-07-01|arXiv|[![Star](https://img.shields.io/github/stars/thinh-dao/BackFed)](https://github.com/thinh-dao/BackFed)|
|23|[Invisible Backdoor Attack against Self-supervised Learning](https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.html)|Hanrong Zhang, Zhenting Wang, Boheng Li, Fulin Lin, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqi...|2025-06-10|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/Zhang-Henry/INACTIVE)](https://github.com/Zhang-Henry/INACTIVE)|
|24|[SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in   VLMs](https://doi.org/10.48550/arXiv.2506.04743)|Shuhan Xu, Siyuan Liang, Hongling Zheng, Aishan Liu, Xinbiao Wang, Yong Luo, Fu Lin, Leszek Rutkowski, Dacheng Tao|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/Ciconey/SRD)](https://github.com/Ciconey/SRD.git)|
|25|[TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor   Attacks on Deep Reinforcement Learning](https://doi.org/10.48550/arXiv.2506.09562)|Mingxuan Zhang, Oubo Ma, Kang Wei, Songze Li, Shouling Ji|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/S3IC-Lab/TooBadRL)](https://github.com/S3IC-Lab/TooBadRL)|
|26|[Defending the Edge: Representative-Attention for Mitigating Backdoor   Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2505.10297)|Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa|2025-05-01|arXiv|[![Star](https://img.shields.io/github/stars/Peatech/FeRA_defense)](https://github.com/Peatech/FeRA_defense.git)|
|27|[Towards Dataset Copyright Evasion Attack against Personalized   Text-to-Image Diffusion Models](http://arxiv.org/abs/2505.02824v1)|Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia|2025-05-01|arXiv|[![Star](https://img.shields.io/github/stars/csyufei/CEAT2I)](https://github.com/csyufei/CEAT2I)|
|28|[Dynamic Attention Analysis for Backdoor Detection in Text-to-Image   Diffusion Models](https://doi.org/10.48550/arXiv.2504.20518)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-04-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/DAA)](https://github.com/Robin-WZQ/DAA)|
|29|[Propaganda via AI? A Study on Semantic Backdoors in Large Language   Models](https://doi.org/10.48550/arXiv.2504.12344)|Nay Myat Min, Long H. Pham, Yige Li, Jun Sun|2025-04-01|arXiv|[![Star](https://img.shields.io/github/stars/NayMyatMin/RAVEN)](https://github.com/NayMyatMin/RAVEN)|
|30|[Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature   Awareness](https://doi.org/10.48550/arXiv.2503.09336)|Yu Feng, Dingxin Zhang, Runkai Zhao, Yong Xia, Heng Huang, Tom Weidong Cai|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/HazardFY/SPBA)](https://github.com/HazardFY/SPBA)|
|31|[Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](http://arxiv.org/abs/2503.17724v2)|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/TwT)](https://github.com/Robin-WZQ/TwT)|
|32|[CBW: Towards Dataset Ownership Verification for Speaker Verification via   Clustering-based Backdoor Watermarking](https://doi.org/10.48550/arXiv.2503.05794)|Yiming Li, Kaiying Yan, Shuo Shao, Tongqing Zhai, Shu-Tao Xia, Zhan Qin, Dacheng Tao|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/Radiant0726/CBW)](https://github.com/Radiant0726/CBW)|
|33|[Detecting Backdoor Attacks in Federated Learning via Direction Alignment   Inspection](https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.html)|Jiahao Xu, Zikai Zhang, Rui Hu|2025-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/JiiahaoXU/AlignIns)](https://github.com/JiiahaoXU/AlignIns)|
|34|[DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on   LLM-based Agent](https://doi.org/10.48550/arXiv.2502.12575)|Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su|2025-02-18|arXiv|[![Star](https://img.shields.io/github/stars/whfeLingYu/DemonAgent)](https://github.com/whfeLingYu/DemonAgent)|
|35|[BackdoorDM: A Comprehensive Benchmark for Backdoor Learning in Diffusion   Model](https://doi.org/10.48550/arXiv.2502.11798)|Weilin Lin, Nanjun Zhou, Yanyun Wang, Jianze Li, Hui Xiong, Li Liu|2025-02-17|arXiv|[![Star](https://img.shields.io/github/stars/linweiii/BackdoorDM)](https://github.com/linweiii/BackdoorDM)|
|36|[BoT: Breaking Long Thought Processes of o1-like Large Language Models   through Backdoor Attack](https://doi.org/10.48550/arXiv.2502.12202)|Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu|2025-02-16|arXiv|[![Star](https://img.shields.io/github/stars/zihao-ai/BoT)](https://github.com/zihao-ai/BoT)|
|37|[Revisiting the Auxiliary Data in Backdoor Purification](https://doi.org/10.48550/arXiv.2502.07231)|Shaokui Wei, Shanchao Yang, Jiayin Liu, Hongyuan Zha|2025-02-10|arXiv|[![Star](https://img.shields.io/github/stars/shawkui/BackdoorBenchER)](https://github.com/shawkui/BackdoorBenchER)|
|38|[Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in   Multilingual LLMs](https://doi.org/10.48550/arXiv.2502.16901)|Himanshu Beniwal, Sailesh Panda, Birudugadda Srivibhav, Mayank Singh|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/himanshubeniwal/X-BAT)](https://github.com/himanshubeniwal/X-BAT)|
|39|[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on   Diffusion Models](https://doi.org/10.48550/arXiv.2502.20650)|Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/paoche11/Gungnir)](https://github.com/paoche11/Gungnir)|
|40|[Detecting Backdoor Samples in Contrastive Language Image Pretraining](https://openreview.net/forum?id=KmQEsIfhr9)|Hanxun Huang, Sarah Monazam Erfani, Yige Li, Xingjun Ma, James Bailey|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/HanxunH/Detect-CLIP-Backdoor-Samples)](https://github.com/HanxunH/Detect-CLIP-Backdoor-Samples)|
|41|[BadRefSR: Backdoor Attacks Against Reference-based Image Super   Resolution](https://doi.org/10.1109/icassp49660.2025.10889523)|Xue Yang, Tao Chen, Lei Guo, Wenbo Jiang, Ji Guo, Yongming Li, Jiaming He|2025-02-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/xuefusiji/BadRefSR)](https://github.com/xuefusiji/BadRefSR)|
|42|[UNIDOOR: A Universal Framework for Action-Level Backdoor Attacks in Deep   Reinforcement Learning](https://doi.org/10.48550/arXiv.2501.15529)|Oubo Ma, Linkang Du, Yang Dai, Chunyi Zhou, Qingming Li, Yuwen Pu, Shouling Ji|2025-01-26|arXiv|[![Star](https://img.shields.io/github/stars/maoubo/UNIDOOR)](https://github.com/maoubo/UNIDOOR)|
|43|[Mechanistic Exploration of Backdoored Large Language Model Attention Patterns](https://doi.org/10.48550/arXiv.2508.15847)|Mohammed Abu Baker, Lakshmi Babu Saheer|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/mshahoyi/sa_attn_analysis)](https://github.com/mshahoyi/sa_attn_analysis)|
|44|[Vertical Federated Unlearning via Backdoor Certification](https://doi.org/10.48550/arXiv.2412.11476)|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025-01-01|IEEE Transactions on Services Computing|[![Star](https://img.shields.io/github/stars/mengde-han/VFL-unlearn)](https://github.com/mengde-han/VFL-unlearn)|
|45|[UFID: A Unified Framework for Black-box Input-level Backdoor Detection on Diffusion Models](https://doi.org/10.1609/aaai.v39i26.34941)|Zihan Guan, Mengxuan Hu, Sheng Li, Anil Kumar S. Vullikanti|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/GuanZihan/official_UFID)](https://github.com/GuanZihan/official_UFID)|
|46|[ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training](https://doi.org/10.48550/arXiv.2511.00446)|Xin Yao, Haiyang Zhao, Yimin Chen, Jiawei Guo, Kecheng Huang, Ming Zhao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/xinyaocse/ToxicTextCLIP)](https://github.com/xinyaocse/ToxicTextCLIP)|
|47|[Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model](https://doi.org/10.48550/arXiv.2503.17724)|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/IBA)](https://github.com/Robin-WZQ/IBA)|
|48|[The Ripple Effect: On Unforeseen Complications of Backdoor Attacks](https://openreview.net/forum?id=sw1Sm72dmV)|Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/zhangrui4041/Backdoor_Complications)](https://github.com/zhangrui4041/Backdoor_Complications)|
|49|[Test-Time Multimodal Backdoor Detection by Contrastive Prompting](https://openreview.net/forum?id=1jd25AlvHS)|Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng|2025-01-01|ICML|[![Star](https://img.shields.io/github/stars/Purshow/BDetCLIP)](https://github.com/Purshow/BDetCLIP)|
|50|[Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack](https://doi.org/10.48550/arXiv.2509.23871)|Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/WhitolfChen/SCAR)](https://github.com/WhitolfChen/SCAR)|
|51|[TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood Screening](https://doi.org/10.48550/arXiv.2510.14299)|Nam Le, Leo Yu Zhang, Kewen Liao, Shirui Pan, Wei Luo|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/namle-w/TEDpp)](https://github.com/namle-w/TEDpp)|
|52|[Sealing The Backdoor: Unlearning Adversarial Text Triggers In Diffusion Models Using Knowledge Distillation](https://doi.org/10.48550/arXiv.2508.18235)|Ashwath Vaithinathan Aravindan, Abha Jha, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Mystic-Slice/Sealing-The-Backdoor)](https://github.com/Mystic-Slice/Sealing-The-Backdoor)|
|53|[Rounding-Guided Backdoor Injection in Deep Learning Model Quantization](https://doi.org/10.48550/arXiv.2510.09647)|Xiangxiang Chen, Peixin Zhang, Jun Sun, Wenhai Wang, Jingyi Wang|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/cxx122/QuRA)](https://github.com/cxx122/QuRA)|
|54|[REFINE: Inversion-Free Backdoor Defense via Model Reprogramming](https://openreview.net/forum?id=4IYdCws9fc)|Yukun Chen, Shuo Shao, Enhao Huang, Yiming Li, Pin-Yu Chen, Zhan Qin, Kui Ren|2025-01-01|ICLR|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|55|[SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs](https://doi.org/10.48550/arXiv.2508.06153)|Zhengxian Wu, Juan Wen, Wanli Peng, Haowei Chang, Yinghan Zhou, Yiming Xue|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)](https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)|
|56|[Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking](https://doi.org/10.1109/AVSS65446.2025.11149824)|Yu-Feng Chen, Tzuhsuan Huang, Pin-Yen Chiu, Jun-Cheng Chen|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/aiiu-lab/BackdoorImageEditing)](https://github.com/aiiu-lab/BackdoorImageEditing)|
|57|[Circumventing Backdoor Space via Weight Symmetry](https://openreview.net/forum?id=dqYO5LVyYh)|Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/JiePeng104/TSC)](https://github.com/JiePeng104/TSC)|
|58|[Backdoor Token Unlearning: Exposing and Defending Backdoors in   Pretrained Language Models](https://doi.org/10.1609/aaai.v39i23.34605)|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/XDJPH/BTU)](https://github.com/XDJPH/BTU)|
|59|[FLARE: Towards Universal Dataset Purification against Backdoor Attacks](https://doi.org/10.1109/TIFS.2025.3581719)|Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li|2025-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|60|[BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://doi.org/10.48550/arXiv.2507.18305)|Biao Yi, Zekun Fei, Jianing Geng, Tong Li, Lihai Nie, Zheli Liu, Yiming Li|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/FZaKK/BadReasoner)](https://github.com/FZaKK/BadReasoner)|
|61|[BeDKD: Backdoor Defense based on Dynamic Knowledge Distillation and Directional Mapping Modulator](https://doi.org/10.48550/arXiv.2508.01595)|Zhengxian Wu, Juan Wen, Wanli Peng, Yinghan Zhou, Changtong dou, Yiming Xue|2025-01-01|AAAI 2026|[![Star](https://img.shields.io/github/stars/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)](https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)|
|62|[Cert-SSB: Toward Certified Sample-Specific Backdoor Defense](https://doi.org/10.48550/arXiv.2504.21730)|Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/NcepuQiaoTing/Cert-SSB)](https://github.com/NcepuQiaoTing/Cert-SSB)|
|63|[Backdooring Self-Supervised Contrastive Learning by Noisy Alignment](https://doi.org/10.48550/arXiv.2508.14015)|Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/jsrdcht/Noisy-Alignment)](https://github.com/jsrdcht/Noisy-Alignment)|
|64|[Claim-Guided Textual Backdoor Attack for Practical Applications](https://doi.org/10.18653/v1/2025.findings-naacl.64)|Minkyoo Song, Hanna Kim, Jaehan Kim, Youngjin Jin, Seungwon Shin|2025-01-01|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/PaperCGBA/CGBA)](https://github.com/PaperCGBA/CGBA)|
|65|[Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems](https://doi.org/10.48550/arXiv.2510.11246)|Pengyu Zhu, Lijun Li, Yaxing Lyu, Li Sun, Sen Su, Jing Shao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS)](https://github.com/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS)|
|66|[DUP: Detection-guided Unlearning for Backdoor Purification in Language Models](https://doi.org/10.48550/arXiv.2508.01647)|Man Hu, Yahui Ding, Yatao Yang, Liangyu Chen, Yanhao Jia, Shuai Zhao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/ManHu2025/DUP)](https://github.com/ManHu2025/DUP)|
|67|[Energy Backdoor Attack to Deep Neural Networks](https://doi.org/10.1109/icassp49660.2025.10888330)|Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier D√©forges, Kassem Kallas|2025-01-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/hbrachemi/energy_backdoor)](https://github.com/hbrachemi/energy_backdoor)|
|68|[Exploring Backdoor Vulnerabilities of Chat Models](https://aclanthology.org/2025.coling-main.62/)|Wenkai Yang, Yunzhuo Hao, Yankai Lin|2025-01-01|COLING|[![Star](https://img.shields.io/github/stars/hychaochao/Chat-Models-Backdoor-Attacking)](https://github.com/hychaochao/Chat-Models-Backdoor-Attacking)|
|69|[Double Landmines: Invisible Textual Backdoor Attacks based on   Dual-Trigger](https://doi.org/10.1186/s42400-025-00512-z)|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-23|Cybersecurity|[![Star](https://img.shields.io/github/stars/HoyaAm/Double-Landmines)](https://github.com/HoyaAm/Double-Landmines)|
|70|[Gracefully Filtering Backdoor Samples for Generative Large Language   Models without Retraining](https://aclanthology.org/2025.coling-main.220/)|Zongru Wu, Pengzhou Cheng, Lingyong Fang, Zhuosheng Zhang, Gongshen Liu|2024-12-03|COLING|[![Star](https://img.shields.io/github/stars/ZrW00/GraceFul)](https://github.com/ZrW00/GraceFul)|
|71|[BadMerging: Backdoor Attacks Against Model Merging](https://doi.org/10.48550/arXiv.2408.07362)|Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian|2024-12-02|OpenAlex|[![Star](https://img.shields.io/github/stars/jzhang538/BadMerging)](https://github.com/jzhang538/BadMerging)|
|72|[Fisher Information guided Purification against Backdoor Attacks](https://doi.org/10.48550/arXiv.2409.00863)|Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard|2024-12-02|OpenAlex|[![Star](https://img.shields.io/github/stars/nazmul-karim170/FIP-Fisher-Backdoor-Removal)](https://github.com/nazmul-karim170/FIP-Fisher-Backdoor-Removal)|
|73|[Backdoor Attacks against No-Reference Image Quality Assessment Models   via a Scalable Trigger](https://doi.org/10.48550/arXiv.2412.07277)|Yi Yu, Song Xia, Xun Lin, Wenhan Yang, Shijian Lu, Yap‚ÄêPeng Tan, Alex C. Kot|2024-12-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/yuyi-sd/BAIQA)](https://github.com/yuyi-sd/BAIQA)|
|74|[Invisible Textual Backdoor Attacks based on Dual-Trigger](http://arxiv.org/abs/2412.17531v3)|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-01|arXiv|[![Star](https://img.shields.io/github/stars/HoyaAm/Double-Landmines)](https://github.com/HoyaAm/Double-Landmines)|
|75|[Perturb and Recover: Fine-tuning for Effective Backdoor Removal from   CLIP](https://doi.org/10.48550/arXiv.2412.00727)|Naman Deep Singh, Francesco Croce, Matthias Hein|2024-12-01|arXiv|[![Star](https://img.shields.io/github/stars/nmndeep/PerturbAndRecover)](https://github.com/nmndeep/PerturbAndRecover)|
|76|[T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models](https://doi.org/10.1007/978-3-031-73013-9_7)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2024-11-26|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/Robin-WZQ/T2IShield)](https://github.com/Robin-WZQ/T2IShield)|
|77|[BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for   Backdoor Defense Evaluation](https://doi.org/10.48550/arXiv.2411.11006)|Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Pengzhou Cheng, Ping Yi, Yue Wu|2024-11-17|OpenAlex|[![Star](https://img.shields.io/github/stars/SJTUHaiyangYu/BackdoorMBTI)](https://github.com/SJTUHaiyangYu/BackdoorMBTI)|
|78|[Your Semantic-Independent Watermark is Fragile: A Semantic Perturbation   Attack against EaaS Watermark](http://arxiv.org/abs/2411.09359v2)|Zekun Fei, Biao Yi, Jianing Geng, Ruiqi He, Lihai Nie, Zheli Liu|2024-11-01|arXiv|[![Star](https://img.shields.io/github/stars/Zk4-ps/EaaS-Embedding-Watermark)](https://github.com/Zk4-ps/EaaS-Embedding-Watermark)|
|79|[Identify Backdoored Model in Federated Learning via Individual   Unlearning](https://doi.org/10.1109/WACV61041.2025.00773)|Jiahao Xu, Zikai Zhang, Rui Hu|2024-11-01|arXiv|[![Star](https://img.shields.io/github/stars/JiiahaoXU/MASA)](https://github.com/JiiahaoXU/MASA)|
|80|[UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening](https://doi.org/10.1007/978-3-031-73033-7_15)|Siyuan Cheng, Guangyu Shen, Kaiyuan Zhang, Guanhong Tao, Shengwei An, Hanxi Guo, Shiqing Ma, Xiangyu Zhang|2024-10-31|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/Megum1/UNIT)](https://github.com/Megum1/UNIT)|
|81|[Mitigating the Backdoor Effect for Multi-Task Model Merging via   Safety-Aware Subspace](https://openreview.net/forum?id=dqMqAaw7Sq)|Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu|2024-10-16|arXiv|[![Star](https://img.shields.io/github/stars/Yangjinluan/DAM)](https://github.com/Yangjinluan/DAM)|
|82|[Adversarially Guided Stateful Defense Against Backdoor Attacks in   Federated Deep Learning](https://doi.org/10.1109/ACSAC63791.2024.00070)|Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay K. Jha|2024-10-01|OpenAlex|[![Star](https://img.shields.io/github/stars/hassanalikhatim/AGSD)](https://github.com/hassanalikhatim/AGSD)|
|83|[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and   Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v4)|Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang|2024-10-01|arXiv|[![Star](https://img.shields.io/github/stars/agiresearch/ASB)](https://github.com/agiresearch/ASB)|
|84|[Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via   Exposed Models](https://doi.org/10.48550/arXiv.2410.19427)|Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang|2024-10-01|arXiv|[![Star](https://img.shields.io/github/stars/bboylyg/Expose-Before-You-Defend)](https://github.com/bboylyg/Expose-Before-You-Defend)|
|85|[Event Trojan: Asynchronous Event-Based Backdoor Attacks](https://doi.org/10.1007/978-3-031-72667-5_18)|Ruofei Wang, Qing Guo, Haoliang Li, Renjie Wan|2024-09-28|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/rfww/EventTrojan)](https://github.com/rfww/EventTrojan)|
|86|[Mask-Based Invisible Backdoor Attacks on Object Detection](https://doi.org/10.36227/techrxiv.171440796.64142276/v1)|Shin Jeong Jin|2024-09-27|2022 IEEE International Conference on Image Processing (ICIP)|[![Star](https://img.shields.io/github/stars/jeongjin0/invisible-backdoor-object-detection)](https://github.com/jeongjin0/invisible-backdoor-object-detection)|
|87|[Obliviate: Neutralizing Task-agnostic Backdoors within the   Parameter-efficient Fine-tuning Paradigm](https://doi.org/10.18653/v1/2025.findings-naacl.71)|Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin|2024-09-21|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/obliviateARR/Obliviate)](https://github.com/obliviateARR/Obliviate)|
|88|[TERD: A Unified Framework for Safeguarding Diffusion Models Against   Backdoors](https://openreview.net/forum?id=lpHjmPvxW1)|Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, Yisen Wang|2024-09-08|International Conference on Machine Learning 2024|[![Star](https://img.shields.io/github/stars/PKU-ML/TERD)](https://github.com/PKU-ML/TERD)|
|89|[NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack   Through White Gaussian Noise](https://doi.org/10.48550/arXiv.2409.02251)|Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi|2024-09-03|arXiv|[![Star](https://img.shields.io/github/stars/SiSL-URI/NoiseAttack)](https://github.com/SiSL-URI/NoiseAttack)|
|90|[Exploiting the Vulnerability of Large Language Models via Defense-Aware   Architectural Backdoor](https://doi.org/10.48550/arXiv.2409.01952)|Abdullah Arafat Miah, Yu Bi|2024-09-03|arXiv|[![Star](https://img.shields.io/github/stars/SiSL-URI/Arch_Backdoor_LLM)](https://github.com/SiSL-URI/Arch_Backdoor_LLM)|
|91|[Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual   Perturbations Against Backdoor Attacks](https://doi.org/10.48550/arXiv.2408.15721)|Oscar Chew, Po-Yi Lu, Jayden Lin, Hsuan-Tien Lin|2024-08-28|arXiv|[![Star](https://img.shields.io/github/stars/oscarchew/t2i-backdoor-defense)](https://github.com/oscarchew/t2i-backdoor-defense)|
|92|[VFLIP: A Backdoor Defense for Vertical Federated Learning via   Identification and Purification](https://doi.org/10.1007/978-3-031-70903-6_15)|Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek|2024-08-28|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/blingcho/VFLIP-esorics24)](https://github.com/blingcho/VFLIP-esorics24)|
|93|[MakeupAttack: Feature Space Black-box Backdoor Attack on Face   Recognition via Makeup Transfer](https://doi.org/10.48550/arXiv.2408.12312)|Ming Sun, Lihua Jing, Zixuan Zhu, Rui Wang|2024-08-22|Frontiers in artificial intelligence and applications|[![Star](https://img.shields.io/github/stars/AaronSun2000/MakeupAttack)](https://github.com/AaronSun2000/MakeupAttack)|
|94|[MEGen: Generative Backdoor into Large Language Models via Model Editing](https://doi.org/10.18653/v1/2025.findings-acl.584)|Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao, Yun Li, Qianren Wang|2024-08-20|Findings of the Association for Computational Linguistics: ACL 2022|[![Star](https://img.shields.io/github/stars/MonoQ-hub/MEGen)](https://github.com/MonoQ-hub/MEGen)|
|95|[BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses   on Large Language Models](https://ink.library.smu.edu.sg/sis_research/10422)|Li Yige, Huang, Hanxun, Zhao Yunhan, Ma, Xingjun, Sun Jun|2024-08-01|Singapore Management University Institutional Knowledge (InK) (Singapore Management University)|[![Star](https://img.shields.io/github/stars/bboylyg/BackdoorLLM)](https://github.com/bboylyg/BackdoorLLM)|
|96|[Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion   Models](https://doi.org/10.1109/ICME59968.2025.11210014)|Hao Jiang, Jin Xiao, Xiaoguang Hu, Chen Tianyou, Zhao Jiajia|2024-07-30|ICME|[![Star](https://img.shields.io/github/stars/shymuel/diff-cleanse)](https://github.com/shymuel/diff-cleanse)|
|97|[BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor   Learning](http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html)|Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen|2024-07-29|International Journal of Computer Vision|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/backdoorbench-a-comprehensive-benchmark-of/code)|
|98|[Flatness-aware Sequential Learning Generates Resilient Backdoors](https://doi.org/10.1007/978-3-031-73021-4_6)|Hoang N. Pham, The-Anh Ta, Anh Tran, Khoa D. Doan|2024-07-19|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/mail-research/SBL-resilient-backdoors)](https://github.com/mail-research/SBL-resilient-backdoors)|
|99|[Provable Robustness of (Graph) Neural Networks Against Data Poisoning   and Backdoor Attacks](https://openreview.net/forum?id=jIAPLDdGVx)|Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan G√ºnnemann|2024-07-15|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/saper0/qpcert)](https://github.com/saper0/qpcert)|
|100|[Distributed Backdoor Attacks on Federated Graph Learning and Certified   Defenses](https://doi.org/10.48550/arXiv.2407.08935)|Yuxin Yang, Qiang Li, Jinyuan Jia, Yuan Hong, Binghui Wang|2024-07-11|OpenAlex|[![Star](https://img.shields.io/github/stars/Yuxin104/Opt-GDBA)](https://github.com/Yuxin104/Opt-GDBA)|
|101|[Future Events as Backdoor Triggers: Investigating Temporal   Vulnerabilities in LLMs](https://doi.org/10.48550/arXiv.2407.04108)|Sara Price, Arjun Panickssery, Samuel R. Bowman, Asa Cooper Stickland|2024-07-04|arXiv|[![Star](https://img.shields.io/github/stars/sbp354/Future_triggered_backdoors)](https://github.com/sbp354/Future_triggered_backdoors)|
|102|[IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields](http://arxiv.org/abs/2407.11921v2)|Wenxiang Jiang, Hanwei Zhang, Shuo Zhao, Zhongwen Guo, Hao Wang|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/jiang-wenxiang/IPA-NeRF)](https://github.com/jiang-wenxiang/IPA-NeRF)|
|103|[Towards Clean-Label Backdoor Attacks in the Physical World](https://doi.org/10.48550/arXiv.2407.19203)|Thinh Dao, Cuong Phan Minh Le, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/21thinh/Clean-Label-Physical-Backdoor-Attacks)](https://github.com/21thinh/Clean-Label-Physical-Backdoor-Attacks)|
|104|[ShadowCode: Towards (Automatic) External Prompt Injection Attack against   Code LLMs](http://arxiv.org/abs/2407.09164v6)|Yuchen Yang, Yiming Li, Hongwei Yao, Bingrun Yang, Yiling He, Tianwei Zhang, Dacheng Tao, Zhan Qin|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/LianPing-cyber/ShadowCodeEPI)](https://github.com/LianPing-cyber/ShadowCodeEPI)|
|105|[Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks   in Federated Learning](https://doi.org/10.48550/arXiv.2407.03144)|Son Nguyen, Thinh Viet Nguyen, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/nguyenhongson1902/Venomancer)](https://github.com/nguyenhongson1902/Venomancer)|
|106|[Defending Against Repetitive-based Backdoor Attacks on Semi-supervised   Learning through Lens of Rate-Distortion-Perception Trade-off](https://doi.org/10.1109/WACV61041.2025.00630)|Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu, Chu-Song Chen|2024-07-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/chengyi-chris/UPure)](https://github.com/chengyi-chris/UPure)|
|107|[Clean-Label Physical Backdoor Attacks with Data Distillation](http://arxiv.org/abs/2407.19203v4)|Thinh Dao, Khoa D Doan, Kok-Seng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/thinh-dao/Clean-Label-Physical-Backdoor-Attacks)](https://github.com/thinh-dao/Clean-Label-Physical-Backdoor-Attacks)|
|108|[Backdoor Graph Condensation](https://doi.org/10.1109/ICDE65448.2025.00172)|Jiahao Wu, Ning Lu, Zeiyu Dai, Kun Wang, Wenqi Fan, Shengcai Liu, Qing Li, Ke Tang|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/JiahaoWuGit/BGC)](https://github.com/JiahaoWuGit/BGC)|
|109|[A Whole-Process Certifiably Robust Aggregation Method Against Backdoor   Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2407.00719)|Anqi Zhou, Yezheng Liu, Yidong Chai, Hongyi Zhu, Xinyue Ge, Yuanchun Jiang, Meng Wang|2024-06-30|arXiv|[![Star](https://img.shields.io/github/stars/brick-brick/WPCRAM)](https://github.com/brick-brick/WPCRAM)|
|110|[Lotus: Evasive and Resilient Backdoor Attacks through Sub-Partitioning](https://doi.org/10.1109/cvpr52733.2024.02342)|Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, ...|2024-06-16|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/Megum1/LOTUS)](https://github.com/Megum1/LOTUS)|
|111|[BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.530)|Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian|2024-06-05|OpenAlex|[![Star](https://img.shields.io/github/stars/DPamK/BadAgent)](https://github.com/DPamK/BadAgent)|
|112|[Invisible Backdoor Attacks on Diffusion Models](https://doi.org/10.48550/arXiv.2406.00816)|Sen Li, Junchi Ma, Minhao Cheng|2024-06-02|arXiv|[![Star](https://img.shields.io/github/stars/invisibleTriggerDiffusion/invisible_triggers_for_diffusion)](https://github.com/invisibleTriggerDiffusion/invisible_triggers_for_diffusion)|
|113|[Let the Noise Speak: Harnessing Noise for a Unified Defense Against   Adversarial and Backdoor Attacks](https://doi.org/10.1007/978-3-032-07884-1_19)|Md Hasan Shahriar, Ning Wang, Naren Ramakrishnan, Y. Thomas Hou, Wenjing Lou|2024-06-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/shahriar0651/NoiSec)](https://github.com/shahriar0651/NoiSec)|
|114|[BAN: Detecting Backdoors Activated by Adversarial Neuron Noise](http://papers.nips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html)|Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek|2024-05-30|NeurIPS|[![Star](https://img.shields.io/github/stars/xiaoyunxxy/ban)](https://github.com/xiaoyunxxy/ban)|
|115|[Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor](http://papers.nips.cc/paper_files/paper/2024/hash/9374af323abb65ce551168d44b09ad5f-Abstract-Conference.html)|Shaokui Wei, Hongyuan Zha, Baoyuan Wu|2024-05-25|NeurIPS|[![Star](https://img.shields.io/github/stars/shawkui/Proactive_Defensive_Backdoor)](https://github.com/shawkui/Proactive_Defensive_Backdoor)|
|116|[Towards Imperceptible Backdoor Attack in Self-supervised Learning](https://doi.org/10.48550/arXiv.2405.14672)|Hanrong Zhang, Zhenting Wang, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma|2024-05-23|arXiv|[![Star](https://img.shields.io/github/stars/Zhang-Henry/IMPERATIVE)](https://github.com/Zhang-Henry/IMPERATIVE)|
|117|[IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling   Consistency](https://openreview.net/forum?id=YCzbfs2few)|Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li|2024-05-15|ICML|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|118|[EmInspector: Combating Backdoor Attacks in Federated Self-Supervised   Learning Through Embedding Inspection](https://doi.org/10.48550/arXiv.2405.13080)|Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo|2024-05-01|arXiv|[![Star](https://img.shields.io/github/stars/ShuchiWu/EmInspector)](https://github.com/ShuchiWu/EmInspector)|
|119|[Not All Prompts Are Secure: A Switchable Backdoor Attack Against   Pre-trained Vision Transformers](https://doi.org/10.1109/CVPR52733.2024.02306)|Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/20000yshust/SWARM)](https://github.com/20000yshust/SWARM)|
|120|[Nearest is Not Dearest: Towards Practical Defense against   Quantization-conditioned Backdoor Attacks](https://doi.org/10.1109/CVPR52733.2024.02315)|Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/AntigoneRandy/QuantBackdoor_EFRAP)](https://github.com/AntigoneRandy/QuantBackdoor_EFRAP)|
|121|[Beyond Traditional Threats: A Persistent Backdoor Attack on Federated   Learning](https://doi.org/10.1609/aaai.v38i19.30131)|Tao Liu, Yuhang Zhang, Feng Zhu, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang|2024-04-26||[![Star](https://img.shields.io/github/stars/PhD-TaoLiu/FCBA)](https://github.com/PhD-TaoLiu/FCBA)|
|122|[Privacy Backdoors: Stealing Data with Corrupted Pretrained Models](https://openreview.net/forum?id=7yixJXmzb8)|Shanglun Feng, Florian Tram√®r|2024-03-30|ICML|[![Star](https://img.shields.io/github/stars/ShanglunFengatETHZ/PrivacyBackdoor)](https://github.com/ShanglunFengatETHZ/PrivacyBackdoor)|
|123|[Generating Potent Poisons and Backdoors from Scratch with Guided   Diffusion](https://doi.org/10.48550/arXiv.2403.16365)|Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellapp...|2024-03-24|arXiv|[![Star](https://img.shields.io/github/stars/hsouri/GDP)](https://github.com/hsouri/GDP)|
|124|[Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain](https://doi.org/10.1609/aaai.v38i19.30099)|Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/f-lk/IBAPC)](https://github.com/f-lk/IBAPC)|
|125|[Progressive Poisoned Data Isolation for Training-Time Backdoor Defense](https://doi.org/10.1609/aaai.v38i10.29023)|Yiming Chen, Haiwei Wu, Jiantao Zhou|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/RorschachChen/PIPD)](https://github.com/RorschachChen/PIPD.git)|
|126|[COMBAT: Alternated Training for Near-Perfect Clean-Label Backdoor Attacks](https://openreview.net/pdf/c182fdd518fe8ec0aeafeb8d1b2b55bb8e46a463.pdf)|Tran Ngoc Huynh, Dang Minh Nguyen, Tung Pham, Anh Tuan Tran|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/VinAIResearch/COMBAT)](https://github.com/VinAIResearch/COMBAT)|
|127|[BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning](https://doi.org/10.1609/aaai.v38i10.29052)|Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/7777777cc/code)](https://github.com/7777777cc/code)|
|128|[An Embarrassingly Simple Defense Against Backdoor Attacks On SSL](https://doi.org/10.48550/arXiv.2403.15918)|Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade|2024-03-23|arXiv|[![Star](https://img.shields.io/github/stars/Aryan-Satpathy/Backdoor)](https://github.com/Aryan-Satpathy/Backdoor)|
|129|[PoisonPrompt: Backdoor Attack on Prompt-Based Large Language Models](https://doi.org/10.1109/icassp48485.2024.10446267)|Hongwei Yao, Jian Lou, Zhan Qin|2024-03-18|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/grasses/PoisonPrompt)](https://github.com/grasses/PoisonPrompt)|
|130|[Invisible Black-Box Backdoor Attack against Deep Cross-Modal Hashing Retrieval](https://doi.org/10.1145/3650205)|Tianshi Wang, Fengling Li, Lei Zhu, Jingjing Li, Zheng Zhang, Heng Tao Shen|2024-03-02|ACM transactions on office information systems|[![Star](https://img.shields.io/github/stars/tswang0116/IB3A)](https://github.com/tswang0116/IB3A)|
|131|[Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized   Scaled Prediction Consistency](https://openreview.net/forum?id=1OfAO2mes1)|Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu|2024-03-01|ICLR|[![Star](https://img.shields.io/github/stars/OPTML-Group/BackdoorMSPC)](https://github.com/OPTML-Group/BackdoorMSPC)|
|132|[BapFL: You can Backdoor Personalized Federated Learning](https://doi.org/10.1145/3649316)|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2024-02-23|ACM Transactions on Knowledge Discovery from Data|[![Star](https://img.shields.io/github/stars/BapFL/code)](https://github.com/BapFL/code)|
|133|[Acquiring Clean Language Models from Backdoor Poisoned Datasets by   Downscaling Frequency Space](https://openreview.net/pdf/9eb71f0c75e3630c53671cf8b0175e95463726f1.pdf)|Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu|2024-02-19|OpenReview|[![Star](https://img.shields.io/github/stars/ZrW00/MuScleLoRA)](https://github.com/ZrW00/MuScleLoRA)|
|134|[Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery   Detection](https://openreview.net/forum?id=8iTpB4RNvP)|Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao|2024-02-18|ICLR|[![Star](https://img.shields.io/github/stars/JWLiang007/PFF)](https://github.com/JWLiang007/PFF)|
|135|[Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based   Agents](http://papers.nips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html)|Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun|2024-02-17|NeurIPS|[![Star](https://img.shields.io/github/stars/lancopku/agent-backdoor-attacks)](https://github.com/lancopku/agent-backdoor-attacks)|
|136|[OrderBkd: Textual backdoor attack through repositioning](https://doi.org/10.1109/ispras60948.2023.10508175)|Irina Alekseevskaia, Konstantin Arkhipenko|2024-02-12|OpenAlex|[![Star](https://img.shields.io/github/stars/alekseevskaia/OrderBkd)](https://github.com/alekseevskaia/OrderBkd)|
|137|[Backdoor Attacks on Dense Retrieval via Public and Unintentional   Triggers](http://arxiv.org/abs/2402.13532v3)|Quanyu Long, Yue Deng, LeiLei Gan, Wenya Wang, Sinno Jialin Pan|2024-02-01|arXiv|[![Star](https://img.shields.io/github/stars/ruyue0001/Backdoor_DPR)](https://github.com/ruyue0001/Backdoor_DPR)|
|138|[SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via   Syntactic Transfer](https://doi.org/10.18653/v1/2025.findings-naacl.196)|Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Zhuosheng Zhang, Gongshen Liu|2024-02-01|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/Zhou-CyberSecurity-AI/SynGhost)](https://github.com/Zhou-CyberSecurity-AI/SynGhost)|
|139|[TransTroj: Transferable Backdoor Attacks to Pre-trained Models via   Embedding Indistinguishability](https://doi.org/10.48550/arXiv.2401.15883)|Hao Wang, Tao Xiang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang|2024-01-28|arXiv|[![Star](https://img.shields.io/github/stars/haowang-cqu/TransTroj)](https://github.com/haowang-cqu/TransTroj)|
|140|[A Closer Look at Robustness of Vision Transformers to Backdoor Attacks](https://doi.org/10.1109/wacv57701.2024.00383)|Akshayvarun Subramanya, Soroush Abbasi Koohpayegani, Aniruddha Saha, Ajinkya Tejankar, Hamed Pirsiavash|2024-01-03|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/UCDvision/backdoor_transformer)](https://github.com/UCDvision/backdoor_transformer.git)|
|141|[How to Craft Backdoors with Unlabeled Data Alone?](https://doi.org/10.48550/arXiv.2404.06694)|Yifei Wang, Wenhan Ma, Stefanie Jegelka, Yisen Wang|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/PKU-ML/nlb)](https://github.com/PKU-ML/nlb)|
|142|[Toward Stealthy Backdoor Attacks Against Speech Recognition via Elements of Sound](https://doi.org/10.1109/tifs.2024.3404885)|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2024-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/HanboCai/BadSpeech_SoE)](https://github.com/HanboCai/BadSpeech_SoE)|
|143|[Shortcuts Everywhere and Nowhere: Exploring Multi-Trigger Backdoor   Attacks](http://arxiv.org/abs/2401.15295v3)|Yige Li, Jiabo He, Hanxun Huang, Jun Sun, Xingjun Ma, Yu-Gang Jiang|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/bboylyg/Multi-Trigger-Backdoor-Attacks)](https://github.com/bboylyg/Multi-Trigger-Backdoor-Attacks)|
|144|[PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection](https://openaccess.thecvf.com/content/CVPR2025/html/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.html)|Wei Li, Pin-Yu Chen, Sijia Liu, Ren Wang|2024-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/WL-619/PSBD)](https://github.com/WL-619/PSBD)|
|145|[PBP: Post-training Backdoor Purification for Malware Classifiers](https://www.ndss-symposium.org/ndss-paper/pbp-post-training-backdoor-purification-for-malware-classifiers/)|Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach|2024-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/judydnguyen/pbp-backdoor-purification-official)](https://github.com/judydnguyen/pbp-backdoor-purification-official)|
|146|[Model Supply Chain Poisoning: Backdooring Pre-trained Models via   Embedding Indistinguishability](https://doi.org/10.1145/3696410.3714624)|Hao Wang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang, Tao Xiang|2024-01-01|WWW|[![Star](https://img.shields.io/github/stars/haowang-cqu/TransTroj)](https://github.com/haowang-cqu/TransTroj)|
|147|[How to Backdoor Consistency Models?](https://doi.org/10.1007/978-981-96-8295-9_23)|Chengen Wang, Murat Kantarcioglu|2024-01-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/chengenw/backdoorCM)](https://github.com/chengenw/backdoorCM)|
|148|[Defending Against Backdoor Attacks by Quarantine Training](https://doi.org/10.1109/access.2024.3354385)|Chengxu Yu, Yulai Zhang|2024-01-01|IEEE Access|[![Star](https://img.shields.io/github/stars/Chengx-Yu/Quarantine-Training)](https://github.com/Chengx-Yu/Quarantine-Training)|
|149|[BadCM: Invisible Backdoor Attack Against Cross-Modal Learning](https://doi.org/10.48550/arXiv.2410.02182)|Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie|2024-01-01||[![Star](https://img.shields.io/github/stars/xandery-geek/BadCM)](https://github.com/xandery-geek/BadCM)|
|150|[Backdoor Contrastive Learning via Bi-level Trigger Optimization](https://openreview.net/forum?id=oxjeePpgSP)|Weiyu Sun, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, Jinghui Chen, Lu Lin|2024-01-01|ICLR|[![Star](https://img.shields.io/github/stars/SWY666/SSL-backdoor-BLTO)](https://github.com/SWY666/SSL-backdoor-BLTO)|
|151|[BackTime: Backdoor Attacks on Multivariate Time Series Forecasting](http://papers.nips.cc/paper_files/paper/2024/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html)|Xiaola Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong|2024-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/xiaolin-cs/BackTime)](https://github.com/xiaolin-cs/BackTime)|
|152|[Adversarial Feature Map Pruning for Backdoor](https://openreview.net/forum?id=IOEEDkla96)|Dong Huang, Qingwen Bu|2024-01-01|ICLR|[![Star](https://img.shields.io/github/stars/retsuh-bqw/FMP)](https://github.com/retsuh-bqw/FMP)|
|153|[OCGEC: One-class Graph Embedding Classification for DNN Backdoor   Detection](https://doi.org/10.1109/ijcnn60899.2024.10650468)|Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi|2023-12-01|2022 International Joint Conference on Neural Networks (IJCNN)|[![Star](https://img.shields.io/github/stars/jhy549/OCGEC)](https://github.com/jhy549/OCGEC)|
|154|[UltraClean: A Simple Framework to Train Robust Neural Networks against   Backdoor Attacks](https://doi.org/10.48550/arXiv.2312.10657)|Bingyin Zhao, Yingjie Lao|2023-12-01|arXiv|[![Star](https://img.shields.io/github/stars/bxz9200/UltraClean)](https://github.com/bxz9200/UltraClean)|
|155|[A Practical Clean-Label Backdoor Attack with Limited Information in Vertical Federated Learning](https://doi.org/10.1109/icdm58522.2023.00013)|Peng Chen, Jirui Yang, Junxiong Lin, Zhihui Lu, Qiang Duan, Hongfeng Chai|2023-12-01|2021 IEEE International Conference on Data Mining (ICDM)|[![Star](https://img.shields.io/github/stars/13thDayOLunarMay/TECB-attack)](https://github.com/13thDayOLunarMay/TECB-attack)|
|156|[Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking](https://doi.org/10.48550/arXiv.2312.07955)|Shengsheng Qian, Dizhan Xue, Yifei Wang, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu|2023-12-01|arXiv|[![Star](https://img.shields.io/github/stars/LivXue/PoisonCAM)](https://github.com/LivXue/PoisonCAM)|
|157|[Activation Gradient based Poisoned Sample Detection Against Backdoor   Attacks](https://openreview.net/forum?id=VNMJfBBUd5)|Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu|2023-12-01|ICLR|[![Star](https://img.shields.io/github/stars/SCLBD/bdzoo2)](https://github.com/SCLBD/bdzoo2)|
|158|[TextGuard: Provable Defense against Backdoor Attacks on Text   Classification](https://www.ndss-symposium.org/ndss-paper/textguard-provable-defense-against-backdoor-attacks-on-text-classification/)|Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song|2023-11-01|OpenAlex|[![Star](https://img.shields.io/github/stars/AI-secure/TextGuard)](https://github.com/AI-secure/TextGuard)|
|159|[ACQ: Few-shot Backdoor Defense via Activation Clipping and Quantizing](https://doi.org/10.1145/3581783.3612410)|Yulin Jin, Xiaoyu Zhang, Jian Lou, Xiaofeng Chen|2023-10-26|ACM Multimedia|[![Star](https://img.shields.io/github/stars/Backdoor-defense/ACQ)](https://github.com/Backdoor-defense/ACQ)|
|160|[Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks](https://doi.org/10.1145/3583780.3614784)|Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu|2023-10-21|OpenAlex|[![Star](https://img.shields.io/github/stars/GuanZihan/Deep-Backdoor-Attack)](https://github.com/GuanZihan/Deep-Backdoor-Attack)|
|161|[An Embarrassingly Simple Backdoor Attack on Self-supervised Learning](https://doi.org/10.1109/iccv51070.2023.00403)|Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/meet-cjli/CTRL)](https://github.com/meet-cjli/CTRL)|
|162|[Computation and Data Efficient Backdoor Attacks](https://doi.org/10.1109/iccv51070.2023.00443)|Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/WU-YU-TONG/computational_efficient_backdoor)](https://github.com/WU-YU-TONG/computational_efficient_backdoor)|
|163|[FLTracer: Accurate Poisoning Attack Provenance in Federated Learning](http://arxiv.org/abs/2310.13424v1)|Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren|2023-10-01|arXiv|[![Star](https://img.shields.io/github/stars/Eyr3/FLTracer)](https://github.com/Eyr3/FLTracer)|
|164|[XGBD: Explanation-Guided Graph Backdoor Detection](https://doi.org/10.48550/arXiv.2308.04406)|Zihan Guan, Mengnan Du, Ninghao Liu|2023-09-28|Frontiers in artificial intelligence and applications|[![Star](https://img.shields.io/github/stars/GuanZihan/GNN_backdoor_detection)](https://github.com/GuanZihan/GNN_backdoor_detection)|
|165|[Resisting Backdoor Attacks in Federated Learning via Bidirectional   Elections and Individual Perspective](https://doi.org/10.48550/arXiv.2309.16456)|Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng|2023-09-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/zhenqincn/Snowball)](https://github.com/zhenqincn/Snowball)|
|166|[TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal   Backdoored Models](https://doi.org/10.1109/iccv51070.2023.00022)|Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha|2023-08-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/SRI-CSL/TIJO)](https://github.com/SRI-CSL/TIJO)|
|167|[Towards Stealthy Backdoor Attacks against Speech Recognition via   Elements of Sound](https://doi.org/10.48550/arXiv.2307.08208)|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2023-07-01|arXiv|[![Star](https://img.shields.io/github/stars/HanboCai/BadSpeech_SoE)](https://github.com/HanboCai/BadSpeech_SoE)|
|168|[Detecting Backdoors in Pre-trained Encoders](https://doi.org/10.1109/cvpr52729.2023.01569)|Shiwei Feng, Guanhong Tao, Siyuan Cheng, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/GiantSeaweed/DECREE)](https://github.com/GiantSeaweed/DECREE)|
|169|[VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion   Models](http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html)|Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho|2023-06-01|NeurIPS|[![Star](https://img.shields.io/github/stars/IBM/villandiffusion)](https://github.com/IBM/villandiffusion)|
|170|[Single Image Backdoor Inversion via Robust Smoothed Classifiers](https://doi.org/10.1109/cvpr52729.2023.00784)|Mingjie Sun, J. Zico Kolter|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/locuslab/smoothinv)](https://github.com/locuslab/smoothinv)|
|171|[Efficient Backdoor Attacks for Deep Neural Networks in Real-world   Scenarios](https://openreview.net/forum?id=vRyp2dhEQp)|Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li|2023-06-01|arXiv|[![Star](https://img.shields.io/github/stars/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios)](https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios)|
|172|[DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via   Restricted Adversarial Distillation](https://doi.org/10.48550/arXiv.2306.08009)|Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao|2023-06-01|OpenAlex|[![Star](https://img.shields.io/github/stars/yanzhicong/DHBE)](https://github.com/yanzhicong/DHBE)|
|173|[Backdoor Cleansing with Unlabeled Data](https://openreview.nethttps://arxiv.org/pdf/2211.12044)|Lu Pang, Tong Sun, Haibin Ling, Chao Chen|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/luluppang/BCU)](https://github.com/luluppang/BCU)|
|174|[Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated   Graph Neural Network](https://doi.org/10.1007/978-3-032-05981-9_22)|Fan Liu, Siqi Lai, Yansong Ning, Hao Liu|2023-06-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/usail-hkust/BkdFedGCN)](https://github.com/usail-hkust/BkdFedGCN)|
|175|[Backdoor Defense via Deconfounded Representation Learning](https://doi.org/10.1109/cvpr52729.2023.01177)|Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/zaixizhang/CBD)](https://github.com/zaixizhang/CBD)|
|176|[An Empirical Study of Backdoor Attacks on Masked Auto Encoders](https://doi.org/10.1109/icassp49357.2023.10095201)|Shuli Zhuang, Pengfei Xia, Bin Li|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/zhuangshuli/MAE-Backdoor)](https://github.com/zhuangshuli/MAE-Backdoor)|
|177|[Going in Style: Audio Backdoors Through Stylistic Transformations](https://doi.org/10.1109/icassp49357.2023.10096332)|Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/skoffas/going-in-style)](https://github.com/skoffas/going-in-style)|
|178|[Text-to-Image Diffusion Models can be Easily Backdoored through   Multimodal Data Poisoning](https://doi.org/10.48550/arXiv.2305.04175)|Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su|2023-05-01|ACM Multimedia|[![Star](https://img.shields.io/github/stars/sf-zhai/BadT2I)](https://github.com/sf-zhai/BadT2I)|
|179|[Training-free Lexical Backdoor Attacks on Language Models](https://doi.org/10.48550/arXiv.2302.04116)|Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen|2023-04-26|Proceedings of the ACM Web Conference 2022|[![Star](https://img.shields.io/github/stars/Jinxhy/TFLexAttack)](https://github.com/Jinxhy/TFLexAttack)|
|180|[Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware   Minimization](https://doi.org/10.1109/iccv51070.2023.00412)|Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu|2023-04-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/SCLBD/BackdoorBench)](https://github.com/SCLBD/BackdoorBench)|
|181|[Defending Against Patch-based Backdoor Attacks on Self-Supervised   Learning](https://doi.org/10.1109/cvpr52729.2023.01178)|Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan|2023-04-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/UCDvision/PatchSearch)](https://github.com/UCDvision/PatchSearch)|
|182|[Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection](https://doi.org/10.1109/tcss.2023.3260833)|Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen|2023-03-30|IEEE Transactions on Computational Social Systems|[![Star](https://img.shields.io/github/stars/Seaocn/Link-Backdoor)](https://github.com/Seaocn/Link-Backdoor)|
|183|[AdaptGuard: Defending Against Universal Attacks for Model Adaptation](http://arxiv.org/abs/2303.10594v2)|Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan|2023-03-01|arXiv|[![Star](https://img.shields.io/github/stars/TomSheng21/AdaptGuard)](https://github.com/TomSheng21/AdaptGuard)|
|184|[Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based   Artificial Bias](https://doi.org/10.1109/tcsvt.2025.3548657)|Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu|2023-03-01|IEEE Transactions on Circuits and Systems for Video Technology|[![Star](https://img.shields.io/github/stars/KirinNg/DBA)](https://github.com/KirinNg/DBA)|
|185|[CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive   Learning](https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf)|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023-03-01|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|
|186|[Detecting Backdoors During the Inference Stage Based on Corruption   Robustness Consistency](https://doi.org/10.1109/cvpr52729.2023.01570)|Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao|2023-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/CGCL-codes/TeCo)](https://github.com/CGCL-codes/TeCo)|
|187|[Mask and Restore: Blind Backdoor Defense at Test Time with Masked   Autoencoder](https://doi.org/10.48550/arXiv.2303.15564)|Tao Sun, Lu Pang, Weimin Lyu, Chao Chen, Haibin Ling|2023-03-01|arXiv|[![Star](https://img.shields.io/github/stars/tsun/BDMAE)](https://github.com/tsun/BDMAE)|
|188|[Revisiting Personalized Federated Learning: Robustness Against Backdoor   Attacks](https://openreview.nethttps://arxiv.org/pdf/2302.01677.pdf)|Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng|2023-02-01|Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining|[![Star](https://img.shields.io/github/stars/alibaba/FederatedScope)](https://github.com/alibaba/FederatedScope)|
|189|[TrojText: Test-time Invisible Textual Trojan Insertion](https://openreview.net/pdf/090c1fa0cc728fa6eb032fe3c74b8b5125be7e94.pdf)|Qian Lou, Yepeng Liu, Bo Feng|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/trojtext-test-time-invisible-textual-trojan/code)|
|190|[SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via   Analyzing Scaled Prediction Consistency](https://openreview.net/pdf/341ae2d07a7459242b24bb6e6ff7e2aec7a756e1.pdf)|Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu|2023-02-01|ICLR 2023 poster|[![Star](https://img.shields.io/github/stars/JunfengGo/SCALE-UP)](https://github.com/JunfengGo/SCALE-UP)|
|191|[Towards Robust Model Watermark via Reducing Parametric Vulnerability](https://openreview.net/pdf/c3ea0d03202ba1e2fbf2a003a936364bb447ce98.pdf)|Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia|2023-02-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/towards-robust-model-watermark-via-reducing/code)|
|192|[Backdoor Learning for NLP: Recent Advances, Challenges, and Future   Research Directions](https://doi.org/10.48550/arXiv.2302.06801)|Marwan Omar|2023-02-01|arXiv|[![Star](https://img.shields.io/github/stars/marwanomar1/Backdoor-Learning-for-NLP)](https://github.com/marwanomar1/Backdoor-Learning-for-NLP)|
|193|[ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep   Learning Paradigms](https://www.usenix.org/conference/usenixsecurity23/presentation/pan)|Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia|2023-02-01|USENIX Security Symposium|[![Star](https://img.shields.io/github/stars/ruoxi-jia-group/ASSET)](https://github.com/ruoxi-jia-group/ASSET)|
|194|[Backdoor Attacks on Time Series: A Generative Approach](https://openreview.net/pdf/b15b1e53dab0744f34198d60d727ddab895c8074.pdf)|Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey|2023-02-01|SaTML 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/backdoor-attacks-on-time-series-a-generative/code)|
|195|[Learning to Backdoor Federated Learning](https://openreview.net/pdf/b3222725885adf97fe0f200feabe9bbd3df94344.pdf)|Henger Li, Wu Chen, Senchun Zhu, Zizhan Zheng|2023-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learning-to-backdoor-federated-learning/code)|
|196|[You Can Backdoor Personalized Federated Learning](https://doi.org/10.48550/arXiv.2307.15971)|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2023-01-01|ACM Trans. Knowl. Discov. Data 2024|[![Star](https://img.shields.io/github/stars/BapFL/code)](https://github.com/BapFL/code)|
|197|[Universal Backdoor Attacks](https://openreview.net/forum?id=3QkzYBSWqL)|Benjamin Schneider, Nils Lukas, Florian Kerschbaum|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Ben-Schneider-code/Universal-Backdoor-Attacks)](https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks)|
|198|[UNICORN: A Unified Backdoor Trigger Inversion Framework](https://openreview.net/pdf/edd35173abda536a0bd486d49c34c8ce04e56652.pdf)|Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma|2023-01-01|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unicorn-a-unified-backdoor-trigger-inversion/code)|
|199|[Towards Stable Backdoor Purification through Feature Shift Tuning](http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html)|Rui Min, Zeyu Qin, Li Shen, Minhao Cheng|2023-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/AISafety-HKUST/stable_backdoor_purification)](https://github.com/AISafety-HKUST/stable_backdoor_purification)|
|200|[The &quot;Beatrix&quot; Resurrections: Robust Backdoor Detection via Gram Matrices](https://www.ndss-symposium.org/ndss-paper/the-beatrix-resurrections-robust-backdoor-detection-via-gram-matrices/)|Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang|2023-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/wanlunsec/Beatrix)](https://github.com/wanlunsec/Beatrix)|
|201|[RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks](https://doi.org/10.48550/arXiv.2302.09420)|Marwan Omar|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/marwanomar1/Backdoor-Learning-for-NLP)](https://github.com/marwanomar1/Backdoor-Learning-for-NLP)|
|202|[Removing Backdoors in Pre-trained Models by Regularized Continual Pre-training](https://openreview.net/pdf/b90599e4935794e4f111f07737fb0e5a485048f3.pdf)|Biru Zhu, Ganqu Cui, Yangyi Chen, Yujia Qin, Lifan Yuan, Chong Fu, Yangdong Deng, Zhiyuan Liu, Maosong Sun, Ming Gu|2023-01-01|Transactions of the Association for Computational Linguistics|[![Star](https://img.shields.io/github/stars/thunlp/RECIPE)](https://github.com/thunlp/RECIPE)|
|203|[Reconstructive Neuron Pruning for Backdoor Defense](https://proceedings.mlr.press/v202/li23v.html)|Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang|2023-01-01|ICML|[![Star](https://img.shields.io/github/stars/bboylyg/RNP)](https://github.com/bboylyg/RNP)|
|204|[NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models](https://doi.org/10.18653/v1/2023.acl-long.867)|Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma|2023-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/RU-System-Software-and-Security/Notable)](https://github.com/RU-System-Software-and-Security/Notable)|
|205|[SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning](https://openreview.net/pdf/512a5c7a02310e8ac2b28531e9e0c6518ad1c4e6.pdf)|Harsh Chaudhari, Matthew Jagielski, Alina Oprea|2023-01-01|SaTML 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.09986/code)|
|206|[From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models](https://doi.org/10.48550/arXiv.2311.02373)|Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/BiBadDiff)](https://github.com/OPTML-Group/BiBadDiff)|
|207|[Distilling Cognitive Backdoor Patterns within an Image](https://openreview.net/pdf/9582391717db932771feaf1c877a1ff5a58478f5.pdf)|Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey|2023-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/distilling-cognitive-backdoor-patterns-within/code)|
|208|[Black-box Backdoor Defense via Zero-shot Image Purification](http://papers.nips.cc/paper_files/paper/2023/hash/b36554b97da741b1c48c9de05c73993e-Abstract-Conference.html)|Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu|2023-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/sycny/ZIP)](https://github.com/sycny/ZIP)|
|209|[Beating Backdoor Attack at Its Own Game](https://doi.org/10.1109/ICCV51070.2023.00426)|Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue|2023-01-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/damianliumin/non-adversarial_backdoor)](https://github.com/damianliumin/non-adversarial_backdoor)|
|210|[BackdoorBox: A Python Toolbox for Backdoor Learning](https://openreview.net/pdf/81b89920b0128744bafa5c1943ac1ed8b0a871c7.pdf)|Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia|2023-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/backdoorbox-a-python-toolbox-for-backdoor/code)|
|211|[Backdoor Defense via Adaptively Splitting Poisoned Dataset](https://doi.org/10.1109/CVPR52729.2023.00390)|Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/KuofengGao/ASD)](https://github.com/KuofengGao/ASD)|
|212|[Backdoor Attacks for Remote Sensing Data With Wavelet Transform](https://doi.org/10.1109/tgrs.2023.3289307)|Nikolaus Dr√§ger, Yonghao Xu, Pedram Ghamisi|2023-01-01|IEEE Trans. Geos. Remote Sens., vol. 61, pp. 1-15, 2023|[![Star](https://img.shields.io/github/stars/ndraeger/waba)](https://github.com/ndraeger/waba)|
|213|[Backdoor Attack with Sparse and Invisible Trigger](https://doi.org/10.48550/arXiv.2306.06209)|Yinghua Gao, Yiming Li, Xueluan Gong, Zhifeng Li, Shu-Tao Xia, Qian Wang|2023-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/YinghuaGao/SIBA)](https://github.com/YinghuaGao/SIBA)|
|214|[Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment](https://doi.org/10.48550/arXiv.2311.09433)|Haoran Wang, Kai Shu|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/wang2226/Backdoor-Activation-Attack)](https://github.com/wang2226/Backdoor-Activation-Attack)|
|215|[BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models](https://doi.org/10.1109/tifs.2024.3386058)|J Kerekes Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian|2023-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/JJ-Vice/BAGM)](https://github.com/JJ-Vice/BAGM)|
|216|[FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks](https://doi.org/10.48550/arXiv.2307.11565)|Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/retsuh-bqw/FMP)](https://github.com/retsuh-bqw/FMP)|
|217|[Rethinking Backdoor Data Poisoning Attacks in the Context of   Semi-Supervised Learning](https://openreview.net/pdf/1e8864ea33570efedf181847e8e700fc3a7e8855.pdf)|Marissa Catherine Connor, Vincent Emanuele|2022-12-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/rethinking-backdoor-data-poisoning-attacks-in/code)|
|218|[Rickrolling the Artist: Injecting Backdoors into Text Encoders for   Text-to-Image Synthesis](https://doi.org/10.1109/iccv51070.2023.00423)|Lukas Struppek, Dominik Hintersdorf, Kristian Kersting|2022-11-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/LukasStruppek/Rickrolling-the-Artist)](https://github.com/LukasStruppek/Rickrolling-the-Artist)|
|219|[CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive   Learning](https://openreview.net/pdf/a71769013eb8042087131d5a81891020c7af2964.pdf)|Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong|2022-11-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/corruptencoder-data-poisoning-based-backdoor/code)|
|220|[BagFlip: A Certified Defense Against Data Poisoning](https://openreview.net/pdf/960044f35c0a2651737dc6ac8644ffd315d6a2dc.pdf)|Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/bagflip-a-certified-defense-against-data/code)|
|221|[Rethinking the Reverse-engineering of Trojan Triggers](https://openreview.net/pdf/e8ad6cc8620c4cec22babbe51c8f36d680dcd00c.pdf)|Zhenting Wang, Kai Mei, Hailun Ding, Juan Zhai, Shiqing Ma|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/rethinking-the-reverse-engineering-of-trojan/code)|
|222|[Towards Out-of-Distribution Sequential Event Prediction: A Causal Treatment](https://openreview.net/pdf/b5224a60869a26365b6e70239acbac055a762b08.pdf)|Chenxiao Yang, Qitian Wu, Qingsong Wen, Zhiqiang Zhou, Liang Sun, Junchi Yan|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/towards-out-of-distribution-sequential-event/code)|
|223|[Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems](https://openreview.nethttps://dl.acm.org/doi/abs/10.1145/3503161.3548261)|Qiang Liu, Tongqing Zhou, Zhiping Cai, Yonghao Tang|2022-10-10|Proceedings of the 30th ACM International Conference on Multimedia|[![Star](https://img.shields.io/github/stars/lqsunshine/DABA)](https://github.com/lqsunshine/DABA)|
|224|[Expose Backdoors on the Way: A Feature-Based Efficient Defense against   Textual Backdoor Attacks](https://doi.org/10.18653/v1/2022.findings-emnlp.47)|Sishuo Chen, Wenkai Yang, Zhiyuan Zhang, Xiaohan Bi, Xu Sun|2022-10-01|OpenAlex|[![Star](https://img.shields.io/github/stars/lancopku/DAN)](https://github.com/lancopku/DAN)|
|225|[FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated   Learning](https://openreview.net/pdf/6731b5784520aedd43f4da6cb01e5587b66819be.pdf)|Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, ...|2022-10-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/flip-a-provable-defense-framework-for/code)|
|226|[Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks   via Motifs](https://doi.org/10.1109/tcss.2023.3267094)|Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang|2022-10-01|IEEE Transactions on Computational Social Systems|[![Star](https://img.shields.io/github/stars/Seaocn/Motif-Backdoor)](https://github.com/Seaocn/Motif-Backdoor)|
|227|[Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor   Attacks in Federated Learning](https://openreview.net/pdf/f0d55f776bc33c4bd42632e2a4a381cc8a49356b.pdf)|Yuxin Wen, Jonas Geiping, Liam H Fowl, Hossein Souri, Rama Chellappa, Micah Goldblum, Tom Goldstein|2022-10-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/thinking-two-moves-ahead-anticipating-other/code)|
|228|[Trap and Replace: Defending Backdoor Attacks by Trapping Them into an   Easy-to-Replace Subnetwork](http://papers.nips.cc/paper_files/paper/2022/hash/ea06e6e9e80f1c3d382317fff67041ac-Abstract-Conference.html)|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|2022-10-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/trap-and-replace-defending-backdoor-attacks/code)|
|229|[Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset   Copyright Protection](http://papers.nips.cc/paper_files/paper/2022/hash/55bfedfd31489e5ae83c9ce8eec7b0e1-Abstract-Conference.html)|Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li|2022-10-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/untargeted-backdoor-watermark-towards/code)|
|230|[TransCAB: Transferable Clean-Annotation Backdoor to Object Detection   with Natural Trigger in Real-World](https://doi.org/10.1109/SRDS60354.2023.00018)|Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, ‚Ä™Surya Nepal‚Ä¨, Derek Abbott|2022-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/inconstance/T-shirt-natural-backdoor-dataset)](https://github.com/inconstance/T-shirt-natural-backdoor-dataset)|
|231|[Deep Fidelity in DNN Watermarking: A Study of Backdoor Watermarking for   Classification Models](https://doi.org/10.1016/j.patcog.2023.109844)|Guang Hua, Andrew Beng Jin Teoh|2022-08-01|Pattern Recognition, Vol. 144, Dec. 2023|[![Star](https://img.shields.io/github/stars/ghua-ac/dnn_watermark)](https://github.com/ghua-ac/dnn_watermark)|
|232|[Friendly Noise against Adversarial Noise: A Powerful Defense against   Data Poisoning Attacks](https://openreview.net/pdf/d929e1c412e3fecf6a4fb8991f306a09330510c6.pdf)|Tian Yu Liu, Yu Yang, Baharan Mirzasoleiman|2022-08-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/friendly-noise-against-adversarial-noise-a/code)|
|233|[RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact   DNN](https://doi.org/10.1007/978-3-031-19772-7_41)|Huy P. Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan|2022-08-01|European Conference on Computer Vision (ECCV 2022)|[![Star](https://img.shields.io/github/stars/huyvnphan/ECCV2022-RIBAC)](https://github.com/huyvnphan/ECCV2022-RIBAC)|
|234|[Data-Efficient Backdoor Attacks](https://openreview.nethttps://www.ijcai.org/proceedings/2022/0554.pdf)|Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li|2022-07-01|Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/xpf/Data-Efficient-Backdoor-Attacks)](https://github.com/xpf/Data-Efficient-Backdoor-Attacks)|
|235|[A Unified Evaluation of Textual Backdoor Learning: Frameworks and   Benchmarks](http://papers.nips.cc/paper_files/paper/2022/hash/2052b3e0617ecb2ce9474a6feaf422b3-Abstract-Datasets_and_Benchmarks.html)|Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun|2022-06-01|NeurIPS 2022 Datasets and Benchmarks |[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/a-unified-evaluation-of-textual-backdoor/code)|
|236|[Backdoor Attacks on Self-Supervised Learning](https://doi.org/10.1109/cvpr52688.2022.01298)|Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash|2022-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/UMBCvision/SSL-Backdoor)](https://github.com/UMBCvision/SSL-Backdoor)|
|237|[Imperceptible Backdoor Attack: From Input Space to Feature   Representation](https://doi.org/10.48550/arXiv.2205.03190)|Nan Zhong, Zhenxing Qian, Xinpeng Zhang|2022-05-01|Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/Ekko-zn/IJCAI2022-Backdoor)](https://github.com/Ekko-zn/IJCAI2022-Backdoor)|
|238|[Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free](http://arxiv.org/abs/2205.11819v1)|Tianlong Chen, Zhenyu Zhang, Yihua Zhang, Shiyu Chang, Sijia Liu, Zhangyang Wang|2022-05-01|arXiv|[![Star](https://img.shields.io/github/stars/VITA-Group/Backdoor-LTH)](https://github.com/VITA-Group/Backdoor-LTH)|
|239|[Enhancing Backdoor Attacks With Multi-Level MMD Regularization](https://doi.org/10.1109/tdsc.2022.3161477)|Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li|2022-03-28|IEEE Transactions on Dependable and Secure Computing|[![Star](https://img.shields.io/github/stars/xpf/Multi-Level-MMD-Regularization)](https://github.com/xpf/Multi-Level-MMD-Regularization)|
|240|[Partial Identification with Noisy Covariates: A Robust Optimization Approach](https://openreview.net/pdf/e1406a39171680783aba296614172a44fd6bdbf7.pdf)|Wenshuo Guo, Mingzhang Yin, Yixin Wang, Michael Jordan|2022-02-09|CLeaR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/partial-identification-with-noisy-covariates/code)|
|241|[Under-confidence Backdoors Are Resilient and Stealthy Backdoors](http://arxiv.org/abs/2202.11203v2)|Minlong Peng, Zidi Xiong, Quang H. Nguyen, Mingming Sun, Khoa D. Doan, Ping Li|2022-02-01|arXiv|[![Star](https://img.shields.io/github/stars/v-mipeng/LabelSmoothedAttack)](https://github.com/v-mipeng/LabelSmoothedAttack.git)|
|242|[Training with More Confidence: Mitigating Injected and Natural Backdoors   During Training](http://papers.nips.cc/paper_files/paper/2022/hash/ec0c9ca85b4ea49c7ebfb503cf55f2ae-Abstract-Conference.html)|Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma|2022-02-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2202.06382/code)|
|243|[Trigger Hunting with a Topological Prior for Trojan Detection](https://openreview.net/pdf/4db1d42d467c296c5ec7fa3f38e37dcb5c140e84.pdf)|Xiaoling Hu, Xiao Lin, Michael Cogswell, Yi Yao, Susmit Jha, Chao Chen|2022-01-28|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/trigger-hunting-with-a-topological-prior-for/code)|
|244|[Few-shot Backdoor Attacks via Neural Tangent Kernels](https://openreview.net/pdf/fbf6611dad17d0a7975a0a139013d45d767f9c59.pdf)|Jonathan Hayase, Sewoong Oh|2022-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/few-shot-backdoor-attacks-via-neural-tangent/code)|
|245|[Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks](https://openreview.net/pdf/09ec283781ceeabec1fbbbfda26653cf25e8db09.pdf)|Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu, Maosong Sun|2022-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/thunlp/StyleAttack)](https://github.com/thunlp/StyleAttack)|
|246|[Stealthy Backdoors as Compression Artifacts](https://doi.org/10.1109/tifs.2022.3160359)|Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans|2022-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/yulongtzzz/Stealthy-Backdoors-as-Compression-Artifacts)](https://github.com/yulongtzzz/Stealthy-Backdoors-as-Compression-Artifacts)|
|247|[Provable Defense against Backdoor Policies in Reinforcement Learning](http://papers.nips.cc/paper_files/paper/2022/hash/5e67e6a814526079ad8505bf6d926fb6-Abstract-Conference.html)|Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Xiaojin Zhu|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/provable-defense-against-backdoor-policies-in/code)|
|248|[Post-Training Detection of Backdoor Attacks for Two-Class and   Multi-Attack Scenarios](https://openreview.net/pdf/ab4bf90af1442414ba5fa816448b5b73d44ecb92.pdf)|Zhen Xiang, David J. Miller, George Kesidis|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/post-training-detection-of-backdoor-attacks/code)|
|249|[Model-Contrastive Learning for Backdoor Elimination](https://doi.org/10.48550/arXiv.2205.04411)|Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen|2022-01-01|ACM Multimedia|[![Star](https://img.shields.io/github/stars/WeCanShow/MCL)](https://github.com/WeCanShow/MCL)|
|250|[Label-Smoothed Backdoor Attack](https://arxiv.org/abs/2202.11203)|Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li|2022-01-01|arXiv|[![Star](https://img.shields.io/github/stars/v-mipeng/LabelSmoothedAttack)](https://github.com/v-mipeng/LabelSmoothedAttack.git)|
|251|[Imperceptible and Robust Backdoor Attack in 3D Point Cloud](https://doi.org/10.48550/arXiv.2208.08052)|Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia|2022-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/KuofengGao/IRBA)](https://github.com/KuofengGao/IRBA)|
|252|[Identifying a Training-Set Attack's Target Using Renormalized Influence   Estimation](http://arxiv.org/abs/2201.10055v2)|Zayd Hammoudeh, Daniel Lowd|2022-01-01|arXiv|[![Star](https://img.shields.io/github/stars/ZaydH/target_identification)](https://github.com/ZaydH/target_identification)|
|253|[How to Backdoor Diffusion Models?](https://openreview.net/pdf/1dc679066d3bc93c7cd365d2948a2a48e4d2ff3a.pdf)|Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho|2022-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/how-to-backdoor-diffusion-models/code)|
|254|[Backdoor Defense via Decoupling the Training Process](https://openreview.net/pdf/825a2fee50fe494bcf13085113d2a7565af192b6.pdf)|Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 9 code implementations](https://www.catalyzex.com/paper/backdoor-defense-via-decoupling-the-training/code)|
|255|[Few-Shot Backdoor Attacks on Visual Object Tracking](https://openreview.net/pdf/132d1b18d6c8d837cebbdb801781870f713295cb.pdf)|Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia|2022-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/few-shot-backdoor-attacks-on-visual-object/code)|
|256|[Data-Free Backdoor Removal Based on Channel Lipschitzness](https://doi.org/10.1007/978-3-031-20065-6_11)|Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu|2022-01-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/rkteddy/channel-Lipschitzness-based-pruning)](https://github.com/rkteddy/channel-Lipschitzness-based-pruning)|
|257|[Black-box Dataset Ownership Verification via Backdoor Watermarking](https://doi.org/10.1109/TIFS.2023.3265535)|Yiming Li, Mingyan Zhu, Xue Yang, Yong Jiang, Tao Wei, Shu-Tao Xia|2022-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/THUYimingLi/DVBW)](https://github.com/THUYimingLi/DVBW)|
|258|[BadPrompt: Backdoor Attacks on Continuous Prompts](http://papers.nips.cc/paper_files/paper/2022/hash/f0722b58f02d7793acf7d328928f933a-Abstract-Conference.html)|Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, Xiaojie Yuan|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/badprompt-backdoor-attacks-on-continuous/code)|
|259|[Backdoor Attacks on Vision Transformers](https://doi.org/10.48550/arXiv.2206.08477)|Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash|2022-01-01|arXiv|[![Star](https://img.shields.io/github/stars/UCDvision/backdoor_transformer)](https://github.com/UCDvision/backdoor_transformer.git)|
|260|[Backdoor Attacks in the Supply Chain of Masked Image Modeling](https://openreview.net/pdf/0c5ec0b08ce9e3512fdc3d80cd06802dbb8ef089.pdf)|Xinyue Shen, Xinlei He, Zheng Li, Yun Shen, Michael Backes, Yang Zhang|2022-01-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/backdoor-attacks-in-the-supply-chain-of/code)|
|261|[Augmentation Backdoors](https://openreview.net/pdf/59a474155bd99e72fd1d60447640fe322d4f340d.pdf)|Joseph Rance, Yiren Zhao, Ilia Shumailov, Robert D. Mullins|2022-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/augmentation-backdoors/code)|
|262|[Architectural Backdoors in Neural Networks](https://openreview.net/pdf/c202e3f7b58579019c2ae7534b94815d06eda13d.pdf)|Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot|2022-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/architectural-backdoors-in-neural-networks/code)|
|263|[An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks](https://doi.org/10.48550/arXiv.2204.04329)|Xinqiao Zhang, Huili Chen, Ke Huang, Farinaz Koushanfar|2022-01-01|arXiv|[![Star](https://img.shields.io/github/stars/xinqiaozhang/adatrojan)](https://github.com/xinqiaozhang/adatrojan)|
|264|[FIBA: Frequency-Injection based Backdoor Attack in Medical Image   Analysis](https://doi.org/10.1109/cvpr52688.2022.02021)|Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao|2021-12-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/HazardFY/FIBA)](https://github.com/HazardFY/FIBA)|
|265|[Manipulating SGD with Data Ordering Attacks](https://openreview.net/pdf/38b5087efcece7a26b421cd3cd7e0a2a30c8096e.pdf)|Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A. Erdogdu, Ross Anderson|2021-11-09|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/manipulating-sgd-with-data-ordering-attacks/code)|
|266|[Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving Adversarial Outcomes](https://openreview.net/pdf/d99b499610c11e58db2b8e2b8b421fbd7ec493a8.pdf)|Sanghyun Hong, Michael-Andrei Panaitescu-Liess, Yigitcan Kaya, Tudor Dumitras|2021-11-09|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/qu-anti-zation-exploiting-quantization/code)|
|267|[Anomaly Localization in Model Gradients Under Backdoor Attacks Against   Federated Learning](https://dblp.uni-trier.de/db/journals/corr/corr2111.html#abs-2111-14683)|Zeki Bilgin|2021-11-01|OpenAlex|[![Star](https://img.shields.io/github/stars/ArcelikAcikKaynak/Federated_Learning)](https://github.com/ArcelikAcikKaynak/Federated_Learning.git)|
|268|[A Kernel Test for Causal Association via Noise Contrastive Backdoor   Adjustment](https://jmlr.org/papers/v25/21-1409.html)|Robert Hu, Dino Sejdinovic, Robin J. Evans|2021-11-01|J. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/MrHuff/kgformula)](https://github.com/MrHuff/kgformula)|
|269|[Adversarial Neuron Pruning Purifies Backdoored Deep Models](https://proceedings.neurips.cc/paper/2021/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html)|Dongxian Wu, Yisen Wang|2021-10-27|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/adversarial-neuron-pruning-purifies/code)|
|270|[Anti-Backdoor Learning: Training Clean Models on Poisoned Data](https://proceedings.neurips.cc/paper/2021/hash/7d38b1e9bd793d3f45e0e212a729a93c-Abstract.html)|Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma|2021-10-21|NeurIPS 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/anti-backdoor-learning-training-clean-models/code)|
|271|[A Backdoor Attack against 3D Point Cloud Classifiers](https://doi.org/10.1109/iccv48922.2021.00750)|Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis|2021-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/zhenxianglance/PCBA)](https://github.com/zhenxianglance/PCBA)|
|272|[AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value   Analysis](https://openreview.net/pdf/b8ad85b4ddd615a5abac4d7c1d5713fc92b9f0e9.pdf)|Junfeng Guo, Ang Li, Cong Liu|2021-10-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/aeva-black-box-backdoor-detection-using/code)|
|273|[Invisible Backdoor Attack with Sample-Specific Triggers](https://doi.org/10.1109/iccv48922.2021.01615)|Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu|2021-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/yuezunli/ISSBA)](https://github.com/yuezunli/ISSBA)|
|274|[Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text   Style Transfer](https://doi.org/10.18653/v1/2021.emnlp-main.374)|Fanchao Qi, Yang‚ÄêYi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun|2021-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/thunlp/StyleAttack)](https://github.com/thunlp/StyleAttack)|
|275|[RAP: Robustness-Aware Perturbations for Defending against Backdoor   Attacks on NLP Models](https://doi.org/10.18653/v1/2021.emnlp-main.659)|Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun|2021-10-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/lancopku/RAP)](https://github.com/lancopku/RAP)|
|276|[Backdoor Attack on Hash-based Image Retrieval via Clean-label Data   Poisoning](http://proceedings.bmvc2023.org/172/)|Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia|2021-09-01|BMVC|[![Star](https://img.shields.io/github/stars/KuofengGao/CIBA)](https://github.com/KuofengGao/CIBA)|
|277|[BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning](https://doi.org/10.24963/ijcai.2021/509)|Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song|2021-08-01|OpenAlex|[![Star](https://img.shields.io/github/stars/wanglun1996/multi_agent_rl_backdoor_videos)](https://github.com/wanglun1996/multi_agent_rl_backdoor_videos)|
|278|[BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised   Learning](https://openreview.nethttps://arxiv.org/pdf/2108.00352.pdf)|Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong|2021-08-01|2022 IEEE Symposium on Security and Privacy (SP)|[![Star](https://img.shields.io/github/stars/jjy1994/BadEncoder)](https://github.com/jjy1994/BadEncoder)|
|279|[Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word   Substitution](https://doi.org/10.18653/v1/2021.acl-long.377)|Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun|2021-06-01|ACL/IJCNLP|[![Star](https://img.shields.io/github/stars/thunlp/BkdAtk-LWS)](https://github.com/thunlp/BkdAtk-LWS)|
|280|[Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks   Trained from Scratch](http://papers.nips.cc/paper_files/paper/2022/hash/79eec295a3cd5785e18c61383e7c996b-Abstract-Conference.html)|Hossein Souri, Liam H Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein|2021-06-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/sleeper-agent-scalable-hidden-trigger/code)|
|281|[Incompatibility Clustering as a Defense Against Backdoor Poisoning   Attacks](https://openreview.net/pdf/e27bb4c7787b3770053151428e69c5ab0f279dd2.pdf)|Charles Jin, Melinda Sun, Martin C. Rinard|2021-05-01|ICLR 2023 poster|[![Star](https://img.shields.io/github/stars/charlesjin/compatibility_clustering)](https://github.com/charlesjin/compatibility_clustering)|
|282|[SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics](http://export.arxiv.org/pdf/2104.11315)|Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh|2021-04-22|arXiv|[![Star](https://img.shields.io/github/stars/SewoongLab/spectre-defense)](https://github.com/SewoongLab/spectre-defense)|
|283|[Targeted Attack against Deep Neural Networks via Flipping Limited Weight   Bits](https://openreview.net/pdf/ed4d75e28ae70ba28f4895cf7097cf634745d11a.pdf)|Jiawang Bai, Baoyuan Wu, Yong Zhang, Yiming Li, Zhifeng Li, Shu-Tao Xia|2021-02-01|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/targeted-attack-against-deep-neural-networks/code)|
|284|[Neural Attention Distillation: Erasing Backdoor Triggers from Deep   Neural Networks](https://openreview.net/pdf/42f5786a622e8cdc4ce43d79d5d83ebe8e4feeeb.pdf)|Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma|2021-01-14|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 8 code implementations](https://www.catalyzex.com/paper/neural-attention-distillation-erasing/code)|
|285|[Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching](https://openreview.net/pdf/3a3c570da85848de52605f6669aae395d063027b.pdf)|Jonas Geiping, Liam H Fowl, W. Ronny Huang, Wojciech Czaja, Gavin Taylor, Michael Moeller, Tom Goldstein|2021-01-12|ICLR 2021 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/witches-brew-industrial-scale-data-poisoning/code)|
|286|[Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger](https://doi.org/10.18653/v1/2021.acl-long.37)|Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun|2021-01-01|ACL/IJCNLP|[![Star](https://img.shields.io/github/stars/thunlp/HiddenKiller)](https://github.com/thunlp/HiddenKiller)|
|287|[WaNet -- Imperceptible Warping-based Backdoor Attack](https://openreview.net/pdf/db3277f5b47619abfe13880772b864960e98f643.pdf)|Tuan Anh Nguyen, Anh Tuan Tran|2021-01-01|International Conference on Learning Representations|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/wanet-imperceptible-warping-based-backdoor/code)|
|288|[Use Procedural Noise to Achieve Backdoor Attack](https://doi.org/10.1109/access.2021.3110239)|Xuan Chen, Yuena Ma, Shiwei Lu|2021-01-01|IEEE Access|[![Star](https://img.shields.io/github/stars/928082786/pnoiseattack)](https://github.com/928082786/pnoiseattack)|
|289|[Red Alarm for Pre-trained Models: Universal Vulnerabilities by Neuron-Level Backdoor Attacks](https://openreview.net/pdf/1cc11ab778ba03f41a45f941b3a3e42ccb867cc6.pdf)|Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun|2021-01-01|ICML 2021 Workshop AML Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/red-alarm-for-pre-trained-models-universal/code)|
|290|[ONION: A Simple and Effective Defense Against Textual Backdoor Attacks](https://doi.org/10.18653/v1/2021.emnlp-main.752)|Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu, Maosong Sun|2021-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/thunlp/ONION)](https://github.com/thunlp/ONION)|
|291|[Adversarial Unlearning of Backdoors via Implicit Hypergradient](https://openreview.net/pdf/6aeb6e81c9d0eadbb4cfbefb6caac0f155d561ea.pdf)|Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia|2021-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-of-backdoors-via/code)|
|292|[Handcrafted Backdoors in Deep Neural Networks](http://papers.nips.cc/paper_files/paper/2022/hash/3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html)|Sanghyun Hong, Nicholas Carlini, Alexey Kurakin|2021-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/handcrafted-backdoors-in-deep-neural-networks/code)|
|293|[Excess Capacity and Backdoor Poisoning](https://proceedings.neurips.cc/paper/2021/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html)|Naren Sarayu Manoj, Avrim Blum|2021-01-01|NeurIPS 2021 Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/excess-capacity-and-backdoor-poisoning/code)|
|294|[CRFL: Certifiably Robust Federated Learning against Backdoor Attacks](http://proceedings.mlr.press/v139/xie21a.html)|Chulin Xie, Minghao Chen, Pin-Yu Chen, Bo Li|2021-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/AI-secure/CRFL)](https://github.com/AI-secure/CRFL)|
|295|[An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware](https://openreview.net/pdf/628fdbcebf74b3b22b28cf024722d2d5b78c9136.pdf)|M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang|2021-01-01|ICLR 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/an-optimization-perspective-on-realizing/code)|
|296|[Poisoned classifiers are not only backdoored, they are fundamentally   broken](https://openreview.net/pdf/4959459ccc8a6c2d401fe6ca978ce4b82b4f3ff0.pdf)|Mingjie Sun, Siddhant Agarwal, J. Zico Kolter|2020-10-01|ICLR 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/poisoned-classifiers-are-not-only-backdoored/code)|
|297|[Weight Poisoning Attacks on Pre-trained Models](http://arxiv.org/abs/2004.06660v1)|Keita Kurita, Paul Michel, Graham Neubig|2020-04-01|arXiv|[![Star](https://img.shields.io/github/stars/neulab/RIPPLe)](https://github.com/neulab/RIPPLe)|
|298|[Backdoor Attack against Speaker Verification](https://doi.org/10.1109/ICASSP39728.2021.9413468)|Tongqing Zhai, Yiming Li, Ziqi Zhang, Baoyuan Wu, Yong Jiang, Shu-Tao Xia|2020-01-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/zhaitongqing233/Backdoor-attack-against-speaker-verification)](https://github.com/zhaitongqing233/Backdoor-attack-against-speaker-verification)|
|299|[Backdoor Learning: A Survey](https://doi.org/10.1109/TNNLS.2022.3182979)|Yiming Li, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia|2020-01-01|IEEE Transactions on Neural Networks and Learning Systems|[![Star](https://img.shields.io/github/stars/THUYimingLi/backdoor-learning-resources)](https://github.com/THUYimingLi/backdoor-learning-resources)|
|300|[Graph Backdoor](https://www.usenix.org/conference/usenixsecurity21/presentation/xi)|Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang|2020-01-01|USENIX Security Symposium|[![Star](https://img.shields.io/github/stars/HarrialX/GraphBackdoor)](https://github.com/HarrialX/GraphBackdoor)|
|301|[Input-Aware Dynamic Backdoor Attack](https://openreview.nethttp://proceedings.neurips.cc/paper/2020/file/234e691320c0ad5b45ee3c96d0d7b8f8-Paper.pdf)|Tuan Anh Nguyen, Anh Tuan Tran|2020-01-01|Neural Information Processing Systems|[![Star](https://img.shields.io/github/stars/VinAIResearch/input-aware-backdoor-attack-release)](https://github.com/VinAIResearch/input-aware-backdoor-attack-release)|
|302|[Rethinking the Trigger of Backdoor Attack](https://openreview.net/pdf/f41085225b4c2960c0e50e0201c0c0ab536e020f.pdf)|Yiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia|2020-01-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/rethinking-the-trigger-of-backdoor-attack/code)|
|303|[Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness](https://openreview.net/pdf/fb8082dd5515e11c88f59b0f4911266f1891fb61.pdf)|Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue Lin|2019-12-19|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/bridging-mode-connectivity-in-loss-landscapes/code)|
|304|[Attack-Resistant Federated Learning with Residual-based Reweighting](https://openreview.net/pdf/1ea807b624ecc563e3b617f0948502afeee0ec8c.pdf)|Shuhao Fu, Chulin Xie, Bo Li, Qifeng Chen|2019-12-01|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/attack-resistant-federated-learning-with/code)|

![Star History Chart](https://api.star-history.com/svg?repos=SeRAlab/ArcGen,PlayerYangh/Authority-Trigger,zth855/Patronus,Robin-WZQ/AMDET,XinyuLiu71/Information_Bottleneck_Backdoor,bboylyg/BackdoorLLM,kazefjj/A2X-backdoor,mala-lab/MTAttack,lafeat/flareon,bin015/BackdoorVLM,OPTML-Group/Unlearn-Backdoor,Xuzhenhua55/CTCC,JiiahaoXU/SoDa-BNGuard,SeekingDream/DLCompilerAttack,ipangbo/causal-debias,dingbinb/FedDLAD,azure-123/PNAct,liangzid/VirusInfectionAttack,azshue/AutoPoison,still2009/cowardFL&type=Date)

