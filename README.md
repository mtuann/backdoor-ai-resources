# Backdoor Learning Papers

Updated list of Backdoor Learning papers as of **January 08, 2026**. 

## Quick Access
üîç **[Interactive Search & Browse](https://mtuann.github.io/papers/)** - Filter, search, and explore all papers with an intuitive interface

## Overview
- **Coverage**: Papers from 2016 to present
- **Sources**: arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML venues
- **Updates**: Automated collection of new publications
- **Features**: Advanced search, code availability tracking, and multi-venue coverage

## Related Topics
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** | **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** | **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** | **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)**
- **[Serverless Computing](https://mtuann.github.io/papers/)** | **[Multi-Modal Learning](https://mtuann.github.io/papers/)**

## Backdoor Learning Papers with Code
This section lists papers with available code (sorted by publication date). For the complete paper list, visit the [Research Papers Page](https://mtuann.github.io/papers/).

---

## Support
If you find this resource helpful, consider supporting its development:

- **Ko-fi** (PayPal/Card): [ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)
- **Techcombank** (Vietnam): 5877 5555 55 (Nguyen Thi Lan Phuong)

---

*This repository is regularly updated. For the latest data, visit the [Research Papers Page](https://mtuann.github.io/papers/).*


|No.|Title|Authors|Publish Date|Venue|Code|
|---|---|---|---|---|---|
|1|[ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures](https://doi.org/10.48550/arxiv.2512.19730)|Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li|2025-12-17|in IEEE Transactions on Information Forensics and Security, vol. 20, pp. 10082-10097, 2025|[![Star](https://img.shields.io/github/stars/SeRAlab/ArcGen)](https://github.com/SeRAlab/ArcGen)|
|2|[Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs](http://arxiv.org/abs/2512.10600v1)|Han Yang, Shaofeng Li, Tian Dong, Xiangyu Xu, Guangchi Liu, Zhen Ling|2025-12-11|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/PlayerYangh/Authority-Trigger)](https://github.com/PlayerYangh/Authority-Trigger)|
|3|[Patronus: Identifying and Mitigating Transferable Backdoors in Pre-trained Language Models](https://doi.org/10.48550/arxiv.2512.06899)|Zhao, Tianhang, Du, Wei, Zhao, Haodong, Duan, Sufeng, Liu, Gongshen|2025-12-01|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/zth855/Patronus)](https://github.com/zth855/Patronus)|
|4|[Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models](http://arxiv.org/abs/2512.00343v1)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-11-29|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/Robin-WZQ/AMDET)](https://github.com/Robin-WZQ/AMDET)|
|5|[Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck](https://doi.org/10.48550/arxiv.2511.21923)|Liu Xin-yu, Zhang Xu, Chen Can, Wang Ren|2025-11-26|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/XinyuLiu71/Information_Bottleneck_Backdoor)](https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git)|
|6|[AutoBackdoor: Automating Backdoor Attacks via LLM Agents](https://doi.org/10.48550/arxiv.2511.16709)|Li, Yige, Li Zhe, Zhao Wei, Min, Nay Myat, Huang, Hanxun, Ma, Xingjun, Sun Jun|2025-11-20|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/bboylyg/BackdoorLLM)](https://github.com/bboylyg/BackdoorLLM)|
|7|[Enhancing All-to-X Backdoor Attacks with Optimized Target Class Mapping](https://doi.org/10.48550/arxiv.2511.13356)|Wang Lei, Tian Yu-long, Han Hao, Xu Fengyuan|2025-11-17|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/kazefjj/A2X-backdoor)](https://github.com/kazefjj/A2X-backdoor)|
|8|[MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models](https://doi.org/10.48550/arxiv.2511.10098)|Wang Zihan, Pang, Guansong, Miao Wenjun, Zheng Jin, Bai Xiao|2025-11-13|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/mala-lab/MTAttack)](https://github.com/mala-lab/MTAttack)|
|9|[Flareon: Stealthy all2all Backdoor Injection via Poisoned Augmentation](https://openreview.net/pdf/8f5e6d6b8c53b5115dfb5e4950961efed881feaa.pdf)|Tianrui Qin, Xuan Wang, Xianghuan He, Yiren Zhao, Kejiang Ye, Chengzhong Xu, Xitong Gao|2025-11-03|ACM Transactions on Knowledge Discovery from Data|[![Star](https://img.shields.io/github/stars/lafeat/flareon)](https://github.com/lafeat/flareon)|
|10|[BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models](https://doi.org/10.48550/arxiv.2511.18921)|Li Juncheng, Li Yige, Huang, Hanxun, Chen Yunhao, Wang Xin, Wang YiXu, Ma, Xingjun, Jiang, Yu-Gang|2025-11-01|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/bin015/BackdoorVLM)](https://github.com/bin015/BackdoorVLM)|
|11|[Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning](https://doi.org/10.48550/arXiv.2510.17021)|Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu|2025-10-19|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Backdoor)](https://github.com/OPTML-Group/Unlearn-Backdoor)|
|12|[CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://doi.org/10.48550/arXiv.2509.09703)|Association for Computational Linguistics 2025, Han Meng, Lin Changting, Tian Shengwei, Xu Zhenhua, Yue Xubin, Zhao Xi-x...|2025-10-10|Underline Science Inc.|[![Star](https://img.shields.io/github/stars/Xuzhenhua55/CTCC)](https://github.com/Xuzhenhua55/CTCC)|
|13|[On the Out-of-Distribution Backdoor Attack for Federated Learning](https://doi.org/10.48550/arXiv.2509.13219)|Jin-Sen Xu, Zikai Zhang, Rui Hu|2025-09-16|OpenAlex|[![Star](https://img.shields.io/github/stars/JiiahaoXU/SoDa-BNGuard)](https://github.com/JiiahaoXU/SoDa-BNGuard)|
|14|[Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](https://doi.org/10.48550/arXiv.2509.11173)|Simin Chen, Jinjun Peng, Yixin He, Junfeng Yang, Baishakhi Ray|2025-09-14|arXiv|[![Star](https://img.shields.io/github/stars/SeekingDream/DLCompilerAttack)](https://github.com/SeekingDream/DLCompilerAttack)|
|15|[CABIN: Debiasing Vision-Language Models Using Backdoor Adjustments](https://doi.org/10.24963/ijcai.2025/55)|B. Y. Pang, Tingrui Qiao, Caroline Walker, Chris Cunningham, Yun Sing Koh|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/ipangbo/causal-debias)](https://github.com/ipangbo/causal-debias)|
|16|[FedDLAD: A Federated Learning Dual-Layer Anomaly Detection Framework for Enhancing Resilience Against Backdoor Attacks](https://doi.org/10.24963/ijcai.2025/559)|Binbin Ding, Penghui Yang, Sheng-Jun Huang|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/dingbinb/FedDLAD)](https://github.com/dingbinb/FedDLAD)|
|17|[PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning](https://doi.org/10.48550/arXiv.2507.00485)|Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang|2025-09-01|OpenAlex|[![Star](https://img.shields.io/github/stars/azure-123/PNAct)](https://github.com/azure-123/PNAct)|
|18|[Virus Infection Attack on LLMs: Your Poisoning Can Spread "VIA" Synthetic Data](http://arxiv.org/abs/2509.23041v2)|Zi Liang, Qingqing Ye, Xuan Liu, Yanyun Wang, Jianliang Xu, Haibo Hu|2025-09-01|arXiv|[![Star](https://img.shields.io/github/stars/liangzid/VirusInfectionAttack)](https://github.com/liangzid/VirusInfectionAttack)|
|19|[Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://doi.org/10.48550/arXiv.2508.21004)|Chen Chen, Yuchen Sun, Jiaxin Gao, Xueluan Gong, Qian Wang, Ziyao Wang, Yongsen Zheng, Kwok-Yan Lam|2025-08-28|Zenodo (CERN European Organization for Nuclear Research)|[![Star](https://img.shields.io/github/stars/azshue/AutoPoison)](https://github.com/azshue/AutoPoison)|
|20|[Coward: Collision-based Watermark for Proactive Federated Backdoor Detection](http://arxiv.org/abs/2508.02115v3)|Wenjie Li, Siying Gu, Yiming Li, Kangjie Chen, Zhili Chen, Tianwei Zhang, Shu-Tao Xia, Dacheng Tao|2025-08-01|arXiv|[![Star](https://img.shields.io/github/stars/still2009/cowardFL)](https://github.com/still2009/cowardFL)|
|21|[CLIP-Guided Backdoor Defense through Entropy-Based Poisoned Dataset   Separation](https://doi.org/10.48550/arXiv.2507.05113)|Binyan Xu, Fan Yang, Xilin Dai, Di Tang, Kehuan Zhang|2025-07-01|OpenAlex|[![Star](https://img.shields.io/github/stars/binyxu/CGD)](https://github.com/binyxu/CGD)|
|22|[BackFed: An Efficient &amp; Standardized Benchmark Suite for Backdoor Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2507.04903)|Thinh Dao, Dung Thuy Nguyen, Khoa D. Doan, Kok-Seng Wong|2025-07-01|arXiv|[![Star](https://img.shields.io/github/stars/thinh-dao/BackFed)](https://github.com/thinh-dao/BackFed)|
|23|[Invisible Backdoor Attack against Self-supervised Learning](https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.html)|Hanrong Zhang, Zhenting Wang, Boheng Li, Fulin Lin, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqi...|2025-06-10|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/Zhang-Henry/INACTIVE)](https://github.com/Zhang-Henry/INACTIVE)|
|24|[SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in   VLMs](https://doi.org/10.48550/arXiv.2506.04743)|Shuhan Xu, Siyuan Liang, Hongling Zheng, Aishan Liu, Xinbiao Wang, Yong Luo, Fu Lin, Leszek Rutkowski, Dacheng Tao|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/Ciconey/SRD)](https://github.com/Ciconey/SRD.git)|
|25|[TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor   Attacks on Deep Reinforcement Learning](https://doi.org/10.48550/arXiv.2506.09562)|Mingxuan Zhang, Oubo Ma, Kang Wei, Songze Li, Shouling Ji|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/S3IC-Lab/TooBadRL)](https://github.com/S3IC-Lab/TooBadRL)|
|26|[Defending the Edge: Representative-Attention for Mitigating Backdoor   Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2505.10297)|Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa|2025-05-01|arXiv|[![Star](https://img.shields.io/github/stars/Peatech/FeRA_defense)](https://github.com/Peatech/FeRA_defense.git)|
|27|[Towards Dataset Copyright Evasion Attack against Personalized   Text-to-Image Diffusion Models](http://arxiv.org/abs/2505.02824v1)|Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia|2025-05-01|arXiv|[![Star](https://img.shields.io/github/stars/csyufei/CEAT2I)](https://github.com/csyufei/CEAT2I)|
|28|[Dynamic Attention Analysis for Backdoor Detection in Text-to-Image   Diffusion Models](https://doi.org/10.48550/arXiv.2504.20518)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2025-04-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/DAA)](https://github.com/Robin-WZQ/DAA)|
|29|[Propaganda via AI? A Study on Semantic Backdoors in Large Language   Models](https://doi.org/10.48550/arXiv.2504.12344)|Nay Myat Min, Long H. Pham, Yige Li, Jun Sun|2025-04-01|arXiv|[![Star](https://img.shields.io/github/stars/NayMyatMin/RAVEN)](https://github.com/NayMyatMin/RAVEN)|
|30|[Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature   Awareness](https://doi.org/10.48550/arXiv.2503.09336)|Yu Feng, Dingxin Zhang, Runkai Zhao, Yong Xia, Heng Huang, Tom Weidong Cai|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/HazardFY/SPBA)](https://github.com/HazardFY/SPBA)|
|31|[Trigger without Trace: Towards Stealthy Backdoor Attack on Text-to-Image Diffusion Models](http://arxiv.org/abs/2503.17724v2)|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/TwT)](https://github.com/Robin-WZQ/TwT)|
|32|[CBW: Towards Dataset Ownership Verification for Speaker Verification via   Clustering-based Backdoor Watermarking](https://doi.org/10.48550/arXiv.2503.05794)|Yiming Li, Kaiying Yan, Shuo Shao, Tongqing Zhai, Shu-Tao Xia, Zhan Qin, Dacheng Tao|2025-03-01|arXiv|[![Star](https://img.shields.io/github/stars/Radiant0726/CBW)](https://github.com/Radiant0726/CBW)|
|33|[Detecting Backdoor Attacks in Federated Learning via Direction Alignment   Inspection](https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.html)|Jiahao Xu, Zikai Zhang, Rui Hu|2025-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/JiiahaoXU/AlignIns)](https://github.com/JiiahaoXU/AlignIns)|
|34|[DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on   LLM-based Agent](https://doi.org/10.48550/arXiv.2502.12575)|Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su|2025-02-18|arXiv|[![Star](https://img.shields.io/github/stars/whfeLingYu/DemonAgent)](https://github.com/whfeLingYu/DemonAgent)|
|35|[BackdoorDM: A Comprehensive Benchmark for Backdoor Learning in Diffusion   Model](https://doi.org/10.48550/arXiv.2502.11798)|Weilin Lin, Nanjun Zhou, Yanyun Wang, Jianze Li, Hui Xiong, Li Liu|2025-02-17|arXiv|[![Star](https://img.shields.io/github/stars/linweiii/BackdoorDM)](https://github.com/linweiii/BackdoorDM)|
|36|[BoT: Breaking Long Thought Processes of o1-like Large Language Models   through Backdoor Attack](https://doi.org/10.48550/arXiv.2502.12202)|Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke Xu, Baoyuan Wu|2025-02-16|arXiv|[![Star](https://img.shields.io/github/stars/zihao-ai/BoT)](https://github.com/zihao-ai/BoT)|
|37|[Revisiting the Auxiliary Data in Backdoor Purification](https://doi.org/10.48550/arXiv.2502.07231)|Shaokui Wei, Shanchao Yang, Jiayin Liu, Hongyuan Zha|2025-02-10|arXiv|[![Star](https://img.shields.io/github/stars/shawkui/BackdoorBenchER)](https://github.com/shawkui/BackdoorBenchER)|
|38|[Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in   Multilingual LLMs](https://doi.org/10.48550/arXiv.2502.16901)|Himanshu Beniwal, Sailesh Panda, Birudugadda Srivibhav, Mayank Singh|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/himanshubeniwal/X-BAT)](https://github.com/himanshubeniwal/X-BAT)|
|39|[Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on   Diffusion Models](https://doi.org/10.48550/arXiv.2502.20650)|Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/paoche11/Gungnir)](https://github.com/paoche11/Gungnir)|
|40|[Detecting Backdoor Samples in Contrastive Language Image Pretraining](https://openreview.net/forum?id=KmQEsIfhr9)|Hanxun Huang, Sarah Monazam Erfani, Yige Li, Xingjun Ma, James Bailey|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/HanxunH/Detect-CLIP-Backdoor-Samples)](https://github.com/HanxunH/Detect-CLIP-Backdoor-Samples)|
|41|[BadRefSR: Backdoor Attacks Against Reference-based Image Super   Resolution](https://doi.org/10.1109/icassp49660.2025.10889523)|Xue Yang, Tao Chen, Lei Guo, Wenbo Jiang, Ji Guo, Yongming Li, Jiaming He|2025-02-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/xuefusiji/BadRefSR)](https://github.com/xuefusiji/BadRefSR)|
|42|[UNIDOOR: A Universal Framework for Action-Level Backdoor Attacks in Deep   Reinforcement Learning](https://doi.org/10.48550/arXiv.2501.15529)|Oubo Ma, Linkang Du, Yang Dai, Chunyi Zhou, Qingming Li, Yuwen Pu, Shouling Ji|2025-01-26|arXiv|[![Star](https://img.shields.io/github/stars/maoubo/UNIDOOR)](https://github.com/maoubo/UNIDOOR)|
|43|[Mechanistic Exploration of Backdoored Large Language Model Attention Patterns](https://doi.org/10.48550/arXiv.2508.15847)|Mohammed Abu Baker, Lakshmi Babu Saheer|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/mshahoyi/sa_attn_analysis)](https://github.com/mshahoyi/sa_attn_analysis)|
|44|[Vertical Federated Unlearning via Backdoor Certification](https://doi.org/10.48550/arXiv.2412.11476)|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025-01-01|IEEE Transactions on Services Computing|[![Star](https://img.shields.io/github/stars/mengde-han/VFL-unlearn)](https://github.com/mengde-han/VFL-unlearn)|
|45|[UFID: A Unified Framework for Black-box Input-level Backdoor Detection on Diffusion Models](https://doi.org/10.1609/aaai.v39i26.34941)|Zihan Guan, Mengxuan Hu, Sheng Li, Anil Kumar S. Vullikanti|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/GuanZihan/official_UFID)](https://github.com/GuanZihan/official_UFID)|
|46|[ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training](https://doi.org/10.48550/arXiv.2511.00446)|Xin Yao, Haiyang Zhao, Yimin Chen, Jiawei Guo, Kecheng Huang, Ming Zhao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/xinyaocse/ToxicTextCLIP)](https://github.com/xinyaocse/ToxicTextCLIP)|
|47|[Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model](https://doi.org/10.48550/arXiv.2503.17724)|Jie Zhang, Zhongqi Wang, Shiguang Shan, Xilin Chen|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Robin-WZQ/IBA)](https://github.com/Robin-WZQ/IBA)|
|48|[The Ripple Effect: On Unforeseen Complications of Backdoor Attacks](https://openreview.net/forum?id=sw1Sm72dmV)|Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/zhangrui4041/Backdoor_Complications)](https://github.com/zhangrui4041/Backdoor_Complications)|
|49|[Test-Time Multimodal Backdoor Detection by Contrastive Prompting](https://openreview.net/forum?id=1jd25AlvHS)|Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng|2025-01-01|ICML|[![Star](https://img.shields.io/github/stars/Purshow/BDetCLIP)](https://github.com/Purshow/BDetCLIP)|
|50|[Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack](https://doi.org/10.48550/arXiv.2509.23871)|Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/WhitolfChen/SCAR)](https://github.com/WhitolfChen/SCAR)|
|51|[TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood Screening](https://doi.org/10.48550/arXiv.2510.14299)|Nam Le, Leo Yu Zhang, Kewen Liao, Shirui Pan, Wei Luo|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/namle-w/TEDpp)](https://github.com/namle-w/TEDpp)|
|52|[Sealing The Backdoor: Unlearning Adversarial Text Triggers In Diffusion Models Using Knowledge Distillation](https://doi.org/10.48550/arXiv.2508.18235)|Ashwath Vaithinathan Aravindan, Abha Jha, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Mystic-Slice/Sealing-The-Backdoor)](https://github.com/Mystic-Slice/Sealing-The-Backdoor)|
|53|[Rounding-Guided Backdoor Injection in Deep Learning Model Quantization](https://doi.org/10.48550/arXiv.2510.09647)|Xiangxiang Chen, Peixin Zhang, Jun Sun, Wenhai Wang, Jingyi Wang|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/cxx122/QuRA)](https://github.com/cxx122/QuRA)|
|54|[REFINE: Inversion-Free Backdoor Defense via Model Reprogramming](https://openreview.net/forum?id=4IYdCws9fc)|Yukun Chen, Shuo Shao, Enhao Huang, Yiming Li, Pin-Yu Chen, Zhan Qin, Kui Ren|2025-01-01|ICLR|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|55|[SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs](https://doi.org/10.48550/arXiv.2508.06153)|Zhengxian Wu, Juan Wen, Wanli Peng, Haowei Chang, Yinghan Zhou, Yiming Xue|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)](https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)|
|56|[Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking](https://doi.org/10.1109/AVSS65446.2025.11149824)|Yu-Feng Chen, Tzuhsuan Huang, Pin-Yen Chiu, Jun-Cheng Chen|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/aiiu-lab/BackdoorImageEditing)](https://github.com/aiiu-lab/BackdoorImageEditing)|
|57|[Circumventing Backdoor Space via Weight Symmetry](https://openreview.net/forum?id=dqYO5LVyYh)|Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/JiePeng104/TSC)](https://github.com/JiePeng104/TSC)|
|58|[Backdoor Token Unlearning: Exposing and Defending Backdoors in   Pretrained Language Models](https://doi.org/10.1609/aaai.v39i23.34605)|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/XDJPH/BTU)](https://github.com/XDJPH/BTU)|
|59|[FLARE: Towards Universal Dataset Purification against Backdoor Attacks](https://doi.org/10.1109/TIFS.2025.3581719)|Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li|2025-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|60|[BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://doi.org/10.48550/arXiv.2507.18305)|Biao Yi, Zekun Fei, Jianing Geng, Tong Li, Lihai Nie, Zheli Liu, Yiming Li|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/FZaKK/BadReasoner)](https://github.com/FZaKK/BadReasoner)|
|61|[BeDKD: Backdoor Defense based on Dynamic Knowledge Distillation and Directional Mapping Modulator](https://doi.org/10.48550/arXiv.2508.01595)|Zhengxian Wu, Juan Wen, Wanli Peng, Yinghan Zhou, Changtong dou, Yiming Xue|2025-01-01|AAAI 2026|[![Star](https://img.shields.io/github/stars/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)](https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs)|
|62|[Cert-SSB: Toward Certified Sample-Specific Backdoor Defense](https://doi.org/10.48550/arXiv.2504.21730)|Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/NcepuQiaoTing/Cert-SSB)](https://github.com/NcepuQiaoTing/Cert-SSB)|
|63|[Backdooring Self-Supervised Contrastive Learning by Noisy Alignment](https://doi.org/10.48550/arXiv.2508.14015)|Tuo Chen, Jie Gui, Minjing Dong, Ju Jia, Lanting Fang, Jian Liu|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/jsrdcht/Noisy-Alignment)](https://github.com/jsrdcht/Noisy-Alignment)|
|64|[Claim-Guided Textual Backdoor Attack for Practical Applications](https://doi.org/10.18653/v1/2025.findings-naacl.64)|Minkyoo Song, Hanna Kim, Jaehan Kim, Youngjin Jin, Seungwon Shin|2025-01-01|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/PaperCGBA/CGBA)](https://github.com/PaperCGBA/CGBA)|
|65|[Collaborative Shadows: Distributed Backdoor Attacks in LLM-Based Multi-Agent Systems](https://doi.org/10.48550/arXiv.2510.11246)|Pengyu Zhu, Lijun Li, Yaxing Lyu, Li Sun, Sen Su, Jing Shao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS)](https://github.com/whfeLingYu/Distributed-Backdoor-Attacks-in-MAS)|
|66|[DUP: Detection-guided Unlearning for Backdoor Purification in Language Models](https://doi.org/10.48550/arXiv.2508.01647)|Man Hu, Yahui Ding, Yatao Yang, Liangyu Chen, Yanhao Jia, Shuai Zhao|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/ManHu2025/DUP)](https://github.com/ManHu2025/DUP)|
|67|[Energy Backdoor Attack to Deep Neural Networks](https://doi.org/10.1109/icassp49660.2025.10888330)|Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier D√©forges, Kassem Kallas|2025-01-01|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/hbrachemi/energy_backdoor)](https://github.com/hbrachemi/energy_backdoor)|
|68|[Exploring Backdoor Vulnerabilities of Chat Models](https://aclanthology.org/2025.coling-main.62/)|Wenkai Yang, Yunzhuo Hao, Yankai Lin|2025-01-01|COLING|[![Star](https://img.shields.io/github/stars/hychaochao/Chat-Models-Backdoor-Attacking)](https://github.com/hychaochao/Chat-Models-Backdoor-Attacking)|
|69|[Double Landmines: Invisible Textual Backdoor Attacks based on   Dual-Trigger](https://doi.org/10.1186/s42400-025-00512-z)|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-23|Cybersecurity|[![Star](https://img.shields.io/github/stars/HoyaAm/Double-Landmines)](https://github.com/HoyaAm/Double-Landmines)|
|70|[Gracefully Filtering Backdoor Samples for Generative Large Language   Models without Retraining](https://aclanthology.org/2025.coling-main.220/)|Zongru Wu, Pengzhou Cheng, Lingyong Fang, Zhuosheng Zhang, Gongshen Liu|2024-12-03|COLING|[![Star](https://img.shields.io/github/stars/ZrW00/GraceFul)](https://github.com/ZrW00/GraceFul)|
|71|[BadMerging: Backdoor Attacks Against Model Merging](https://doi.org/10.48550/arXiv.2408.07362)|Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian|2024-12-02|OpenAlex|[![Star](https://img.shields.io/github/stars/jzhang538/BadMerging)](https://github.com/jzhang538/BadMerging)|
|72|[Fisher Information guided Purification against Backdoor Attacks](https://doi.org/10.48550/arXiv.2409.00863)|Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard|2024-12-02|OpenAlex|[![Star](https://img.shields.io/github/stars/nazmul-karim170/FIP-Fisher-Backdoor-Removal)](https://github.com/nazmul-karim170/FIP-Fisher-Backdoor-Removal)|
|73|[Backdoor Attacks against No-Reference Image Quality Assessment Models   via a Scalable Trigger](https://doi.org/10.48550/arXiv.2412.07277)|Yi Yu, Song Xia, Xun Lin, Wenhan Yang, Shijian Lu, Yap‚ÄêPeng Tan, Alex C. Kot|2024-12-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/yuyi-sd/BAIQA)](https://github.com/yuyi-sd/BAIQA)|
|74|[Invisible Textual Backdoor Attacks based on Dual-Trigger](http://arxiv.org/abs/2412.17531v3)|Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou|2024-12-01|arXiv|[![Star](https://img.shields.io/github/stars/HoyaAm/Double-Landmines)](https://github.com/HoyaAm/Double-Landmines)|
|75|[Perturb and Recover: Fine-tuning for Effective Backdoor Removal from   CLIP](https://doi.org/10.48550/arXiv.2412.00727)|Naman Deep Singh, Francesco Croce, Matthias Hein|2024-12-01|arXiv|[![Star](https://img.shields.io/github/stars/nmndeep/PerturbAndRecover)](https://github.com/nmndeep/PerturbAndRecover)|
|76|[T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models](https://doi.org/10.1007/978-3-031-73013-9_7)|Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen|2024-11-26|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/Robin-WZQ/T2IShield)](https://github.com/Robin-WZQ/T2IShield)|
|77|[BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for   Backdoor Defense Evaluation](https://doi.org/10.48550/arXiv.2411.11006)|Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Pengzhou Cheng, Ping Yi, Yue Wu|2024-11-17|OpenAlex|[![Star](https://img.shields.io/github/stars/SJTUHaiyangYu/BackdoorMBTI)](https://github.com/SJTUHaiyangYu/BackdoorMBTI)|
|78|[Your Semantic-Independent Watermark is Fragile: A Semantic Perturbation   Attack against EaaS Watermark](http://arxiv.org/abs/2411.09359v2)|Zekun Fei, Biao Yi, Jianing Geng, Ruiqi He, Lihai Nie, Zheli Liu|2024-11-01|arXiv|[![Star](https://img.shields.io/github/stars/Zk4-ps/EaaS-Embedding-Watermark)](https://github.com/Zk4-ps/EaaS-Embedding-Watermark)|
|79|[Identify Backdoored Model in Federated Learning via Individual   Unlearning](https://doi.org/10.1109/WACV61041.2025.00773)|Jiahao Xu, Zikai Zhang, Rui Hu|2024-11-01|arXiv|[![Star](https://img.shields.io/github/stars/JiiahaoXU/MASA)](https://github.com/JiiahaoXU/MASA)|
|80|[UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening](https://doi.org/10.1007/978-3-031-73033-7_15)|Siyuan Cheng, Guangyu Shen, Kaiyuan Zhang, Guanhong Tao, Shengwei An, Hanxi Guo, Shiqing Ma, Xiangyu Zhang|2024-10-31|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/Megum1/UNIT)](https://github.com/Megum1/UNIT)|
|81|[Mitigating the Backdoor Effect for Multi-Task Model Merging via   Safety-Aware Subspace](https://openreview.net/forum?id=dqMqAaw7Sq)|Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu|2024-10-16|arXiv|[![Star](https://img.shields.io/github/stars/Yangjinluan/DAM)](https://github.com/Yangjinluan/DAM)|
|82|[Adversarially Guided Stateful Defense Against Backdoor Attacks in   Federated Deep Learning](https://doi.org/10.1109/ACSAC63791.2024.00070)|Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay K. Jha|2024-10-01|OpenAlex|[![Star](https://img.shields.io/github/stars/hassanalikhatim/AGSD)](https://github.com/hassanalikhatim/AGSD)|
|83|[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and   Defenses in LLM-based Agents](http://arxiv.org/abs/2410.02644v4)|Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang|2024-10-01|arXiv|[![Star](https://img.shields.io/github/stars/agiresearch/ASB)](https://github.com/agiresearch/ASB)|
|84|[Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via   Exposed Models](https://doi.org/10.48550/arXiv.2410.19427)|Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang|2024-10-01|arXiv|[![Star](https://img.shields.io/github/stars/bboylyg/Expose-Before-You-Defend)](https://github.com/bboylyg/Expose-Before-You-Defend)|
|85|[Event Trojan: Asynchronous Event-Based Backdoor Attacks](https://doi.org/10.1007/978-3-031-72667-5_18)|Ruofei Wang, Qing Guo, Haoliang Li, Renjie Wan|2024-09-28|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/rfww/EventTrojan)](https://github.com/rfww/EventTrojan)|
|86|[Mask-Based Invisible Backdoor Attacks on Object Detection](https://doi.org/10.36227/techrxiv.171440796.64142276/v1)|Shin Jeong Jin|2024-09-27|2022 IEEE International Conference on Image Processing (ICIP)|[![Star](https://img.shields.io/github/stars/jeongjin0/invisible-backdoor-object-detection)](https://github.com/jeongjin0/invisible-backdoor-object-detection)|
|87|[Obliviate: Neutralizing Task-agnostic Backdoors within the   Parameter-efficient Fine-tuning Paradigm](https://doi.org/10.18653/v1/2025.findings-naacl.71)|Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin|2024-09-21|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/obliviateARR/Obliviate)](https://github.com/obliviateARR/Obliviate)|
|88|[TERD: A Unified Framework for Safeguarding Diffusion Models Against   Backdoors](https://openreview.net/forum?id=lpHjmPvxW1)|Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, Yisen Wang|2024-09-08|International Conference on Machine Learning 2024|[![Star](https://img.shields.io/github/stars/PKU-ML/TERD)](https://github.com/PKU-ML/TERD)|
|89|[NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack   Through White Gaussian Noise](https://doi.org/10.48550/arXiv.2409.02251)|Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi|2024-09-03|arXiv|[![Star](https://img.shields.io/github/stars/SiSL-URI/NoiseAttack)](https://github.com/SiSL-URI/NoiseAttack)|
|90|[Exploiting the Vulnerability of Large Language Models via Defense-Aware   Architectural Backdoor](https://doi.org/10.48550/arXiv.2409.01952)|Abdullah Arafat Miah, Yu Bi|2024-09-03|arXiv|[![Star](https://img.shields.io/github/stars/SiSL-URI/Arch_Backdoor_LLM)](https://github.com/SiSL-URI/Arch_Backdoor_LLM)|
|91|[Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual   Perturbations Against Backdoor Attacks](https://doi.org/10.48550/arXiv.2408.15721)|Oscar Chew, Po-Yi Lu, Jayden Lin, Hsuan-Tien Lin|2024-08-28|arXiv|[![Star](https://img.shields.io/github/stars/oscarchew/t2i-backdoor-defense)](https://github.com/oscarchew/t2i-backdoor-defense)|
|92|[VFLIP: A Backdoor Defense for Vertical Federated Learning via   Identification and Purification](https://doi.org/10.1007/978-3-031-70903-6_15)|Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek|2024-08-28|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/blingcho/VFLIP-esorics24)](https://github.com/blingcho/VFLIP-esorics24)|
|93|[MakeupAttack: Feature Space Black-box Backdoor Attack on Face   Recognition via Makeup Transfer](https://doi.org/10.48550/arXiv.2408.12312)|Ming Sun, Lihua Jing, Zixuan Zhu, Rui Wang|2024-08-22|Frontiers in artificial intelligence and applications|[![Star](https://img.shields.io/github/stars/AaronSun2000/MakeupAttack)](https://github.com/AaronSun2000/MakeupAttack)|
|94|[MEGen: Generative Backdoor into Large Language Models via Model Editing](https://doi.org/10.18653/v1/2025.findings-acl.584)|Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao, Yun Li, Qianren Wang|2024-08-20|Findings of the Association for Computational Linguistics: ACL 2022|[![Star](https://img.shields.io/github/stars/MonoQ-hub/MEGen)](https://github.com/MonoQ-hub/MEGen)|
|95|[BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses   on Large Language Models](https://ink.library.smu.edu.sg/sis_research/10422)|Li Yige, Huang, Hanxun, Zhao Yunhan, Ma, Xingjun, Sun Jun|2024-08-01|Singapore Management University Institutional Knowledge (InK) (Singapore Management University)|[![Star](https://img.shields.io/github/stars/bboylyg/BackdoorLLM)](https://github.com/bboylyg/BackdoorLLM)|
|96|[Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion   Models](https://doi.org/10.1109/ICME59968.2025.11210014)|Hao Jiang, Jin Xiao, Xiaoguang Hu, Chen Tianyou, Zhao Jiajia|2024-07-30|ICME|[![Star](https://img.shields.io/github/stars/shymuel/diff-cleanse)](https://github.com/shymuel/diff-cleanse)|
|97|[BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor   Learning](http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html)|Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen|2024-07-29|International Journal of Computer Vision|[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/backdoorbench-a-comprehensive-benchmark-of/code)|
|98|[Flatness-aware Sequential Learning Generates Resilient Backdoors](https://doi.org/10.1007/978-3-031-73021-4_6)|Hoang N. Pham, The-Anh Ta, Anh Tran, Khoa D. Doan|2024-07-19|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/mail-research/SBL-resilient-backdoors)](https://github.com/mail-research/SBL-resilient-backdoors)|
|99|[Provable Robustness of (Graph) Neural Networks Against Data Poisoning   and Backdoor Attacks](https://openreview.net/forum?id=jIAPLDdGVx)|Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan G√ºnnemann|2024-07-15|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/saper0/qpcert)](https://github.com/saper0/qpcert)|
|100|[Distributed Backdoor Attacks on Federated Graph Learning and Certified   Defenses](https://doi.org/10.48550/arXiv.2407.08935)|Yuxin Yang, Qiang Li, Jinyuan Jia, Yuan Hong, Binghui Wang|2024-07-11|OpenAlex|[![Star](https://img.shields.io/github/stars/Yuxin104/Opt-GDBA)](https://github.com/Yuxin104/Opt-GDBA)|
|101|[Future Events as Backdoor Triggers: Investigating Temporal   Vulnerabilities in LLMs](https://doi.org/10.48550/arXiv.2407.04108)|Sara Price, Arjun Panickssery, Samuel R. Bowman, Asa Cooper Stickland|2024-07-04|arXiv|[![Star](https://img.shields.io/github/stars/sbp354/Future_triggered_backdoors)](https://github.com/sbp354/Future_triggered_backdoors)|
|102|[IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields](http://arxiv.org/abs/2407.11921v2)|Wenxiang Jiang, Hanwei Zhang, Shuo Zhao, Zhongwen Guo, Hao Wang|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/jiang-wenxiang/IPA-NeRF)](https://github.com/jiang-wenxiang/IPA-NeRF)|
|103|[Towards Clean-Label Backdoor Attacks in the Physical World](https://doi.org/10.48550/arXiv.2407.19203)|Thinh Dao, Cuong Phan Minh Le, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/21thinh/Clean-Label-Physical-Backdoor-Attacks)](https://github.com/21thinh/Clean-Label-Physical-Backdoor-Attacks)|
|104|[ShadowCode: Towards (Automatic) External Prompt Injection Attack against   Code LLMs](http://arxiv.org/abs/2407.09164v6)|Yuchen Yang, Yiming Li, Hongwei Yao, Bingrun Yang, Yiling He, Tianwei Zhang, Dacheng Tao, Zhan Qin|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/LianPing-cyber/ShadowCodeEPI)](https://github.com/LianPing-cyber/ShadowCodeEPI)|
|105|[Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks   in Federated Learning](https://doi.org/10.48550/arXiv.2407.03144)|Son Nguyen, Thinh Viet Nguyen, Khoa D. Doan, Kok‚ÄêSeng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/nguyenhongson1902/Venomancer)](https://github.com/nguyenhongson1902/Venomancer)|
|106|[Defending Against Repetitive-based Backdoor Attacks on Semi-supervised   Learning through Lens of Rate-Distortion-Perception Trade-off](https://doi.org/10.1109/WACV61041.2025.00630)|Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu, Chu-Song Chen|2024-07-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/chengyi-chris/UPure)](https://github.com/chengyi-chris/UPure)|
|107|[Clean-Label Physical Backdoor Attacks with Data Distillation](http://arxiv.org/abs/2407.19203v4)|Thinh Dao, Khoa D Doan, Kok-Seng Wong|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/thinh-dao/Clean-Label-Physical-Backdoor-Attacks)](https://github.com/thinh-dao/Clean-Label-Physical-Backdoor-Attacks)|
|108|[Backdoor Graph Condensation](https://doi.org/10.1109/ICDE65448.2025.00172)|Jiahao Wu, Ning Lu, Zeiyu Dai, Kun Wang, Wenqi Fan, Shengcai Liu, Qing Li, Ke Tang|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/JiahaoWuGit/BGC)](https://github.com/JiahaoWuGit/BGC)|
|109|[A Whole-Process Certifiably Robust Aggregation Method Against Backdoor   Attacks in Federated Learning](https://doi.org/10.48550/arXiv.2407.00719)|Anqi Zhou, Yezheng Liu, Yidong Chai, Hongyi Zhu, Xinyue Ge, Yuanchun Jiang, Meng Wang|2024-06-30|arXiv|[![Star](https://img.shields.io/github/stars/brick-brick/WPCRAM)](https://github.com/brick-brick/WPCRAM)|
|110|[Lotus: Evasive and Resilient Backdoor Attacks through Sub-Partitioning](https://doi.org/10.1109/cvpr52733.2024.02342)|Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, ...|2024-06-16|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/Megum1/LOTUS)](https://github.com/Megum1/LOTUS)|
|111|[BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](https://doi.org/10.18653/v1/2024.acl-long.530)|Yifei Wang, Dizhan Xue, Shengjie Zhang, Shengsheng Qian|2024-06-05|OpenAlex|[![Star](https://img.shields.io/github/stars/DPamK/BadAgent)](https://github.com/DPamK/BadAgent)|
|112|[Invisible Backdoor Attacks on Diffusion Models](https://doi.org/10.48550/arXiv.2406.00816)|Sen Li, Junchi Ma, Minhao Cheng|2024-06-02|arXiv|[![Star](https://img.shields.io/github/stars/invisibleTriggerDiffusion/invisible_triggers_for_diffusion)](https://github.com/invisibleTriggerDiffusion/invisible_triggers_for_diffusion)|
|113|[Let the Noise Speak: Harnessing Noise for a Unified Defense Against   Adversarial and Backdoor Attacks](https://doi.org/10.1007/978-3-032-07884-1_19)|Md Hasan Shahriar, Ning Wang, Naren Ramakrishnan, Y. Thomas Hou, Wenjing Lou|2024-06-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/shahriar0651/NoiSec)](https://github.com/shahriar0651/NoiSec)|
|114|[BAN: Detecting Backdoors Activated by Adversarial Neuron Noise](http://papers.nips.cc/paper_files/paper/2024/hash/cfaccbd9b5e62562779351ebcb140c94-Abstract-Conference.html)|Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek|2024-05-30|NeurIPS|[![Star](https://img.shields.io/github/stars/xiaoyunxxy/ban)](https://github.com/xiaoyunxxy/ban)|
|115|[Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor](http://papers.nips.cc/paper_files/paper/2024/hash/9374af323abb65ce551168d44b09ad5f-Abstract-Conference.html)|Shaokui Wei, Hongyuan Zha, Baoyuan Wu|2024-05-25|NeurIPS|[![Star](https://img.shields.io/github/stars/shawkui/Proactive_Defensive_Backdoor)](https://github.com/shawkui/Proactive_Defensive_Backdoor)|
|116|[Towards Imperceptible Backdoor Attack in Self-supervised Learning](https://doi.org/10.48550/arXiv.2405.14672)|Hanrong Zhang, Zhenting Wang, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma|2024-05-23|arXiv|[![Star](https://img.shields.io/github/stars/Zhang-Henry/IMPERATIVE)](https://github.com/Zhang-Henry/IMPERATIVE)|
|117|[IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling   Consistency](https://openreview.net/forum?id=YCzbfs2few)|Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li|2024-05-15|ICML|[![Star](https://img.shields.io/github/stars/THUYimingLi/BackdoorBox)](https://github.com/THUYimingLi/BackdoorBox)|
|118|[EmInspector: Combating Backdoor Attacks in Federated Self-Supervised   Learning Through Embedding Inspection](https://doi.org/10.48550/arXiv.2405.13080)|Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo|2024-05-01|arXiv|[![Star](https://img.shields.io/github/stars/ShuchiWu/EmInspector)](https://github.com/ShuchiWu/EmInspector)|
|119|[Not All Prompts Are Secure: A Switchable Backdoor Attack Against   Pre-trained Vision Transformers](https://doi.org/10.1109/CVPR52733.2024.02306)|Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/20000yshust/SWARM)](https://github.com/20000yshust/SWARM)|
|120|[Nearest is Not Dearest: Towards Practical Defense against   Quantization-conditioned Backdoor Attacks](https://doi.org/10.1109/CVPR52733.2024.02315)|Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li|2024-05-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/AntigoneRandy/QuantBackdoor_EFRAP)](https://github.com/AntigoneRandy/QuantBackdoor_EFRAP)|
|121|[Beyond Traditional Threats: A Persistent Backdoor Attack on Federated   Learning](https://doi.org/10.1609/aaai.v38i19.30131)|Tao Liu, Yuhang Zhang, Feng Zhu, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang|2024-04-26||[![Star](https://img.shields.io/github/stars/PhD-TaoLiu/FCBA)](https://github.com/PhD-TaoLiu/FCBA)|
|122|[Privacy Backdoors: Stealing Data with Corrupted Pretrained Models](https://openreview.net/forum?id=7yixJXmzb8)|Shanglun Feng, Florian Tram√®r|2024-03-30|ICML|[![Star](https://img.shields.io/github/stars/ShanglunFengatETHZ/PrivacyBackdoor)](https://github.com/ShanglunFengatETHZ/PrivacyBackdoor)|
|123|[Generating Potent Poisons and Backdoors from Scratch with Guided   Diffusion](https://doi.org/10.48550/arXiv.2403.16365)|Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellapp...|2024-03-24|arXiv|[![Star](https://img.shields.io/github/stars/hsouri/GDP)](https://github.com/hsouri/GDP)|
|124|[Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain](https://doi.org/10.1609/aaai.v38i19.30099)|Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/f-lk/IBAPC)](https://github.com/f-lk/IBAPC)|
|125|[Progressive Poisoned Data Isolation for Training-Time Backdoor Defense](https://doi.org/10.1609/aaai.v38i10.29023)|Yiming Chen, Haiwei Wu, Jiantao Zhou|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/RorschachChen/PIPD)](https://github.com/RorschachChen/PIPD.git)|
|126|[COMBAT: Alternated Training for Near-Perfect Clean-Label Backdoor Attacks](https://openreview.net/pdf/c182fdd518fe8ec0aeafeb8d1b2b55bb8e46a463.pdf)|Tran Ngoc Huynh, Dang Minh Nguyen, Tung Pham, Anh Tuan Tran|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/VinAIResearch/COMBAT)](https://github.com/VinAIResearch/COMBAT)|
|127|[BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning](https://doi.org/10.1609/aaai.v38i10.29052)|Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang|2024-03-24|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/7777777cc/code)](https://github.com/7777777cc/code)|
|128|[An Embarrassingly Simple Defense Against Backdoor Attacks On SSL](https://doi.org/10.48550/arXiv.2403.15918)|Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade|2024-03-23|arXiv|[![Star](https://img.shields.io/github/stars/Aryan-Satpathy/Backdoor)](https://github.com/Aryan-Satpathy/Backdoor)|
|129|[PoisonPrompt: Backdoor Attack on Prompt-Based Large Language Models](https://doi.org/10.1109/icassp48485.2024.10446267)|Hongwei Yao, Jian Lou, Zhan Qin|2024-03-18|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/grasses/PoisonPrompt)](https://github.com/grasses/PoisonPrompt)|
|130|[Invisible Black-Box Backdoor Attack against Deep Cross-Modal Hashing Retrieval](https://doi.org/10.1145/3650205)|Tianshi Wang, Fengling Li, Lei Zhu, Jingjing Li, Zheng Zhang, Heng Tao Shen|2024-03-02|ACM transactions on office information systems|[![Star](https://img.shields.io/github/stars/tswang0116/IB3A)](https://github.com/tswang0116/IB3A)|
|131|[Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized   Scaled Prediction Consistency](https://openreview.net/forum?id=1OfAO2mes1)|Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu|2024-03-01|ICLR|[![Star](https://img.shields.io/github/stars/OPTML-Group/BackdoorMSPC)](https://github.com/OPTML-Group/BackdoorMSPC)|
|132|[BapFL: You can Backdoor Personalized Federated Learning](https://doi.org/10.1145/3649316)|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2024-02-23|ACM Transactions on Knowledge Discovery from Data|[![Star](https://img.shields.io/github/stars/BapFL/code)](https://github.com/BapFL/code)|
|133|[Acquiring Clean Language Models from Backdoor Poisoned Datasets by   Downscaling Frequency Space](https://openreview.net/pdf/9eb71f0c75e3630c53671cf8b0175e95463726f1.pdf)|Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu|2024-02-19|OpenReview|[![Star](https://img.shields.io/github/stars/ZrW00/MuScleLoRA)](https://github.com/ZrW00/MuScleLoRA)|
|134|[Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery   Detection](https://openreview.net/forum?id=8iTpB4RNvP)|Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao|2024-02-18|ICLR|[![Star](https://img.shields.io/github/stars/JWLiang007/PFF)](https://github.com/JWLiang007/PFF)|
|135|[Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based   Agents](http://papers.nips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html)|Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun|2024-02-17|NeurIPS|[![Star](https://img.shields.io/github/stars/lancopku/agent-backdoor-attacks)](https://github.com/lancopku/agent-backdoor-attacks)|
|136|[OrderBkd: Textual backdoor attack through repositioning](https://doi.org/10.1109/ispras60948.2023.10508175)|Irina Alekseevskaia, Konstantin Arkhipenko|2024-02-12|OpenAlex|[![Star](https://img.shields.io/github/stars/alekseevskaia/OrderBkd)](https://github.com/alekseevskaia/OrderBkd)|
|137|[Backdoor Attacks on Dense Retrieval via Public and Unintentional   Triggers](http://arxiv.org/abs/2402.13532v3)|Quanyu Long, Yue Deng, LeiLei Gan, Wenya Wang, Sinno Jialin Pan|2024-02-01|arXiv|[![Star](https://img.shields.io/github/stars/ruyue0001/Backdoor_DPR)](https://github.com/ruyue0001/Backdoor_DPR)|
|138|[SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via   Syntactic Transfer](https://doi.org/10.18653/v1/2025.findings-naacl.196)|Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Zhuosheng Zhang, Gongshen Liu|2024-02-01|Findings of the Association for Computational Linguistics: NAACL 2022|[![Star](https://img.shields.io/github/stars/Zhou-CyberSecurity-AI/SynGhost)](https://github.com/Zhou-CyberSecurity-AI/SynGhost)|
|139|[TransTroj: Transferable Backdoor Attacks to Pre-trained Models via   Embedding Indistinguishability](https://doi.org/10.48550/arXiv.2401.15883)|Hao Wang, Tao Xiang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang|2024-01-28|arXiv|[![Star](https://img.shields.io/github/stars/haowang-cqu/TransTroj)](https://github.com/haowang-cqu/TransTroj)|
|140|[A Closer Look at Robustness of Vision Transformers to Backdoor Attacks](https://doi.org/10.1109/wacv57701.2024.00383)|Akshayvarun Subramanya, Soroush Abbasi Koohpayegani, Aniruddha Saha, Ajinkya Tejankar, Hamed Pirsiavash|2024-01-03|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/UCDvision/backdoor_transformer)](https://github.com/UCDvision/backdoor_transformer.git)|
|141|[How to Craft Backdoors with Unlabeled Data Alone?](https://doi.org/10.48550/arXiv.2404.06694)|Yifei Wang, Wenhan Ma, Stefanie Jegelka, Yisen Wang|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/PKU-ML/nlb)](https://github.com/PKU-ML/nlb)|
|142|[Toward Stealthy Backdoor Attacks Against Speech Recognition via Elements of Sound](https://doi.org/10.1109/tifs.2024.3404885)|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2024-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/HanboCai/BadSpeech_SoE)](https://github.com/HanboCai/BadSpeech_SoE)|
|143|[Shortcuts Everywhere and Nowhere: Exploring Multi-Trigger Backdoor   Attacks](http://arxiv.org/abs/2401.15295v3)|Yige Li, Jiabo He, Hanxun Huang, Jun Sun, Xingjun Ma, Yu-Gang Jiang|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/bboylyg/Multi-Trigger-Backdoor-Attacks)](https://github.com/bboylyg/Multi-Trigger-Backdoor-Attacks)|
|144|[PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection](https://openaccess.thecvf.com/content/CVPR2025/html/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.html)|Wei Li, Pin-Yu Chen, Sijia Liu, Ren Wang|2024-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/WL-619/PSBD)](https://github.com/WL-619/PSBD)|
|145|[PBP: Post-training Backdoor Purification for Malware Classifiers](https://www.ndss-symposium.org/ndss-paper/pbp-post-training-backdoor-purification-for-malware-classifiers/)|Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach|2024-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/judydnguyen/pbp-backdoor-purification-official)](https://github.com/judydnguyen/pbp-backdoor-purification-official)|
|146|[Model Supply Chain Poisoning: Backdooring Pre-trained Models via   Embedding Indistinguishability](https://doi.org/10.1145/3696410.3714624)|Hao Wang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang, Tao Xiang|2024-01-01|WWW|[![Star](https://img.shields.io/github/stars/haowang-cqu/TransTroj)](https://github.com/haowang-cqu/TransTroj)|
|147|[How to Backdoor Consistency Models?](https://doi.org/10.1007/978-981-96-8295-9_23)|Chengen Wang, Murat Kantarcioglu|2024-01-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/chengenw/backdoorCM)](https://github.com/chengenw/backdoorCM)|
|148|[Defending Against Backdoor Attacks by Quarantine Training](https://doi.org/10.1109/access.2024.3354385)|Chengxu Yu, Yulai Zhang|2024-01-01|IEEE Access|[![Star](https://img.shields.io/github/stars/Chengx-Yu/Quarantine-Training)](https://github.com/Chengx-Yu/Quarantine-Training)|
|149|[BadCM: Invisible Backdoor Attack Against Cross-Modal Learning](https://doi.org/10.48550/arXiv.2410.02182)|Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie|2024-01-01||[![Star](https://img.shields.io/github/stars/xandery-geek/BadCM)](https://github.com/xandery-geek/BadCM)|
|150|[Backdoor Contrastive Learning via Bi-level Trigger Optimization](https://openreview.net/forum?id=oxjeePpgSP)|Weiyu Sun, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, Jinghui Chen, Lu Lin|2024-01-01|ICLR|[![Star](https://img.shields.io/github/stars/SWY666/SSL-backdoor-BLTO)](https://github.com/SWY666/SSL-backdoor-BLTO)|
|151|[BackTime: Backdoor Attacks on Multivariate Time Series Forecasting](http://papers.nips.cc/paper_files/paper/2024/hash/ed3cd2520148b577039adfade82a5566-Abstract-Conference.html)|Xiaola Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong|2024-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/xiaolin-cs/BackTime)](https://github.com/xiaolin-cs/BackTime)|
|152|[Adversarial Feature Map Pruning for Backdoor](https://openreview.net/forum?id=IOEEDkla96)|Dong Huang, Qingwen Bu|2024-01-01|ICLR|[![Star](https://img.shields.io/github/stars/retsuh-bqw/FMP)](https://github.com/retsuh-bqw/FMP)|
|153|[OCGEC: One-class Graph Embedding Classification for DNN Backdoor   Detection](https://doi.org/10.1109/ijcnn60899.2024.10650468)|Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi|2023-12-01|2022 International Joint Conference on Neural Networks (IJCNN)|[![Star](https://img.shields.io/github/stars/jhy549/OCGEC)](https://github.com/jhy549/OCGEC)|
|154|[UltraClean: A Simple Framework to Train Robust Neural Networks against   Backdoor Attacks](https://doi.org/10.48550/arXiv.2312.10657)|Bingyin Zhao, Yingjie Lao|2023-12-01|arXiv|[![Star](https://img.shields.io/github/stars/bxz9200/UltraClean)](https://github.com/bxz9200/UltraClean)|
|155|[A Practical Clean-Label Backdoor Attack with Limited Information in Vertical Federated Learning](https://doi.org/10.1109/icdm58522.2023.00013)|Peng Chen, Jirui Yang, Junxiong Lin, Zhihui Lu, Qiang Duan, Hongfeng Chai|2023-12-01|2021 IEEE International Conference on Data Mining (ICDM)|[![Star](https://img.shields.io/github/stars/13thDayOLunarMay/TECB-attack)](https://github.com/13thDayOLunarMay/TECB-attack)|
|156|[Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking](https://doi.org/10.48550/arXiv.2312.07955)|Shengsheng Qian, Dizhan Xue, Yifei Wang, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu|2023-12-01|arXiv|[![Star](https://img.shields.io/github/stars/LivXue/PoisonCAM)](https://github.com/LivXue/PoisonCAM)|
|157|[Activation Gradient based Poisoned Sample Detection Against Backdoor   Attacks](https://openreview.net/forum?id=VNMJfBBUd5)|Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu|2023-12-01|ICLR|[![Star](https://img.shields.io/github/stars/SCLBD/bdzoo2)](https://github.com/SCLBD/bdzoo2)|
|158|[TextGuard: Provable Defense against Backdoor Attacks on Text   Classification](https://www.ndss-symposium.org/ndss-paper/textguard-provable-defense-against-backdoor-attacks-on-text-classification/)|Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song|2023-11-01|OpenAlex|[![Star](https://img.shields.io/github/stars/AI-secure/TextGuard)](https://github.com/AI-secure/TextGuard)|
|159|[ACQ: Few-shot Backdoor Defense via Activation Clipping and Quantizing](https://doi.org/10.1145/3581783.3612410)|Yulin Jin, Xiaoyu Zhang, Jian Lou, Xiaofeng Chen|2023-10-26|ACM Multimedia|[![Star](https://img.shields.io/github/stars/Backdoor-defense/ACQ)](https://github.com/Backdoor-defense/ACQ)|
|160|[Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks](https://doi.org/10.1145/3583780.3614784)|Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu|2023-10-21|OpenAlex|[![Star](https://img.shields.io/github/stars/GuanZihan/Deep-Backdoor-Attack)](https://github.com/GuanZihan/Deep-Backdoor-Attack)|
|161|[An Embarrassingly Simple Backdoor Attack on Self-supervised Learning](https://doi.org/10.1109/iccv51070.2023.00403)|Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/meet-cjli/CTRL)](https://github.com/meet-cjli/CTRL)|
|162|[Computation and Data Efficient Backdoor Attacks](https://doi.org/10.1109/iccv51070.2023.00443)|Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang|2023-10-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/WU-YU-TONG/computational_efficient_backdoor)](https://github.com/WU-YU-TONG/computational_efficient_backdoor)|
|163|[FLTracer: Accurate Poisoning Attack Provenance in Federated Learning](http://arxiv.org/abs/2310.13424v1)|Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren|2023-10-01|arXiv|[![Star](https://img.shields.io/github/stars/Eyr3/FLTracer)](https://github.com/Eyr3/FLTracer)|
|164|[XGBD: Explanation-Guided Graph Backdoor Detection](https://doi.org/10.48550/arXiv.2308.04406)|Zihan Guan, Mengnan Du, Ninghao Liu|2023-09-28|Frontiers in artificial intelligence and applications|[![Star](https://img.shields.io/github/stars/GuanZihan/GNN_backdoor_detection)](https://github.com/GuanZihan/GNN_backdoor_detection)|
|165|[Resisting Backdoor Attacks in Federated Learning via Bidirectional   Elections and Individual Perspective](https://doi.org/10.48550/arXiv.2309.16456)|Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng|2023-09-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/zhenqincn/Snowball)](https://github.com/zhenqincn/Snowball)|
|166|[TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal   Backdoored Models](https://doi.org/10.1109/iccv51070.2023.00022)|Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha|2023-08-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/SRI-CSL/TIJO)](https://github.com/SRI-CSL/TIJO)|
|167|[Towards Stealthy Backdoor Attacks against Speech Recognition via   Elements of Sound](https://doi.org/10.48550/arXiv.2307.08208)|Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li|2023-07-01|arXiv|[![Star](https://img.shields.io/github/stars/HanboCai/BadSpeech_SoE)](https://github.com/HanboCai/BadSpeech_SoE)|
|168|[Detecting Backdoors in Pre-trained Encoders](https://doi.org/10.1109/cvpr52729.2023.01569)|Shiwei Feng, Guanhong Tao, Siyuan Cheng, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/GiantSeaweed/DECREE)](https://github.com/GiantSeaweed/DECREE)|
|169|[VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion   Models](http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html)|Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho|2023-06-01|NeurIPS|[![Star](https://img.shields.io/github/stars/IBM/villandiffusion)](https://github.com/IBM/villandiffusion)|
|170|[Single Image Backdoor Inversion via Robust Smoothed Classifiers](https://doi.org/10.1109/cvpr52729.2023.00784)|Mingjie Sun, J. Zico Kolter|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/locuslab/smoothinv)](https://github.com/locuslab/smoothinv)|
|171|[Efficient Backdoor Attacks for Deep Neural Networks in Real-world   Scenarios](https://openreview.net/forum?id=vRyp2dhEQp)|Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li|2023-06-01|arXiv|[![Star](https://img.shields.io/github/stars/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios)](https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios)|
|172|[DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via   Restricted Adversarial Distillation](https://doi.org/10.48550/arXiv.2306.08009)|Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao|2023-06-01|OpenAlex|[![Star](https://img.shields.io/github/stars/yanzhicong/DHBE)](https://github.com/yanzhicong/DHBE)|
|173|[Backdoor Cleansing with Unlabeled Data](https://openreview.nethttps://arxiv.org/pdf/2211.12044)|Lu Pang, Tong Sun, Haibin Ling, Chao Chen|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/luluppang/BCU)](https://github.com/luluppang/BCU)|
|174|[Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated   Graph Neural Network](https://doi.org/10.1007/978-3-032-05981-9_22)|Fan Liu, Siqi Lai, Yansong Ning, Hao Liu|2023-06-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/usail-hkust/BkdFedGCN)](https://github.com/usail-hkust/BkdFedGCN)|
|175|[Backdoor Defense via Deconfounded Representation Learning](https://doi.org/10.1109/cvpr52729.2023.01177)|Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu|2023-06-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/zaixizhang/CBD)](https://github.com/zaixizhang/CBD)|
|176|[An Empirical Study of Backdoor Attacks on Masked Auto Encoders](https://doi.org/10.1109/icassp49357.2023.10095201)|Shuli Zhuang, Pengfei Xia, Bin Li|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/zhuangshuli/MAE-Backdoor)](https://github.com/zhuangshuli/MAE-Backdoor)|
|177|[Going in Style: Audio Backdoors Through Stylistic Transformations](https://doi.org/10.1109/icassp49357.2023.10096332)|Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti|2023-05-05|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/skoffas/going-in-style)](https://github.com/skoffas/going-in-style)|
|178|[Text-to-Image Diffusion Models can be Easily Backdoored through   Multimodal Data Poisoning](https://doi.org/10.48550/arXiv.2305.04175)|Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su|2023-05-01|ACM Multimedia|[![Star](https://img.shields.io/github/stars/sf-zhai/BadT2I)](https://github.com/sf-zhai/BadT2I)|
|179|[Training-free Lexical Backdoor Attacks on Language Models](https://doi.org/10.48550/arXiv.2302.04116)|Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen|2023-04-26|Proceedings of the ACM Web Conference 2022|[![Star](https://img.shields.io/github/stars/Jinxhy/TFLexAttack)](https://github.com/Jinxhy/TFLexAttack)|
|180|[Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware   Minimization](https://doi.org/10.1109/iccv51070.2023.00412)|Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu|2023-04-01|2021 IEEE/CVF International Conference on Computer Vision (ICCV)|[![Star](https://img.shields.io/github/stars/SCLBD/BackdoorBench)](https://github.com/SCLBD/BackdoorBench)|
|181|[Defending Against Patch-based Backdoor Attacks on Self-Supervised   Learning](https://doi.org/10.1109/cvpr52729.2023.01178)|Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan|2023-04-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/UCDvision/PatchSearch)](https://github.com/UCDvision/PatchSearch)|
|182|[Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection](https://doi.org/10.1109/tcss.2023.3260833)|Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen|2023-03-30|IEEE Transactions on Computational Social Systems|[![Star](https://img.shields.io/github/stars/Seaocn/Link-Backdoor)](https://github.com/Seaocn/Link-Backdoor)|
|183|[AdaptGuard: Defending Against Universal Attacks for Model Adaptation](http://arxiv.org/abs/2303.10594v2)|Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan|2023-03-01|arXiv|[![Star](https://img.shields.io/github/stars/TomSheng21/AdaptGuard)](https://github.com/TomSheng21/AdaptGuard)|
|184|[Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based   Artificial Bias](https://doi.org/10.1109/tcsvt.2025.3548657)|Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu|2023-03-01|IEEE Transactions on Circuits and Systems for Video Technology|[![Star](https://img.shields.io/github/stars/KirinNg/DBA)](https://github.com/KirinNg/DBA)|
|185|[CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive   Learning](https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf)|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023-03-01|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|
|186|[Detecting Backdoors During the Inference Stage Based on Corruption   Robustness Consistency](https://doi.org/10.1109/cvpr52729.2023.01570)|Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao|2023-03-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/CGCL-codes/TeCo)](https://github.com/CGCL-codes/TeCo)|
|187|[Mask and Restore: Blind Backdoor Defense at Test Time with Masked   Autoencoder](https://doi.org/10.48550/arXiv.2303.15564)|Tao Sun, Lu Pang, Weimin Lyu, Chao Chen, Haibin Ling|2023-03-01|arXiv|[![Star](https://img.shields.io/github/stars/tsun/BDMAE)](https://github.com/tsun/BDMAE)|
|188|[Revisiting Personalized Federated Learning: Robustness Against Backdoor   Attacks](https://openreview.nethttps://arxiv.org/pdf/2302.01677.pdf)|Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng|2023-02-01|Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining|[![Star](https://img.shields.io/github/stars/alibaba/FederatedScope)](https://github.com/alibaba/FederatedScope)|
|189|[TrojText: Test-time Invisible Textual Trojan Insertion](https://openreview.net/pdf/090c1fa0cc728fa6eb032fe3c74b8b5125be7e94.pdf)|Qian Lou, Yepeng Liu, Bo Feng|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/trojtext-test-time-invisible-textual-trojan/code)|
|190|[SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via   Analyzing Scaled Prediction Consistency](https://openreview.net/pdf/341ae2d07a7459242b24bb6e6ff7e2aec7a756e1.pdf)|Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu|2023-02-01|ICLR 2023 poster|[![Star](https://img.shields.io/github/stars/JunfengGo/SCALE-UP)](https://github.com/JunfengGo/SCALE-UP)|
|191|[Towards Robust Model Watermark via Reducing Parametric Vulnerability](https://openreview.net/pdf/c3ea0d03202ba1e2fbf2a003a936364bb447ce98.pdf)|Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia|2023-02-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/towards-robust-model-watermark-via-reducing/code)|
|192|[Backdoor Learning for NLP: Recent Advances, Challenges, and Future   Research Directions](https://doi.org/10.48550/arXiv.2302.06801)|Marwan Omar|2023-02-01|arXiv|[![Star](https://img.shields.io/github/stars/marwanomar1/Backdoor-Learning-for-NLP)](https://github.com/marwanomar1/Backdoor-Learning-for-NLP)|
|193|[ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep   Learning Paradigms](https://www.usenix.org/conference/usenixsecurity23/presentation/pan)|Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia|2023-02-01|USENIX Security Symposium|[![Star](https://img.shields.io/github/stars/ruoxi-jia-group/ASSET)](https://github.com/ruoxi-jia-group/ASSET)|
|194|[Backdoor Attacks on Time Series: A Generative Approach](https://openreview.net/pdf/b15b1e53dab0744f34198d60d727ddab895c8074.pdf)|Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey|2023-02-01|SaTML 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/backdoor-attacks-on-time-series-a-generative/code)|
|195|[Learning to Backdoor Federated Learning](https://openreview.net/pdf/b3222725885adf97fe0f200feabe9bbd3df94344.pdf)|Henger Li, Wu Chen, Senchun Zhu, Zizhan Zheng|2023-01-01|ICLR 2023 BANDS Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learning-to-backdoor-federated-learning/code)|
|196|[You Can Backdoor Personalized Federated Learning](https://doi.org/10.48550/arXiv.2307.15971)|Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao|2023-01-01|ACM Trans. Knowl. Discov. Data 2024|[![Star](https://img.shields.io/github/stars/BapFL/code)](https://github.com/BapFL/code)|
|197|[Universal Backdoor Attacks](https://openreview.net/forum?id=3QkzYBSWqL)|Benjamin Schneider, Nils Lukas, Florian Kerschbaum|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Ben-Schneider-code/Universal-Backdoor-Attacks)](https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks)|
|198|[UNICORN: A Unified Backdoor Trigger Inversion Framework](https://openreview.net/pdf/edd35173abda536a0bd486d49c34c8ce04e56652.pdf)|Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma|2023-01-01|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unicorn-a-unified-backdoor-trigger-inversion/code)|
|199|[Towards Stable Backdoor Purification through Feature Shift Tuning](http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html)|Rui Min, Zeyu Qin, Li Shen, Minhao Cheng|2023-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/AISafety-HKUST/stable_backdoor_purification)](https://github.com/AISafety-HKUST/stable_backdoor_purification)|
|200|[The &quot;Beatrix&quot; Resurrections: Robust Backdoor Detection via Gram Matrices](https://www.ndss-symposium.org/ndss-paper/the-beatrix-resurrections-robust-backdoor-detection-via-gram-matrices/)|Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang|2023-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/wanlunsec/Beatrix)](https://github.com/wanlunsec/Beatrix)|
|201|[RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks](https://doi.org/10.48550/arXiv.2302.09420)|Marwan Omar|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/marwanomar1/Backdoor-Learning-for-NLP)](https://github.com/marwanomar1/Backdoor-Learning-for-NLP)|
|202|[Removing Backdoors in Pre-trained Models by Regularized Continual Pre-training](https://openreview.net/pdf/b90599e4935794e4f111f07737fb0e5a485048f3.pdf)|Biru Zhu, Ganqu Cui, Yangyi Chen, Yujia Qin, Lifan Yuan, Chong Fu, Yangdong Deng, Zhiyuan Liu, Maosong Sun, Ming Gu|2023-01-01|Transactions of the Association for Computational Linguistics|[![Star](https://img.shields.io/github/stars/thunlp/RECIPE)](https://github.com/thunlp/RECIPE)|

![Star History Chart](https://api.star-history.com/svg?repos=mtuann/backdoor-ai-resources&type=Date)

